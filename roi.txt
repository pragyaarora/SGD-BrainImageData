CROSS VALIDATION 20
Iteration :  0   Loss :  8.33673599849
Iteration :  1   Loss :  0.212376372374
Iteration :  2   Loss :  0.194679639799
Iteration :  3   Loss :  0.190347416014
Iteration :  4   Loss :  0.186206283524
Iteration :  5   Loss :  0.182214777831
Iteration :  6   Loss :  0.1783497106
Iteration :  7   Loss :  0.174596565515
Iteration :  8   Loss :  0.170945474925
Iteration :  9   Loss :  0.16738928631
Iteration :  10   Loss :  0.163922538245
Iteration :  11   Loss :  0.160540877022
Iteration :  12   Loss :  0.157240704787
Iteration :  13   Loss :  0.154018957349
Iteration :  14   Loss :  0.150872958483
Iteration :  15   Loss :  0.147800321368
Iteration :  16   Loss :  0.144798880172
Iteration :  17   Loss :  0.141866641559
Iteration :  18   Loss :  0.139001749721
Iteration :  19   Loss :  0.13620246083
Iteration :  20   Loss :  0.133467124167
Iteration :  21   Loss :  0.130794168054
Iteration :  22   Loss :  0.128182089265
Iteration :  23   Loss :  0.125629444955
Iteration :  24   Loss :  0.123134846395
Iteration :  25   Loss :  0.120696953972
Iteration :  26   Loss :  0.11831447305
Iteration :  27   Loss :  0.115986150381
Iteration :  28   Loss :  0.113710770854
Iteration :  29   Loss :  0.111487154411
Iteration :  30   Loss :  0.10931415306
Iteration :  31   Loss :  0.107190647925
Iteration :  32   Loss :  0.105115546342
Iteration :  33   Loss :  0.103087779035
Iteration :  34   Loss :  0.101106297428
Iteration :  35   Loss :  0.0991700711658
Iteration :  36   Loss :  0.0972780859305
Iteration :  37   Loss :  0.0954293416238
Iteration :  38   Loss :  0.0936228509915
Iteration :  39   Loss :  0.0918576387381
Iteration :  40   Loss :  0.0901327411628
Iteration :  41   Loss :  0.0884472063198
Iteration :  42   Loss :  0.0868000946763
Iteration :  43   Loss :  0.0851904802129
Iteration :  44   Loss :  0.0836174518836
Iteration :  45   Loss :  0.0820801153305
Iteration :  46   Loss :  0.0805775947307
Iteration :  47   Loss :  0.0791090346483
Iteration :  48   Loss :  0.0776736017618
Iteration :  49   Loss :  0.0762704863524
Iteration :  50   Loss :  0.0748989034541
Iteration :  51   Loss :  0.0735580935945
Iteration :  52   Loss :  0.0722473230861
Iteration :  53   Loss :  0.0709658838552
Iteration :  54   Loss :  0.069713092833
Iteration :  55   Loss :  0.0684882909525
Iteration :  56   Loss :  0.0672908418231
Iteration :  57   Loss :  0.0661201301621
Iteration :  58   Loss :  0.0649755600763
Iteration :  59   Loss :  0.0638565532794
Iteration :  60   Loss :  0.0627625473314
Iteration :  61   Loss :  0.0616929939692
Iteration :  62   Loss :  0.0606473575855
Iteration :  63   Loss :  0.0596251138973
Iteration :  64   Loss :  0.0586257488253
Iteration :  65   Loss :  0.0576487575926
Iteration :  66   Loss :  0.0566936440367
Iteration :  67   Loss :  0.0557599201157
Iteration :  68   Loss :  0.0548471055859
Iteration :  69   Loss :  0.0539547278196
Iteration :  70   Loss :  0.0530823217335
Iteration :  71   Loss :  0.0522294297981
Iteration :  72   Loss :  0.0513956021022
Iteration :  73   Loss :  0.0505803964509
Iteration :  74   Loss :  0.0497833784833
Iteration :  75   Loss :  0.0490041217972
Iteration :  76   Loss :  0.0482422080791
Iteration :  77   Loss :  0.0474972272363
Iteration :  78   Loss :  0.0467687775353
Iteration :  79   Loss :  0.0460564657497
Iteration :  80   Loss :  0.0453599073241
Iteration :  81   Loss :  0.0446787265573
Iteration :  82   Loss :  0.0440125568104
Iteration :  83   Loss :  0.0433610407392
Iteration :  84   Loss :  0.042723830554
Iteration :  85   Loss :  0.0421005883017
Iteration :  86   Loss :  0.0414909861673
Iteration :  87   Loss :  0.0408947067892
Iteration :  88   Loss :  0.0403114435788
Iteration :  89   Loss :  0.0397409010373
Iteration :  90   Loss :  0.0391827950587
Iteration :  91   Loss :  0.0386368532104
Iteration :  92   Loss :  0.0381028149794
Iteration :  93   Loss :  0.0375804319771
Iteration :  94   Loss :  0.0370694680915
Iteration :  95   Loss :  0.0365696995811
Iteration :  96   Loss :  0.0360809151028
Iteration :  97   Loss :  0.0356029156709
Iteration :  98   Loss :  0.0351355145421
Iteration :  99   Loss :  0.0346785370283
[ -4.24696243e-04   1.72028068e-04  -1.55369759e-04 ...,   1.36269704e-04
  -5.73598653e-05   1.46408232e-04]
CROSS VALIDATION 21
Iteration :  0   Loss :  8.02700400312
Iteration :  1   Loss :  0.211776264077
Iteration :  2   Loss :  0.195092866568
Iteration :  3   Loss :  0.190578681789
Iteration :  4   Loss :  0.186331951988
Iteration :  5   Loss :  0.182273365765
Iteration :  6   Loss :  0.178363072944
Iteration :  7   Loss :  0.1745781445
Iteration :  8   Loss :  0.170904035
Iteration :  9   Loss :  0.16733079111
Iteration :  10   Loss :  0.163851170089
Iteration :  11   Loss :  0.160459625674
Iteration :  12   Loss :  0.157151725319
Iteration :  13   Loss :  0.15392379774
Iteration :  14   Loss :  0.150772710718
Iteration :  15   Loss :  0.147695726152
Iteration :  16   Loss :  0.144690402792
Iteration :  17   Loss :  0.141754529393
Iteration :  18   Loss :  0.138886077826
Iteration :  19   Loss :  0.136083169581
Iteration :  20   Loss :  0.133344051393
Iteration :  21   Loss :  0.130667077162
Iteration :  22   Loss :  0.128050694229
Iteration :  23   Loss :  0.12549343264
Iteration :  24   Loss :  0.122993896481
Iteration :  25   Loss :  0.120550756567
Iteration :  26   Loss :  0.118162744048
Iteration :  27   Loss :  0.115828644581
Iteration :  28   Loss :  0.113547292867
Iteration :  29   Loss :  0.111317567433
Iteration :  30   Loss :  0.109138385588
Iteration :  31   Loss :  0.107008698552
Iteration :  32   Loss :  0.1049274868
Iteration :  33   Loss :  0.10289375565
Iteration :  34   Loss :  0.100906531191
Iteration :  35   Loss :  0.09896485661
Iteration :  36   Loss :  0.0970677889984
Iteration :  37   Loss :  0.0952143966941
Iteration :  38   Loss :  0.0934037572158
Iteration :  39   Loss :  0.0916349558116
Iteration :  40   Loss :  0.0899070846296
Iteration :  41   Loss :  0.0882192424914
Iteration :  42   Loss :  0.0865705352245
Iteration :  43   Loss :  0.0849600764853
Iteration :  44   Loss :  0.0833869889858
Iteration :  45   Loss :  0.0818504060189
Iteration :  46   Loss :  0.0803494731686
Iteration :  47   Loss :  0.0788833500851
Iteration :  48   Loss :  0.0774512122094
Iteration :  49   Loss :  0.076052252341
Iteration :  50   Loss :  0.0746856819554
Iteration :  51   Loss :  0.0733507322009
Iteration :  52   Loss :  0.0720466545253
Iteration :  53   Loss :  0.0707727209068
Iteration :  54   Loss :  0.0695282236906
Iteration :  55   Loss :  0.06831247505
Iteration :  56   Loss :  0.0671248061164
Iteration :  57   Loss :  0.0659645658315
Iteration :  58   Loss :  0.0648311195901
Iteration :  59   Loss :  0.0637238477458
Iteration :  60   Loss :  0.0626421440549
Iteration :  61   Loss :  0.0615854141293
Iteration :  62   Loss :  0.0605530739649
Iteration :  63   Loss :  0.0595445486024
Iteration :  64   Loss :  0.0585592709671
Iteration :  65   Loss :  0.0575966809204
Iteration :  66   Loss :  0.0566562245477
Iteration :  67   Loss :  0.0557373536882
Iteration :  68   Loss :  0.0548395257092
Iteration :  69   Loss :  0.0539622035092
Iteration :  70   Loss :  0.053104855733
Iteration :  71   Loss :  0.0522669571716
Iteration :  72   Loss :  0.0514479893171
Iteration :  73   Loss :  0.0506474410411
Iteration :  74   Loss :  0.0498648093645
Iteration :  75   Loss :  0.0490996002885
Iteration :  76   Loss :  0.0483513296573
Iteration :  77   Loss :  0.0476195240298
Iteration :  78   Loss :  0.0469037215358
Iteration :  79   Loss :  0.0462034727008
Iteration :  80   Loss :  0.045518341223
Iteration :  81   Loss :  0.0448479046916
Iteration :  82   Loss :  0.044191755235
Iteration :  83   Loss :  0.0435495000931
Iteration :  84   Loss :  0.0429207621063
Iteration :  85   Loss :  0.0423051801172
Iteration :  86   Loss :  0.0417024092818
Iteration :  87   Loss :  0.0411121212879
Iteration :  88   Loss :  0.0405340044805
Iteration :  89   Loss :  0.0399677638942
Iteration :  90   Loss :  0.0394131211949
Iteration :  91   Loss :  0.0388698145337
Iteration :  92   Loss :  0.0383375983179
Iteration :  93   Loss :  0.0378162429051
Iteration :  94   Loss :  0.0373055342261
Iteration :  95   Loss :  0.0368052733462
Iteration :  96   Loss :  0.0363152759722
Iteration :  97   Loss :  0.035835371914
Iteration :  98   Loss :  0.0353654045116
Iteration :  99   Loss :  0.0349052300343
[ -4.20469174e-04   1.75091283e-04  -1.58604854e-04 ...,   1.30312882e-04
  -4.35922453e-05   1.47816830e-04]
CROSS VALIDATION 22
Iteration :  0   Loss :  8.0166181256
Iteration :  1   Loss :  0.211627346267
Iteration :  2   Loss :  0.194931172362
Iteration :  3   Loss :  0.190433205051
Iteration :  4   Loss :  0.186196486059
Iteration :  5   Loss :  0.1821449717
Iteration :  6   Loss :  0.178240151532
Iteration :  7   Loss :  0.174459737092
Iteration :  8   Loss :  0.170789524066
Iteration :  9   Loss :  0.16721975604
Iteration :  10   Loss :  0.16374331133
Iteration :  11   Loss :  0.16035472193
Iteration :  12   Loss :  0.157049607962
Iteration :  13   Loss :  0.153824334745
Iteration :  14   Loss :  0.150675796145
Iteration :  15   Loss :  0.14760127299
Iteration :  16   Loss :  0.144598337939
Iteration :  17   Loss :  0.141664790028
Iteration :  18   Loss :  0.138798608737
Iteration :  19   Loss :  0.135997921151
Iteration :  20   Loss :  0.133260978072
Iteration :  21   Loss :  0.130586136296
Iteration :  22   Loss :  0.127971845152
Iteration :  23   Loss :  0.125416635982
Iteration :  24   Loss :  0.122919113625
Iteration :  25   Loss :  0.120477949237
Iteration :  26   Loss :  0.118091873982
Iteration :  27   Loss :  0.115759673282
Iteration :  28   Loss :  0.113480181401
Iteration :  29   Loss :  0.111252276271
Iteration :  30   Loss :  0.109074874477
Iteration :  31   Loss :  0.106946926414
Iteration :  32   Loss :  0.104867411654
Iteration :  33   Loss :  0.102835334561
Iteration :  34   Loss :  0.100849720244
Iteration :  35   Loss :  0.0989096109215
Iteration :  36   Loss :  0.0970140627569
Iteration :  37   Loss :  0.0951621432485
Iteration :  38   Loss :  0.0933529292054
Iteration :  39   Loss :  0.0915855053426
Iteration :  40   Loss :  0.089858963498
Iteration :  41   Loss :  0.0881724024474
Iteration :  42   Loss :  0.0865249282741
Iteration :  43   Loss :  0.084915655219
Iteration :  44   Loss :  0.0833437069244
Iteration :  45   Loss :  0.0818082179624
Iteration :  46   Loss :  0.0803083355347
Iteration :  47   Loss :  0.0788432212234
Iteration :  48   Loss :  0.0774120526781
Iteration :  49   Loss :  0.076014025133
Iteration :  50   Loss :  0.0746483526666
Iteration :  51   Loss :  0.0733142691329
Iteration :  52   Loss :  0.0720110287184
Iteration :  53   Loss :  0.0707379061048
Iteration :  54   Loss :  0.0694941962377
Iteration :  55   Loss :  0.0682792137265
Iteration :  56   Loss :  0.0670922919188
Iteration :  57   Loss :  0.0659327817058
Iteration :  58   Loss :  0.0648000501275
Iteration :  59   Loss :  0.0636934788501
Iteration :  60   Loss :  0.0626124625908
Iteration :  61   Loss :  0.0615564075614
Iteration :  62   Loss :  0.0605247299952
Iteration :  63   Loss :  0.0595168548152
Iteration :  64   Loss :  0.0585322144874
Iteration :  65   Loss :  0.0575702480932
Iteration :  66   Loss :  0.0566304006428
Iteration :  67   Loss :  0.0557121226367
Iteration :  68   Loss :  0.0548148698739
Iteration :  69   Loss :  0.0539381034943
Iteration :  70   Loss :  0.0530812902333
Iteration :  71   Loss :  0.0522439028644
Iteration :  72   Loss :  0.0514254207966
Iteration :  73   Loss :  0.0506253307958
Iteration :  74   Loss :  0.0498431277958
Iteration :  75   Loss :  0.0490783157694
Iteration :  76   Loss :  0.048330408629
Iteration :  77   Loss :  0.0475989311325
Iteration :  78   Loss :  0.0468834197706
Iteration :  79   Loss :  0.0461834236198
Iteration :  80   Loss :  0.0454985051429
Iteration :  81   Loss :  0.0448282409274
Iteration :  82   Loss :  0.044172222351
Iteration :  83   Loss :  0.0435300561673
Iteration :  84   Loss :  0.0429013650058
Iteration :  85   Loss :  0.0422857877829
Iteration :  86   Loss :  0.0416829800198
Iteration :  87   Loss :  0.041092614068
Iteration :  88   Loss :  0.0405143792395
Iteration :  89   Loss :  0.0399479818458
Iteration :  90   Loss :  0.0393931451444
Iteration :  91   Loss :  0.0388496091998
Iteration :  92   Loss :  0.038317130661
Iteration :  93   Loss :  0.0377954824622
Iteration :  94   Loss :  0.0372844534534
Iteration :  95   Loss :  0.0367838479678
Iteration :  96   Loss :  0.036293485334
Iteration :  97   Loss :  0.0358131993417
Iteration :  98   Loss :  0.0353428376682
Iteration :  99   Loss :  0.0348822612746
[ -4.21513967e-04   1.75678975e-04  -1.60089950e-04 ...,   1.30440612e-04
  -4.42772918e-05   1.47965386e-04]
CROSS VALIDATION 23
Iteration :  0   Loss :  9.45189173336
Iteration :  1   Loss :  0.209512881879
Iteration :  2   Loss :  0.195197102605
Iteration :  3   Loss :  0.190000631515
Iteration :  4   Loss :  0.185419051538
Iteration :  5   Loss :  0.181169168268
Iteration :  6   Loss :  0.177140776343
Iteration :  7   Loss :  0.173279957689
Iteration :  8   Loss :  0.169556373511
Iteration :  9   Loss :  0.165951188944
Iteration :  10   Loss :  0.162451798892
Iteration :  11   Loss :  0.159049241284
Iteration :  12   Loss :  0.155736814869
Iteration :  13   Loss :  0.15250928996
Iteration :  14   Loss :  0.149362433157
Iteration :  15   Loss :  0.146292708359
Iteration :  16   Loss :  0.143297081673
Iteration :  17   Loss :  0.140372890073
Iteration :  18   Loss :  0.137517750605
Iteration :  19   Loss :  0.134729496161
Iteration :  20   Loss :  0.132006129168
Iteration :  21   Loss :  0.129345787683
Iteration :  22   Loss :  0.126746720283
Iteration :  23   Loss :  0.124207267335
Iteration :  24   Loss :  0.121725847034
Iteration :  25   Loss :  0.119300945025
Iteration :  26   Loss :  0.116931106805
Iteration :  27   Loss :  0.114614932277
Iteration :  28   Loss :  0.112351071961
Iteration :  29   Loss :  0.110138224478
Iteration :  30   Loss :  0.107975134956
Iteration :  31   Loss :  0.105860594062
Iteration :  32   Loss :  0.103793437399
Iteration :  33   Loss :  0.101772545033
Iteration :  34   Loss :  0.0997968409656
Iteration :  35   Loss :  0.0978652923805
Iteration :  36   Loss :  0.0959769085594
Iteration :  37   Loss :  0.0941307393876
Iteration :  38   Loss :  0.0923258734161
Iteration :  39   Loss :  0.0905614354846
Iteration :  40   Loss :  0.0888365839427
Iteration :  41   Loss :  0.0871505075335
Iteration :  42   Loss :  0.0855024220239
Iteration :  43   Loss :  0.0838915666805
Iteration :  44   Loss :  0.0823172006963
Iteration :  45   Loss :  0.0807785996721
Iteration :  46   Loss :  0.0792750522582
Iteration :  47   Loss :  0.0778058570469
Iteration :  48   Loss :  0.0763703197993
Iteration :  49   Loss :  0.074967751073
Iteration :  50   Loss :  0.0735974643009
Iteration :  51   Loss :  0.0722587743543
Iteration :  52   Loss :  0.0709509966012
Iteration :  53   Loss :  0.0696734464568
Iteration :  54   Loss :  0.0684254394001
Iteration :  55   Loss :  0.0672062914178
Iteration :  56   Loss :  0.0660153198211
Iteration :  57   Loss :  0.0648518443715
Iteration :  58   Loss :  0.063715188645
Iteration :  59   Loss :  0.0626046815609
Iteration :  60   Loss :  0.0615196590035
Iteration :  61   Loss :  0.060459465468
Iteration :  62   Loss :  0.0594234556732
Iteration :  63   Loss :  0.0584109960879
Iteration :  64   Loss :  0.0574214663331
Iteration :  65   Loss :  0.0564542604319
Iteration :  66   Loss :  0.0555087878875
Iteration :  67   Loss :  0.0545844745818
Iteration :  68   Loss :  0.0536807634926
Iteration :  69   Loss :  0.0527971152341
Iteration :  70   Loss :  0.0519330084294
Iteration :  71   Loss :  0.0510879399242
Iteration :  72   Loss :  0.0502614248545
Iteration :  73   Loss :  0.0494529965785
Iteration :  74   Loss :  0.0486622064828
Iteration :  75   Loss :  0.0478886236731
Iteration :  76   Loss :  0.0471318345586
Iteration :  77   Loss :  0.046391442338
Iteration :  78   Loss :  0.0456670663981
Iteration :  79   Loss :  0.0449583416345
Iteration :  80   Loss :  0.0442649177087
Iteration :  81   Loss :  0.0435864582541
Iteration :  82   Loss :  0.0429226400507
Iteration :  83   Loss :  0.042273152185
Iteration :  84   Loss :  0.0416376952178
Iteration :  85   Loss :  0.0410159803801
Iteration :  86   Loss :  0.0404077288198
Iteration :  87   Loss :  0.0398126709181
Iteration :  88   Loss :  0.0392305456951
Iteration :  89   Loss :  0.0386611003193
Iteration :  90   Loss :  0.0381040897319
Iteration :  91   Loss :  0.0375592763909
Iteration :  92   Loss :  0.0370264301389
Iteration :  93   Loss :  0.0365053281861
Iteration :  94   Loss :  0.0359957552033
Iteration :  95   Loss :  0.0354975035067
Iteration :  96   Loss :  0.0350103733197
Iteration :  97   Loss :  0.0345341730885
Iteration :  98   Loss :  0.0340687198299
Iteration :  99   Loss :  0.0336138394872
[-0.0007057   0.00013768 -0.00028516 ...,  0.00019901 -0.00010515
  0.00018159]
CROSS VALIDATION 24
Iteration :  0   Loss :  8.01316658292
Iteration :  1   Loss :  0.211544832108
Iteration :  2   Loss :  0.195048916252
Iteration :  3   Loss :  0.190528123572
Iteration :  4   Loss :  0.186278628456
Iteration :  5   Loss :  0.182218923833
Iteration :  6   Loss :  0.17830834381
Iteration :  7   Loss :  0.174523593087
Iteration :  8   Loss :  0.170849939727
Iteration :  9   Loss :  0.16727732648
Iteration :  10   Loss :  0.163798448683
Iteration :  11   Loss :  0.160407721244
Iteration :  12   Loss :  0.157100686306
Iteration :  13   Loss :  0.153873655607
Iteration :  14   Loss :  0.150723485312
Iteration :  15   Loss :  0.147647429281
Iteration :  16   Loss :  0.144643040674
Iteration :  17   Loss :  0.141708104371
Iteration :  18   Loss :  0.138840589583
Iteration :  19   Loss :  0.136038615998
Iteration :  20   Loss :  0.133300429155
Iteration :  21   Loss :  0.13062438217
Iteration :  22   Loss :  0.128008921864
Iteration :  23   Loss :  0.125452577927
Iteration :  24   Loss :  0.122953954159
Iteration :  25   Loss :  0.120511721116
Iteration :  26   Loss :  0.118124609661
Iteration :  27   Loss :  0.115791405125
Iteration :  28   Loss :  0.113510941833
Iteration :  29   Loss :  0.111282097883
Iteration :  30   Loss :  0.109103790118
Iteration :  31   Loss :  0.106974969281
Iteration :  32   Loss :  0.104894615367
Iteration :  33   Loss :  0.102861733255
Iteration :  34   Loss :  0.100875348647
Iteration :  35   Loss :  0.0989345044268
Iteration :  36   Loss :  0.0970382574818
Iteration :  37   Loss :  0.0951856760593
Iteration :  38   Loss :  0.0933758377056
Iteration :  39   Loss :  0.0916078278115
Iteration :  40   Loss :  0.0898807387706
Iteration :  41   Loss :  0.0881936697324
Iteration :  42   Loss :  0.0865457269053
Iteration :  43   Loss :  0.0849360243437
Iteration :  44   Loss :  0.0833636851339
Iteration :  45   Loss :  0.0818278428744
Iteration :  46   Loss :  0.0803276433407
Iteration :  47   Loss :  0.078862246215
Iteration :  48   Loss :  0.0774308267698
Iteration :  49   Loss :  0.0760325773978
Iteration :  50   Loss :  0.0746667088985
Iteration :  51   Loss :  0.073332451452
Iteration :  52   Loss :  0.0720290552288
Iteration :  53   Loss :  0.0707557906139
Iteration :  54   Loss :  0.069511948043
Iteration :  55   Loss :  0.0682968374729
Iteration :  56   Loss :  0.0671097875262
Iteration :  57   Loss :  0.0659501443679
Iteration :  58   Loss :  0.0648172703776
Iteration :  59   Loss :  0.063710542693
Iteration :  60   Loss :  0.0626293516977
Iteration :  61   Loss :  0.0615730995252
Iteration :  62   Loss :  0.0605411986454
Iteration :  63   Loss :  0.0595330705903
Iteration :  64   Loss :  0.0585481448654
Iteration :  65   Loss :  0.0575858580796
Iteration :  66   Loss :  0.0566456533152
Iteration :  67   Loss :  0.0557269797452
Iteration :  68   Loss :  0.0548292924954
Iteration :  69   Loss :  0.0539520527365
Iteration :  70   Loss :  0.0530947279834
Iteration :  71   Loss :  0.0522567925743
Iteration :  72   Loss :  0.0514377282947
Iteration :  73   Loss :  0.0506370251143
Iteration :  74   Loss :  0.0498541819995
Iteration :  75   Loss :  0.0490887077714
Iteration :  76   Loss :  0.0483401219776
Iteration :  77   Loss :  0.047607955754
Iteration :  78   Loss :  0.0468917526539
Iteration :  79   Loss :  0.0461910694276
Iteration :  80   Loss :  0.0455054767396
Iteration :  81   Loss :  0.044834559813
Iteration :  82   Loss :  0.0441779189941
Iteration :  83   Loss :  0.0435351702327
Iteration :  84   Loss :  0.0429059454747
Iteration :  85   Loss :  0.0422898929652
Iteration :  86   Loss :  0.0416866774618
Iteration :  87   Loss :  0.0410959803573
Iteration :  88   Loss :  0.0405174997134
Iteration :  89   Loss :  0.0399509502066
Iteration :  90   Loss :  0.0393960629895
Iteration :  91   Loss :  0.03885258547
Iteration :  92   Loss :  0.0383202810128
Iteration :  93   Loss :  0.0377989285699
Iteration :  94   Loss :  0.0372883222442
Iteration :  95   Loss :  0.0367882707948
Iteration :  96   Loss :  0.0362985970911
Iteration :  97   Loss :  0.0358191375241
Iteration :  98   Loss :  0.0353497413831
Iteration :  99   Loss :  0.0348902702078
[ -4.20376990e-04   1.75358941e-04  -1.58764275e-04 ...,   1.30081182e-04
  -4.31782462e-05   1.47740023e-04]
CROSS VALIDATION 25
Iteration :  0   Loss :  8.03870450613
Iteration :  1   Loss :  0.21124832778
Iteration :  2   Loss :  0.194915321846
Iteration :  3   Loss :  0.190373490584
Iteration :  4   Loss :  0.18610914854
Iteration :  5   Loss :  0.182036800599
Iteration :  6   Loss :  0.17811442822
Iteration :  7   Loss :  0.174318219317
Iteration :  8   Loss :  0.170633238313
Iteration :  9   Loss :  0.167049354239
Iteration :  10   Loss :  0.16355924592
Iteration :  11   Loss :  0.160157337489
Iteration :  12   Loss :  0.156839191532
Iteration :  13   Loss :  0.153601144451
Iteration :  14   Loss :  0.150440077772
Iteration :  15   Loss :  0.147353269574
Iteration :  16   Loss :  0.144338295078
Iteration :  17   Loss :  0.141392958457
Iteration :  18   Loss :  0.138515245028
Iteration :  19   Loss :  0.13570328709
Iteration :  20   Loss :  0.132955339058
Iteration :  21   Loss :  0.130269759001
Iteration :  22   Loss :  0.12764499466
Iteration :  23   Loss :  0.125079572585
Iteration :  24   Loss :  0.122572089448
Iteration :  25   Loss :  0.120121204876
Iteration :  26   Loss :  0.117725635318
Iteration :  27   Loss :  0.115384148632
Iteration :  28   Loss :  0.113095559156
Iteration :  29   Loss :  0.110858723132
Iteration :  30   Loss :  0.108672534385
Iteration :  31   Loss :  0.106535920246
Iteration :  32   Loss :  0.104447837679
Iteration :  33   Loss :  0.102407269673
Iteration :  34   Loss :  0.100413221905
Iteration :  35   Loss :  0.0984647197316
Iteration :  36   Loss :  0.0965608055535
Iteration :  37   Loss :  0.0947005365867
Iteration :  38   Loss :  0.0928829830781
Iteration :  39   Loss :  0.0911072269785
Iteration :  40   Loss :  0.0893723610771
Iteration :  41   Loss :  0.0876774885832
Iteration :  42   Loss :  0.0860217231224
Iteration :  43   Loss :  0.0844041890996
Iteration :  44   Loss :  0.0828240223683
Iteration :  45   Loss :  0.0812803711301
Iteration :  46   Loss :  0.0797723969859
Iteration :  47   Loss :  0.0782992760553
Iteration :  48   Loss :  0.0768602000788
Iteration :  49   Loss :  0.0754543774297
Iteration :  50   Loss :  0.0740810339653
Iteration :  51   Loss :  0.0727394136646
Iteration :  52   Loss :  0.071428779012
Iteration :  53   Loss :  0.0701484111042
Iteration :  54   Loss :  0.0688976094728
Iteration :  55   Loss :  0.0676756916326
Iteration :  56   Loss :  0.0664819923767
Iteration :  57   Loss :  0.0653158628548
Iteration :  58   Loss :  0.0641766694768
Iteration :  59   Loss :  0.0630637926936
Iteration :  60   Loss :  0.0619766257065
Iteration :  61   Loss :  0.0609145731614
Iteration :  62   Loss :  0.059877049879
Iteration :  63   Loss :  0.0588634796692
Iteration :  64   Loss :  0.057873294273
Iteration :  65   Loss :  0.0569059324673
Iteration :  66   Loss :  0.0559608393588
Iteration :  67   Loss :  0.0550374658866
Iteration :  68   Loss :  0.0541352685425
Iteration :  69   Loss :  0.053253709309
Iteration :  70   Loss :  0.0523922558093
Iteration :  71   Loss :  0.051550381653
Iteration :  72   Loss :  0.0507275669579
Iteration :  73   Loss :  0.0499232990218
Iteration :  74   Loss :  0.0491370731162
Iteration :  75   Loss :  0.0483683933707
Iteration :  76   Loss :  0.0476167737169
Iteration :  77   Loss :  0.0468817388618
Iteration :  78   Loss :  0.0461628252607
Iteration :  79   Loss :  0.0454595820639
Iteration :  80   Loss :  0.0447715720131
Iteration :  81   Loss :  0.0440983722665
Iteration :  82   Loss :  0.0434395751361
Iteration :  83   Loss :  0.0427947887245
Iteration :  84   Loss :  0.0421636374485
Iteration :  85   Loss :  0.0415457624454
Iteration :  86   Loss :  0.0409408218574
Iteration :  87   Loss :  0.0403484909922
Iteration :  88   Loss :  0.0397684623647
Iteration :  89   Loss :  0.039200445622
Iteration :  90   Loss :  0.0386441673594
Iteration :  91   Loss :  0.0380993708377
Iteration :  92   Loss :  0.0375658156103
Iteration :  93   Loss :  0.037043277073
Iteration :  94   Loss :  0.0365315459495
Iteration :  95   Loss :  0.0360304277235
Iteration :  96   Loss :  0.0355397420331
Iteration :  97   Loss :  0.0350593220372
Iteration :  98   Loss :  0.0345890137679
Iteration :  99   Loss :  0.0341286754779
[ -4.14095891e-04   1.75821395e-04  -1.53373521e-04 ...,   1.27878619e-04
  -3.72169308e-05   1.45433400e-04]
CROSS VALIDATION 26
Iteration :  0   Loss :  8.01408495373
Iteration :  1   Loss :  0.211563617392
Iteration :  2   Loss :  0.195055776808
Iteration :  3   Loss :  0.19053529114
Iteration :  4   Loss :  0.186285804812
Iteration :  5   Loss :  0.182225964986
Iteration :  6   Loss :  0.178315163501
Iteration :  7   Loss :  0.174530130601
Iteration :  8   Loss :  0.170856146526
Iteration :  9   Loss :  0.167283159725
Iteration :  10   Loss :  0.163803867668
Iteration :  11   Loss :  0.160412685212
Iteration :  12   Loss :  0.15710515297
Iteration :  13   Loss :  0.153877580047
Iteration :  14   Loss :  0.150726819092
Iteration :  15   Loss :  0.147650119683
Iteration :  16   Loss :  0.144645030008
Iteration :  17   Loss :  0.141709329323
Iteration :  18   Loss :  0.138840980588
Iteration :  19   Loss :  0.136038096631
Iteration :  20   Loss :  0.133298915525
Iteration :  21   Loss :  0.130621782333
Iteration :  22   Loss :  0.128005135243
Iteration :  23   Loss :  0.125447494751
Iteration :  24   Loss :  0.122947454928
Iteration :  25   Loss :  0.120503676095
Iteration :  26   Loss :  0.118114878423
Iteration :  27   Loss :  0.115779836146
Iteration :  28   Loss :  0.113497372156
Iteration :  29   Loss :  0.111266352872
Iteration :  30   Loss :  0.109085683305
Iteration :  31   Loss :  0.106954302335
Iteration :  32   Loss :  0.1048711782
Iteration :  33   Loss :  0.102835304274
Iteration :  34   Loss :  0.100845695191
Iteration :  35   Loss :  0.0989013833899
Iteration :  36   Loss :  0.097001416144
Iteration :  37   Loss :  0.09514485315
Iteration :  38   Loss :  0.0933307647071
Iteration :  39   Loss :  0.0915582305186
Iteration :  40   Loss :  0.0898263391144
Iteration :  41   Loss :  0.0881341878727
Iteration :  42   Loss :  0.0864808835903
Iteration :  43   Loss :  0.0848655435294
Iteration :  44   Loss :  0.0832872968463
Iteration :  45   Loss :  0.0817452862916
Iteration :  46   Loss :  0.0802386700582
Iteration :  47   Loss :  0.0787666236539
Iteration :  48   Loss :  0.0773283416704
Iteration :  49   Loss :  0.0759230393378
Iteration :  50   Loss :  0.0745499537644
Iteration :  51   Loss :  0.0732083447835
Iteration :  52   Loss :  0.0718974953561
Iteration :  53   Loss :  0.0706167115012
Iteration :  54   Loss :  0.0693653217568
Iteration :  55   Loss :  0.0681426761952
Iteration :  56   Loss :  0.066948145044
Iteration :  57   Loss :  0.0657811169782
Iteration :  58   Loss :  0.0646409971652
Iteration :  59   Loss :  0.0635272051519
Iteration :  60   Loss :  0.0624391726868
Iteration :  61   Loss :  0.0613763415682
Iteration :  62   Loss :  0.0603381616024
Iteration :  63   Loss :  0.0593240887485
Iteration :  64   Loss :  0.0583335835117
Iteration :  65   Loss :  0.0573661096316
Iteration :  66   Loss :  0.0564211331002
Iteration :  67   Loss :  0.0554981215241
Iteration :  68   Loss :  0.0545965438321
Iteration :  69   Loss :  0.0537158703168
Iteration :  70   Loss :  0.0528555729857
Iteration :  71   Loss :  0.0520151261869
Iteration :  72   Loss :  0.0511940074703
Iteration :  73   Loss :  0.0503916986391
Iteration :  74   Loss :  0.0496076869436
Iteration :  75   Loss :  0.0488414663724
Iteration :  76   Loss :  0.0480925389951
Iteration :  77   Loss :  0.0473604163163
Iteration :  78   Loss :  0.0466446206026
Iteration :  79   Loss :  0.0459446861512
Iteration :  80   Loss :  0.0452601604744
Iteration :  81   Loss :  0.0445906053746
Iteration :  82   Loss :  0.0439355978967
Iteration :  83   Loss :  0.043294731143
Iteration :  84   Loss :  0.0426676149439
Iteration :  85   Loss :  0.0420538763791
Iteration :  86   Loss :  0.0414531601506
Iteration :  87   Loss :  0.0408651288083
Iteration :  88   Loss :  0.0402894628348
Iteration :  89   Loss :  0.0397258605962
Iteration :  90   Loss :  0.0391740381697
Iteration :  91   Loss :  0.0386337290571
Iteration :  92   Loss :  0.0381046837984
Iteration :  93   Loss :  0.0375866694969
Iteration :  94   Loss :  0.0370794692699
Iteration :  95   Loss :  0.0365828816367
Iteration :  96   Loss :  0.036096719859
Iteration :  97   Loss :  0.0356208112449
Iteration :  98   Loss :  0.0351549964279
Iteration :  99   Loss :  0.0346991286336
[ -4.17855366e-04   1.69452877e-04  -1.57190238e-04 ...,   1.27422513e-04
  -3.98924632e-05   1.48612816e-04]
CROSS VALIDATION 27
Iteration :  0   Loss :  7.99778391833
Iteration :  1   Loss :  0.211392326116
Iteration :  2   Loss :  0.195009925157
Iteration :  3   Loss :  0.190490753571
Iteration :  4   Loss :  0.186242521924
Iteration :  5   Loss :  0.182183885527
Iteration :  6   Loss :  0.178274284041
Iteration :  7   Loss :  0.174490475624
Iteration :  8   Loss :  0.170817753669
Iteration :  9   Loss :  0.167246071914
Iteration :  10   Loss :  0.163768129402
Iteration :  11   Loss :  0.160378341077
Iteration :  12   Loss :  0.15707224732
Iteration :  13   Loss :  0.153846157318
Iteration :  14   Loss :  0.150696924439
Iteration :  15   Loss :  0.147621799799
Iteration :  16   Loss :  0.144618334032
Iteration :  17   Loss :  0.141684309798
Iteration :  18   Loss :  0.138817694431
Iteration :  19   Loss :  0.136016606097
Iteration :  20   Loss :  0.133279289148
Iteration :  21   Loss :  0.130604095825
Iteration :  22   Loss :  0.127989472341
Iteration :  23   Loss :  0.125433947988
Iteration :  24   Loss :  0.122936126325
Iteration :  25   Loss :  0.120494677746
Iteration :  26   Loss :  0.118108332973
Iteration :  27   Loss :  0.115775877141
Iteration :  28   Loss :  0.113496144258
Iteration :  29   Loss :  0.111268011932
Iteration :  30   Loss :  0.109090396287
Iteration :  31   Loss :  0.106962247077
Iteration :  32   Loss :  0.104882543017
Iteration :  33   Loss :  0.102850287389
Iteration :  34   Loss :  0.100864503989
Iteration :  35   Loss :  0.0989242334888
Iteration :  36   Loss :  0.0970285302698
Iteration :  37   Loss :  0.0951764598101
Iteration :  38   Loss :  0.0933670966492
Iteration :  39   Loss :  0.0915995229653
Iteration :  40   Loss :  0.0898728277664
Iteration :  41   Loss :  0.0881861066733
Iteration :  42   Loss :  0.0865384622519
Iteration :  43   Loss :  0.0849290048248
Iteration :  44   Loss :  0.0833568536782
Iteration :  45   Loss :  0.0818211385592
Iteration :  46   Loss :  0.0803210013533
Iteration :  47   Loss :  0.0788555978232
Iteration :  48   Loss :  0.0774240992978
Iteration :  49   Loss :  0.0760256942052
Iteration :  50   Loss :  0.0746595893601
Iteration :  51   Loss :  0.0733250109359
Iteration :  52   Loss :  0.0720212050737
Iteration :  53   Loss :  0.0707474381046
Iteration :  54   Loss :  0.0695029963859
Iteration :  55   Loss :  0.0682871857737
Iteration :  56   Loss :  0.067099330774
Iteration :  57   Loss :  0.0659387734304
Iteration :  58   Loss :  0.0648048720143
Iteration :  59   Loss :  0.0636969995936
Iteration :  60   Loss :  0.0626145425543
Iteration :  61   Loss :  0.0615568991483
Iteration :  62   Loss :  0.060523478133
Iteration :  63   Loss :  0.0595136975607
Iteration :  64   Loss :  0.0585269837625
Iteration :  65   Loss :  0.0575627705613
Iteration :  66   Loss :  0.0566204987305
Iteration :  67   Loss :  0.0556996157088
Iteration :  68   Loss :  0.0547995755618
Iteration :  69   Loss :  0.0539198391761
Iteration :  70   Loss :  0.0530598746602
Iteration :  71   Loss :  0.0522191579195
Iteration :  72   Loss :  0.0513971733704
Iteration :  73   Loss :  0.0505934147557
Iteration :  74   Loss :  0.0498073860216
Iteration :  75   Loss :  0.0490386022235
Iteration :  76   Loss :  0.0482865904262
Iteration :  77   Loss :  0.0475508905711
Iteration :  78   Loss :  0.0468310562879
Iteration :  79   Loss :  0.0461266556315
Iteration :  80   Loss :  0.0454372717306
Iteration :  81   Loss :  0.0447625033387
Iteration :  82   Loss :  0.0441019652818
Iteration :  83   Loss :  0.0434552887987
Iteration :  84   Loss :  0.0428221217738
Iteration :  85   Loss :  0.0422021288644
Iteration :  86   Loss :  0.0415949915243
Iteration :  87   Loss :  0.0410004079285
Iteration :  88   Loss :  0.0404180928042
Iteration :  89   Loss :  0.0398477771745
Iteration :  90   Loss :  0.0392892080219
Iteration :  91   Loss :  0.0387421478793
Iteration :  92   Loss :  0.0382063743573
Iteration :  93   Loss :  0.0376816796174
Iteration :  94   Loss :  0.0371678697991
Iteration :  95   Loss :  0.0366647644122
Iteration :  96   Loss :  0.0361721957031
Iteration :  97   Loss :  0.0356900080038
Iteration :  98   Loss :  0.035218057074
Iteration :  99   Loss :  0.0347562094439
[ -4.20015826e-04   1.76464550e-04  -1.58488211e-04 ...,   1.31091800e-04
  -4.37014451e-05   1.47506515e-04]
CROSS VALIDATION 28
Iteration :  0   Loss :  0.575784314735
Iteration :  1   Loss :  0.174934868671
Iteration :  2   Loss :  0.167531342935
Iteration :  3   Loss :  0.162428741829
Iteration :  4   Loss :  0.158140020121
Iteration :  5   Loss :  0.154294559586
Iteration :  6   Loss :  0.150737910176
Iteration :  7   Loss :  0.147391114346
Iteration :  8   Loss :  0.144208560084
Iteration :  9   Loss :  0.1411615691
Iteration :  10   Loss :  0.138230919703
Iteration :  11   Loss :  0.135403052667
Iteration :  12   Loss :  0.132667986215
Iteration :  13   Loss :  0.130018097024
Iteration :  14   Loss :  0.127447371178
Iteration :  15   Loss :  0.124950924683
Iteration :  16   Loss :  0.122524685859
Iteration :  17   Loss :  0.120165178874
Iteration :  18   Loss :  0.117869372672
Iteration :  19   Loss :  0.115634573501
Iteration :  20   Loss :  0.11345834732
Iteration :  21   Loss :  0.111338463213
Iteration :  22   Loss :  0.109272851887
Iteration :  23   Loss :  0.107259575207
Iteration :  24   Loss :  0.105296803939
Iteration :  25   Loss :  0.103382801632
Iteration :  26   Loss :  0.101515913114
Iteration :  27   Loss :  0.0996945564548
Iteration :  28   Loss :  0.0979172174744
Iteration :  29   Loss :  0.0961824460868
Iteration :  30   Loss :  0.0944888539096
Iteration :  31   Loss :  0.0928351126804
Iteration :  32   Loss :  0.0912199531184
Iteration :  33   Loss :  0.0896421639511
Iteration :  34   Loss :  0.0881005908943
Iteration :  35   Loss :  0.0865941354336
Iteration :  36   Loss :  0.08512175331
Iteration :  37   Loss :  0.0836824526544
Iteration :  38   Loss :  0.0822752917554
Iteration :  39   Loss :  0.0808993764757
Iteration :  40   Loss :  0.0795538573549
Iteration :  41   Loss :  0.0782379264574
Iteration :  42   Loss :  0.076950814036
Iteration :  43   Loss :  0.075691785088
Iteration :  44   Loss :  0.0744601358886
Iteration :  45   Loss :  0.073255190583
Iteration :  46   Loss :  0.0720762979179
Iteration :  47   Loss :  0.0709228281879
Iteration :  48   Loss :  0.0697941704651
Iteration :  49   Loss :  0.0686897301712
Iteration :  50   Loss :  0.0676089270385
Iteration :  51   Loss :  0.0665511934951
Iteration :  52   Loss :  0.0655159734905
Iteration :  53   Loss :  0.0645027217633
Iteration :  54   Loss :  0.0635109035313
Iteration :  55   Loss :  0.0625399945655
Iteration :  56   Loss :  0.061589481593
Iteration :  57   Loss :  0.0606588629557
Iteration :  58   Loss :  0.0597476494423
Iteration :  59   Loss :  0.0588553652047
Iteration :  60   Loss :  0.057981548669
Iteration :  61   Loss :  0.0571257533601
Iteration :  62   Loss :  0.0562875485689
Iteration :  63   Loss :  0.0554665198095
Iteration :  64   Loss :  0.0546622690324
Iteration :  65   Loss :  0.0538744145793
Iteration :  66   Loss :  0.0531025908866
Iteration :  67   Loss :  0.0523464479577
Iteration :  68   Loss :  0.0516056506409
Iteration :  69   Loss :  0.050879877753
Iteration :  70   Loss :  0.0501688210995
Iteration :  71   Loss :  0.0494721844354
Iteration :  72   Loss :  0.0487896824138
Iteration :  73   Loss :  0.0481210395595
Iteration :  74   Loss :  0.0474659893016
Iteration :  75   Loss :  0.0468242730897
Iteration :  76   Loss :  0.0461956396111
Iteration :  77   Loss :  0.0455798441205
Iteration :  78   Loss :  0.0449766478866
Iteration :  79   Loss :  0.0443858177552
Iteration :  80   Loss :  0.0438071258247
Iteration :  81   Loss :  0.0432403492244
Iteration :  82   Loss :  0.0426852699882
Iteration :  83   Loss :  0.0421416750086
Iteration :  84   Loss :  0.0416093560602
Iteration :  85   Loss :  0.041088109878
Iteration :  86   Loss :  0.0405777382769
Iteration :  87   Loss :  0.0400780482988
Iteration :  88   Loss :  0.039588852374
Iteration :  89   Loss :  0.0391099684833
Iteration :  90   Loss :  0.03864122031
Iteration :  91   Loss :  0.0381824373683
Iteration :  92   Loss :  0.0377334551003
Iteration :  93   Loss :  0.0372941149286
Iteration :  94   Loss :  0.0368642642588
Iteration :  95   Loss :  0.0364437564222
Iteration :  96   Loss :  0.0360324505534
Iteration :  97   Loss :  0.0356302113962
Iteration :  98   Loss :  0.0352369090351
Iteration :  99   Loss :  0.0348524185482
[ -3.51881991e-04   1.24050962e-04   1.04303817e-04 ...,   1.16038562e-04
   2.24030329e-05   1.40968578e-04]
CROSS VALIDATION 29
Iteration :  0   Loss :  7.9780565554
Iteration :  1   Loss :  0.211074413899
Iteration :  2   Loss :  0.194831786472
Iteration :  3   Loss :  0.190333870668
Iteration :  4   Loss :  0.186098544893
Iteration :  5   Loss :  0.182048821103
Iteration :  6   Loss :  0.178146025476
Iteration :  7   Loss :  0.174367826833
Iteration :  8   Loss :  0.170699994978
Iteration :  9   Loss :  0.167132748309
Iteration :  10   Loss :  0.163658939656
Iteration :  11   Loss :  0.160273076331
Iteration :  12   Loss :  0.1569707555
Iteration :  13   Loss :  0.153748321766
Iteration :  14   Loss :  0.150602650733
Iteration :  15   Loss :  0.147531007477
Iteration :  16   Loss :  0.144530951359
Iteration :  17   Loss :  0.141600270468
Iteration :  18   Loss :  0.138736935542
Iteration :  19   Loss :  0.13593906695
Iteration :  20   Loss :  0.133204910601
Iteration :  21   Loss :  0.130532819989
Iteration :  22   Loss :  0.127921242472
Iteration :  23   Loss :  0.125368708484
Iteration :  24   Loss :  0.122873822719
Iteration :  25   Loss :  0.120435256665
Iteration :  26   Loss :  0.118051742009
Iteration :  27   Loss :  0.115722064603
Iteration :  28   Loss :  0.113445058817
Iteration :  29   Loss :  0.111219602141
Iteration :  30   Loss :  0.109044610007
Iteration :  31   Loss :  0.106919030824
Iteration :  32   Loss :  0.104841841262
Iteration :  33   Loss :  0.102812041841
Iteration :  34   Loss :  0.100828652902
Iteration :  35   Loss :  0.0988907110098
Iteration :  36   Loss :  0.0969972658724
Iteration :  37   Loss :  0.0951473778233
Iteration :  38   Loss :  0.093340115905
Iteration :  39   Loss :  0.0915745565731
Iteration :  40   Loss :  0.0898497830201
Iteration :  41   Loss :  0.0881648850885
Iteration :  42   Loss :  0.0865189597266
Iteration :  43   Loss :  0.0849111119137
Iteration :  44   Loss :  0.083340455964
Iteration :  45   Loss :  0.0818061171048
Iteration :  46   Loss :  0.0803072332139
Iteration :  47   Loss :  0.0788429565995
Iteration :  48   Loss :  0.0774124557068
Iteration :  49   Loss :  0.07601491665
Iteration :  50   Loss :  0.074649544479
Iteration :  51   Loss :  0.0733155641149
Iteration :  52   Loss :  0.0720122209085
Iteration :  53   Loss :  0.0707387808048
Iteration :  54   Loss :  0.0694945301164
Iteration :  55   Loss :  0.0682787749356
Iteration :  56   Loss :  0.0670908402321
Iteration :  57   Loss :  0.0659300686978
Iteration :  58   Loss :  0.0647958194123
Iteration :  59   Loss :  0.0636874664055
Iteration :  60   Loss :  0.0626043971954
Iteration :  61   Loss :  0.0615460113753
Iteration :  62   Loss :  0.0605117193153
Iteration :  63   Loss :  0.0595009410339
Iteration :  64   Loss :  0.0585131052816
Iteration :  65   Loss :  0.0575476488649
Iteration :  66   Loss :  0.0566040162248
Iteration :  67   Loss :  0.0556816592697
Iteration :  68   Loss :  0.0547800374499
Iteration :  69   Loss :  0.0538986180509
Iteration :  70   Loss :  0.0530368766727
Iteration :  71   Loss :  0.0521942978571
Iteration :  72   Loss :  0.0513703758226
Iteration :  73   Loss :  0.0505646152627
Iteration :  74   Loss :  0.04977653217
Iteration :  75   Loss :  0.0490056546466
Iteration :  76   Loss :  0.0482515236706
Iteration :  77   Loss :  0.0475136937927
Iteration :  78   Loss :  0.0467917337446
Iteration :  79   Loss :  0.0460852269443
Iteration :  80   Loss :  0.0453937718947
Iteration :  81   Loss :  0.0447169824709
Iteration :  82   Loss :  0.0440544881011
Iteration :  83   Loss :  0.043405933846
Iteration :  84   Loss :  0.0427709803857
Iteration :  85   Loss :  0.0421493039225
Iteration :  86   Loss :  0.0415405960121
Iteration :  87   Loss :  0.0409445633319
Iteration :  88   Loss :  0.0403609273967
Iteration :  89   Loss :  0.0397894242316
Iteration :  90   Loss :  0.0392298040102
Iteration :  91   Loss :  0.038681830665
Iteration :  92   Loss :  0.038145281476
Iteration :  93   Loss :  0.0376199466439
Iteration :  94   Loss :  0.0371056288504
Iteration :  95   Loss :  0.0366021428107
Iteration :  96   Loss :  0.0361093148195
Iteration :  97   Loss :  0.0356269822943
Iteration :  98   Loss :  0.0351549933175
Iteration :  99   Loss :  0.0346932061789
[ -4.21334612e-04   1.76628500e-04  -1.57366245e-04 ...,   1.31460687e-04
  -4.49218248e-05   1.47216861e-04]
CROSS VALIDATION 30
Iteration :  0   Loss :  11.8221935034
Iteration :  1   Loss :  0.209246779389
Iteration :  2   Loss :  0.190096173556
Iteration :  3   Loss :  0.18551639293
Iteration :  4   Loss :  0.181333902531
Iteration :  5   Loss :  0.17737674844
Iteration :  6   Loss :  0.173580086373
Iteration :  7   Loss :  0.169912397377
Iteration :  8   Loss :  0.166355857421
Iteration :  9   Loss :  0.162899251193
Iteration :  10   Loss :  0.15953491527
Iteration :  11   Loss :  0.156257250979
Iteration :  12   Loss :  0.153061934448
Iteration :  13   Loss :  0.149945467627
Iteration :  14   Loss :  0.146904908983
Iteration :  15   Loss :  0.143937704685
Iteration :  16   Loss :  0.141041578895
Iteration :  17   Loss :  0.138214460282
Iteration :  18   Loss :  0.135454431619
Iteration :  19   Loss :  0.132759694557
Iteration :  20   Loss :  0.130128544697
Iteration :  21   Loss :  0.127559353848
Iteration :  22   Loss :  0.125050557405
Iteration :  23   Loss :  0.122600645459
Iteration :  24   Loss :  0.12020815665
Iteration :  25   Loss :  0.117871674048
Iteration :  26   Loss :  0.115589822511
Iteration :  27   Loss :  0.113361267081
Iteration :  28   Loss :  0.111184712091
Iteration :  29   Loss :  0.109058900654
Iteration :  30   Loss :  0.106982614334
Iteration :  31   Loss :  0.104954672779
Iteration :  32   Loss :  0.102973933174
Iteration :  33   Loss :  0.101039289397
Iteration :  34   Loss :  0.0991496708246
Iteration :  35   Loss :  0.0973040407374
Iteration :  36   Loss :  0.0955013943397
Iteration :  37   Loss :  0.0937407564352
Iteration :  38   Loss :  0.0920211788167
Iteration :  39   Loss :  0.0903417374615
Iteration :  40   Loss :  0.0887015296302
Iteration :  41   Loss :  0.0870996709799
Iteration :  42   Loss :  0.0855352927979
Iteration :  43   Loss :  0.0840075394607
Iteration :  44   Loss :  0.0825155662051
Iteration :  45   Loss :  0.0810585372864
Iteration :  46   Loss :  0.079635624572
Iteration :  47   Loss :  0.0782460065993
Iteration :  48   Loss :  0.0768888681019
Iteration :  49   Loss :  0.0755633999832
Iteration :  50   Loss :  0.0742687996992
Iteration :  51   Loss :  0.0730042719939
Iteration :  52   Loss :  0.071769029919
Iteration :  53   Loss :  0.0705622960614
Iteration :  54   Loss :  0.0693833039045
Iteration :  55   Loss :  0.0682312992459
Iteration :  56   Loss :  0.0671055416091
Iteration :  57   Loss :  0.0660053055894
Iteration :  58   Loss :  0.0649298820955
Iteration :  59   Loss :  0.0638785794533
Iteration :  60   Loss :  0.0628507243596
Iteration :  61   Loss :  0.0618456626791
Iteration :  62   Loss :  0.0608627600925
Iteration :  63   Loss :  0.0599014026083
Iteration :  64   Loss :  0.0589609969573
Iteration :  65   Loss :  0.0580409708882
Iteration :  66   Loss :  0.0571407733858
Iteration :  67   Loss :  0.0562598748256
Iteration :  68   Loss :  0.0553977670782
Iteration :  69   Loss :  0.0545539635698
Iteration :  70   Loss :  0.0537279992994
Iteration :  71   Loss :  0.0529194308074
Iteration :  72   Loss :  0.0521278360885
Iteration :  73   Loss :  0.0513528144333
Iteration :  74   Loss :  0.0505939861874
Iteration :  75   Loss :  0.0498509924101
Iteration :  76   Loss :  0.0491234944229
Iteration :  77   Loss :  0.0484111732342
Iteration :  78   Loss :  0.0477137288367
Iteration :  79   Loss :  0.0470308793764
Iteration :  80   Loss :  0.0463623601968
Iteration :  81   Loss :  0.0457079227707
Iteration :  82   Loss :  0.0450673335355
Iteration :  83   Loss :  0.0444403726523
Iteration :  84   Loss :  0.0438268327143
Iteration :  85   Loss :  0.0432265174308
Iteration :  86   Loss :  0.0426392403144
Iteration :  87   Loss :  0.0420648234001
Iteration :  88   Loss :  0.0415030960188
Iteration :  89   Loss :  0.0409538936493
Iteration :  90   Loss :  0.0404170568653
Iteration :  91   Loss :  0.0398924303885
Iteration :  92   Loss :  0.039379862256
Iteration :  93   Loss :  0.0388792031014
Iteration :  94   Loss :  0.0383903055438
Iteration :  95   Loss :  0.0379130236765
Iteration :  96   Loss :  0.0374472126385
Iteration :  97   Loss :  0.036992728253
Iteration :  98   Loss :  0.0365494267113
Iteration :  99   Loss :  0.0361171642841
[ -3.39428174e-04  -2.05706776e-04  -3.42211452e-04 ...,   8.94863765e-05
  -1.18649257e-04   1.26970593e-04]
CROSS VALIDATION 31
Iteration :  0   Loss :  7.94058658357
Iteration :  1   Loss :  0.210262135288
Iteration :  2   Loss :  0.194702286404
Iteration :  3   Loss :  0.190182747695
Iteration :  4   Loss :  0.185948389522
Iteration :  5   Loss :  0.181907139483
Iteration :  6   Loss :  0.178015246055
Iteration :  7   Loss :  0.174248412133
Iteration :  8   Loss :  0.170591595877
Iteration :  9   Loss :  0.167034681204
Iteration :  10   Loss :  0.163570397867
Iteration :  11   Loss :  0.16019322777
Iteration :  12   Loss :  0.156898788613
Iteration :  13   Loss :  0.153683466922
Iteration :  14   Loss :  0.150544189568
Iteration :  15   Loss :  0.147478276188
Iteration :  16   Loss :  0.144483340854
Iteration :  17   Loss :  0.141557224821
Iteration :  18   Loss :  0.138697949463
Iteration :  19   Loss :  0.135903682652
Iteration :  20   Loss :  0.133172714268
Iteration :  21   Loss :  0.130503437976
Iteration :  22   Loss :  0.127894337376
Iteration :  23   Loss :  0.125343975172
Iteration :  24   Loss :  0.122850984434
Iteration :  25   Loss :  0.120414061292
Iteration :  26   Loss :  0.118031958585
Iteration :  27   Loss :  0.115703480133
Iteration :  28   Loss :  0.113427475415
Iteration :  29   Loss :  0.111202834507
Iteration :  30   Loss :  0.109028483206
Iteration :  31   Loss :  0.106903378329
Iteration :  32   Loss :  0.104826503201
Iteration :  33   Loss :  0.102796863386
Iteration :  34   Loss :  0.100813482738
Iteration :  35   Loss :  0.0988753998481
Iteration :  36   Loss :  0.0969816649843
Iteration :  37   Loss :  0.0951313375919
Iteration :  38   Loss :  0.0933234844285
Iteration :  39   Loss :  0.0915571783687
Iteration :  40   Loss :  0.0898314978961
Iteration :  41   Loss :  0.0881455272648
Iteration :  42   Loss :  0.0864983572815
Iteration :  43   Loss :  0.0848890866277
Iteration :  44   Loss :  0.0833168236137
Iteration :  45   Loss :  0.0817806882356
Iteration :  46   Loss :  0.0802798143927
Iteration :  47   Loss :  0.0788133521188
Iteration :  48   Loss :  0.0773804696872
Iteration :  49   Loss :  0.075980355464
Iteration :  50   Loss :  0.0746122194061
Iteration :  51   Loss :  0.0732752941314
Iteration :  52   Loss :  0.0719688355163
Iteration :  53   Loss :  0.0706921228117
Iteration :  54   Loss :  0.0694444582952
Iteration :  55   Loss :  0.0682251665052
Iteration :  56   Loss :  0.0670335931226
Iteration :  57   Loss :  0.0658691035776
Iteration :  58   Loss :  0.0647310814682
Iteration :  59   Loss :  0.0636189268767
Iteration :  60   Loss :  0.062532054665
Iteration :  61   Loss :  0.061469892821
Iteration :  62   Loss :  0.0604318809162
Iteration :  63   Loss :  0.0594174687208
Iteration :  64   Loss :  0.0584261150062
Iteration :  65   Loss :  0.0574572865556
Iteration :  66   Loss :  0.0565104573863
Iteration :  67   Loss :  0.0555851081813
Iteration :  68   Loss :  0.0546807259169
Iteration :  69   Loss :  0.0537968036716
Iteration :  70   Loss :  0.0529328405953
Iteration :  71   Loss :  0.052088342019
Iteration :  72   Loss :  0.051262819686
Iteration :  73   Loss :  0.0504557920856
Iteration :  74   Loss :  0.0496667848742
Iteration :  75   Loss :  0.04889533137
Iteration :  76   Loss :  0.048140973109
Iteration :  77   Loss :  0.0474032604511
Iteration :  78   Loss :  0.0466817532263
Iteration :  79   Loss :  0.0459760214098
Iteration :  80   Loss :  0.0452856458149
Iteration :  81   Loss :  0.0446102187909
Iteration :  82   Loss :  0.0439493449129
Iteration :  83   Loss :  0.043302641649
Iteration :  84   Loss :  0.0426697399902
Iteration :  85   Loss :  0.0420502850289
Iteration :  86   Loss :  0.0414439364705
Iteration :  87   Loss :  0.0408503690675
Iteration :  88   Loss :  0.0402692729641
Iteration :  89   Loss :  0.0397003539419
Iteration :  90   Loss :  0.0391433335632
Iteration :  91   Loss :  0.0385979492073
Iteration :  92   Loss :  0.0380639539987
Iteration :  93   Loss :  0.0375411166333
Iteration :  94   Loss :  0.0370292211034
Iteration :  95   Loss :  0.0365280663322
Iteration :  96   Loss :  0.0360374657262
Iteration :  97   Loss :  0.0355572466549
Iteration :  98   Loss :  0.0350872498713
Iteration :  99   Loss :  0.0346273288842
[ -4.17107810e-04   1.76712783e-04  -1.61037797e-04 ...,   1.19181350e-04
  -4.37161208e-05   1.45229486e-04]
CROSS VALIDATION 32
Iteration :  0   Loss :  0.449525879571
Iteration :  1   Loss :  0.195246821582
Iteration :  2   Loss :  0.1903392871
Iteration :  3   Loss :  0.18583071443
Iteration :  4   Loss :  0.181585905524
Iteration :  5   Loss :  0.177539135504
Iteration :  6   Loss :  0.173652833364
Iteration :  7   Loss :  0.169903257571
Iteration :  8   Loss :  0.166274305327
Iteration :  9   Loss :  0.162754446575
Iteration :  10   Loss :  0.15933505628
Iteration :  11   Loss :  0.15600944233
Iteration :  12   Loss :  0.152772247666
Iteration :  13   Loss :  0.149619066342
Iteration :  14   Loss :  0.146546188006
Iteration :  15   Loss :  0.143550422592
Iteration :  16   Loss :  0.140628976857
Iteration :  17   Loss :  0.137779365426
Iteration :  18   Loss :  0.134999345373
Iteration :  19   Loss :  0.132286867253
Iteration :  20   Loss :  0.129640037835
Iteration :  21   Loss :  0.127057091342
Iteration :  22   Loss :  0.124536366957
Iteration :  23   Loss :  0.122076291008
Iteration :  24   Loss :  0.119675362713
Iteration :  25   Loss :  0.117332142626
Iteration :  26   Loss :  0.115045243197
Iteration :  27   Loss :  0.112813320953
Iteration :  28   Loss :  0.110635069972
Iteration :  29   Loss :  0.108509216383
Iteration :  30   Loss :  0.106434513713
Iteration :  31   Loss :  0.104409738935
Iteration :  32   Loss :  0.102433689151
Iteration :  33   Loss :  0.100505178838
Iteration :  34   Loss :  0.0986230376573
Iteration :  35   Loss :  0.0967861088071
Iteration :  36   Loss :  0.0949932479353
Iteration :  37   Loss :  0.0932433226175
Iteration :  38   Loss :  0.0915352124027
Iteration :  39   Loss :  0.0898678094177
Iteration :  40   Loss :  0.0882400195002
Iteration :  41   Loss :  0.0866507638093
Iteration :  42   Loss :  0.0850989808421
Iteration :  43   Loss :  0.0835836287583
Iteration :  44   Loss :  0.0821036879034
Iteration :  45   Loss :  0.0806581634038
Iteration :  46   Loss :  0.0792460877053
Iteration :  47   Loss :  0.0778665229294
Iteration :  48   Loss :  0.0765185629306
Iteration :  49   Loss :  0.0752013349586
Iteration :  50   Loss :  0.0739140008493
Iteration :  51   Loss :  0.0726557576986
Iteration :  52   Loss :  0.0714258379972
Iteration :  53   Loss :  0.0702235092354
Iteration :  54   Loss :  0.0690480730088
Iteration :  55   Loss :  0.0678988636788
Iteration :  56   Loss :  0.0667752466537
Iteration :  57   Loss :  0.0656766163703
Iteration :  58   Loss :  0.0646023940563
Iteration :  59   Loss :  0.0635520253558
Iteration :  60   Loss :  0.0625249778953
Iteration :  61   Loss :  0.0615207388576
Iteration :  62   Loss :  0.0605388126262
Iteration :  63   Loss :  0.0595787185462
Iteration :  64   Loss :  0.0586399888435
Iteration :  65   Loss :  0.0577221667297
Iteration :  66   Loss :  0.0568248047147
Iteration :  67   Loss :  0.0559474631413
Iteration :  68   Loss :  0.0550897089494
Iteration :  69   Loss :  0.0542511146758
Iteration :  70   Loss :  0.0534312576907
Iteration :  71   Loss :  0.0526297196681
Iteration :  72   Loss :  0.0518460862891
Iteration :  73   Loss :  0.0510799471679
Iteration :  74   Loss :  0.0503308959945
Iteration :  75   Loss :  0.0495985308769
Iteration :  76   Loss :  0.0488824548676
Iteration :  77   Loss :  0.0481822766503
Iteration :  78   Loss :  0.0474976113592
Iteration :  79   Loss :  0.0468280815004
Iteration :  80   Loss :  0.0461733179367
Iteration :  81   Loss :  0.0455329608997
Iteration :  82   Loss :  0.0449066609872
Iteration :  83   Loss :  0.0442940801049
Iteration :  84   Loss :  0.0436948923153
Iteration :  85   Loss :  0.0431087845571
Iteration :  86   Loss :  0.042535457205
Iteration :  87   Loss :  0.0419746244452
Iteration :  88   Loss :  0.0414260144501
Iteration :  89   Loss :  0.0408893693415
Iteration :  90   Loss :  0.0403644449401
Iteration :  91   Loss :  0.0398510103068
Iteration :  92   Loss :  0.0393488470861
Iteration :  93   Loss :  0.0388577486707
Iteration :  94   Loss :  0.0383775192059
Iteration :  95   Loss :  0.037907972462
Iteration :  96   Loss :  0.0374489305995
Iteration :  97   Loss :  0.0370002228573
Iteration :  98   Loss :  0.0365616841915
Iteration :  99   Loss :  0.0361331538957
[ -2.42635112e-04   2.84895958e-04   1.36725351e-05 ...,   1.37043497e-04
  -3.99922435e-05   1.49049589e-04]
CROSS VALIDATION 33
Iteration :  0   Loss :  8.0135807587
Iteration :  1   Loss :  0.211578434284
Iteration :  2   Loss :  0.195055921371
Iteration :  3   Loss :  0.19053697586
Iteration :  4   Loss :  0.186288291113
Iteration :  5   Loss :  0.182228934694
Iteration :  6   Loss :  0.178318461955
Iteration :  7   Loss :  0.174533678851
Iteration :  8   Loss :  0.170859905351
Iteration :  9   Loss :  0.16728711298
Iteration :  10   Loss :  0.16380801388
Iteration :  11   Loss :  0.160417033069
Iteration :  12   Loss :  0.157109718788
Iteration :  13   Loss :  0.153882386315
Iteration :  14   Loss :  0.150731893633
Iteration :  15   Loss :  0.147655495179
Iteration :  16   Loss :  0.144650743758
Iteration :  17   Loss :  0.141715423148
Iteration :  18   Loss :  0.138847500836
Iteration :  19   Loss :  0.136045094241
Iteration :  20   Loss :  0.133306446143
Iteration :  21   Loss :  0.130629906446
Iteration :  22   Loss :  0.12801391833
Iteration :  23   Loss :  0.125457007435
Iteration :  24   Loss :  0.122957773113
Iteration :  25   Loss :  0.12051488108
Iteration :  26   Loss :  0.118127056979
Iteration :  27   Loss :  0.115793080545
Iteration :  28   Loss :  0.113511780132
Iteration :  29   Loss :  0.111282027503
Iteration :  30   Loss :  0.109102732808
Iteration :  31   Loss :  0.106972839739
Iteration :  32   Loss :  0.104891320905
Iteration :  33   Loss :  0.102857173465
Iteration :  34   Loss :  0.100869415099
Iteration :  35   Loss :  0.0989270803829
Iteration :  36   Loss :  0.0970292176424
Iteration :  37   Loss :  0.0951748863519
Iteration :  38   Loss :  0.0933631551198
Iteration :  39   Loss :  0.091593100294
Iteration :  40   Loss :  0.0898638051911
Iteration :  41   Loss :  0.0881743599325
Iteration :  42   Loss :  0.0865238618447
Iteration :  43   Loss :  0.0849114163582
Iteration :  44   Loss :  0.0833361383183
Iteration :  45   Loss :  0.0817971536061
Iteration :  46   Loss :  0.0802936009567
Iteration :  47   Loss :  0.0788246338563
Iteration :  48   Loss :  0.0773894224027
Iteration :  49   Loss :  0.0759871550216
Iteration :  50   Loss :  0.0746170399468
Iteration :  51   Loss :  0.0732783063877
Iteration :  52   Loss :  0.0719702053345
Iteration :  53   Loss :  0.0706920099694
Iteration :  54   Loss :  0.0694430156808
Iteration :  55   Loss :  0.068222539695
Iteration :  56   Loss :  0.0670299203603
Iteration :  57   Loss :  0.0658645161349
Iteration :  58   Loss :  0.0647257043366
Iteration :  59   Loss :  0.0636128797235
Iteration :  60   Loss :  0.062525452972
Iteration :  61   Loss :  0.0614628491205
Iteration :  62   Loss :  0.0604245060384
Iteration :  63   Loss :  0.0594098729761
Iteration :  64   Loss :  0.0584184092383
Iteration :  65   Loss :  0.0574495830156
Iteration :  66   Loss :  0.0565028703978
Iteration :  67   Loss :  0.0555777545808
Iteration :  68   Loss :  0.0546737252733
Iteration :  69   Loss :  0.0537902782966
Iteration :  70   Loss :  0.0529269153703
Iteration :  71   Loss :  0.0520831440673
Iteration :  72   Loss :  0.0512584779233
Iteration :  73   Loss :  0.0504524366792
Iteration :  74   Loss :  0.0496645466416
Iteration :  75   Loss :  0.0488943411402
Iteration :  76   Loss :  0.0481413610676
Iteration :  77   Loss :  0.0474051554842
Iteration :  78   Loss :  0.0466852822742
Iteration :  79   Loss :  0.0459813088382
Iteration :  80   Loss :  0.0452928128084
Iteration :  81   Loss :  0.0446193827713
Iteration :  82   Loss :  0.0439606189843
Iteration :  83   Loss :  0.0433161340699
Iteration :  84   Loss :  0.0426855536736
Iteration :  85   Loss :  0.0420685170685
Iteration :  86   Loss :  0.0414646776949
Iteration :  87   Loss :  0.0408737036189
Iteration :  88   Loss :  0.0402952779018
Iteration :  89   Loss :  0.0397290988701
Iteration :  90   Loss :  0.0391748802802
Iteration :  91   Loss :  0.0386323513767
Iteration :  92   Loss :  0.0381012568426
Iteration :  93   Loss :  0.0375813566461
Iteration :  94   Loss :  0.0370724257893
Iteration :  95   Loss :  0.0365742539682
Iteration :  96   Loss :  0.036086645152
Iteration :  97   Loss :  0.0356094170962
Iteration :  98   Loss :  0.0351424007988
Iteration :  99   Loss :  0.0346854399151
[ -4.16119740e-04   1.77838489e-04  -1.60718425e-04 ...,   1.28080934e-04
  -4.10490101e-05   1.48368147e-04]
CROSS VALIDATION 34
Iteration :  0   Loss :  12.2072559098
Iteration :  1   Loss :  0.193069166484
Iteration :  2   Loss :  0.187823368655
Iteration :  3   Loss :  0.183365278494
Iteration :  4   Loss :  0.179243373796
Iteration :  5   Loss :  0.17532976298
Iteration :  6   Loss :  0.171570069216
Iteration :  7   Loss :  0.167936065202
Iteration :  8   Loss :  0.164411081929
Iteration :  9   Loss :  0.160984303361
Iteration :  10   Loss :  0.157648174631
Iteration :  11   Loss :  0.15439709388
Iteration :  12   Loss :  0.15122669784
Iteration :  13   Loss :  0.148133446868
Iteration :  14   Loss :  0.14511437164
Iteration :  15   Loss :  0.142166912058
Iteration :  16   Loss :  0.13928881118
Iteration :  17   Loss :  0.136478043272
Iteration :  18   Loss :  0.13373276367
Iteration :  19   Loss :  0.131051272996
Iteration :  20   Loss :  0.128431990993
Iteration :  21   Loss :  0.125873436948
Iteration :  22   Loss :  0.123374214676
Iteration :  23   Loss :  0.120933000698
Iteration :  24   Loss :  0.11854853467
Iteration :  25   Loss :  0.116219611409
Iteration :  26   Loss :  0.113945074066
Iteration :  27   Loss :  0.111723808102
Iteration :  28   Loss :  0.109554735875
Iteration :  29   Loss :  0.107436811656
Iteration :  30   Loss :  0.105369016992
Iteration :  31   Loss :  0.103350356356
Iteration :  32   Loss :  0.101379853039
Iteration :  33   Loss :  0.0994565452904
Iteration :  34   Loss :  0.0975794827021
Iteration :  35   Loss :  0.0957477228552
Iteration :  36   Loss :  0.0939603282583
Iteration :  37   Loss :  0.0922163636022
Iteration :  38   Loss :  0.0905148933631
Iteration :  39   Loss :  0.0888549797838
Iteration :  40   Loss :  0.0872356812606
Iteration :  41   Loss :  0.0856560511566
Iteration :  42   Loss :  0.084115137061
Iteration :  43   Loss :  0.0826119805016
Iteration :  44   Loss :  0.081145617117
Iteration :  45   Loss :  0.0797150772845
Iteration :  46   Loss :  0.078319387195
Iteration :  47   Loss :  0.0769575703602
Iteration :  48   Loss :  0.0756286495319
Iteration :  49   Loss :  0.0743316490093
Iteration :  50   Loss :  0.0730655972991
Iteration :  51   Loss :  0.0718295300921
Iteration :  52   Loss :  0.0706224935049
Iteration :  53   Loss :  0.0694435475273
Iteration :  54   Loss :  0.0682917696038
Iteration :  55   Loss :  0.0671662582625
Iteration :  56   Loss :  0.0660661366975
Iteration :  57   Loss :  0.0649905561989
Iteration :  58   Loss :  0.0639386993243
Iteration :  59   Loss :  0.0629097827081
Iteration :  60   Loss :  0.0619030594134
Iteration :  61   Loss :  0.0609178207528
Iteration :  62   Loss :  0.059953397524
Iteration :  63   Loss :  0.0590091606365
Iteration :  64   Loss :  0.0580845211361
Iteration :  65   Loss :  0.0571789296598
Iteration :  66   Loss :  0.0562918753846
Iteration :  67   Loss :  0.0554228845477
Iteration :  68   Loss :  0.0545715186342
Iteration :  69   Loss :  0.0537373723277
Iteration :  70   Loss :  0.052920071322
Iteration :  71   Loss :  0.0521192700781
Iteration :  72   Loss :  0.0513346495994
Iteration :  73   Loss :  0.050565915281
Iteration :  74   Loss :  0.0498127948669
Iteration :  75   Loss :  0.0490750365374
Iteration :  76   Loss :  0.048352407127
Iteration :  77   Loss :  0.0476446904648
Iteration :  78   Loss :  0.0469516858188
Iteration :  79   Loss :  0.0462732064195
Iteration :  80   Loss :  0.0456090780389
Iteration :  81   Loss :  0.0449591375979
Iteration :  82   Loss :  0.0443232317822
Iteration :  83   Loss :  0.0437012156505
Iteration :  84   Loss :  0.0430929512243
Iteration :  85   Loss :  0.0424983060551
Iteration :  86   Loss :  0.041917151773
Iteration :  87   Loss :  0.0413493626244
Iteration :  88   Loss :  0.0407948140127
Iteration :  89   Loss :  0.0402533810611
Iteration :  90   Loss :  0.0397249372189
Iteration :  91   Loss :  0.039209352935
Iteration :  92   Loss :  0.0387064944244
Iteration :  93   Loss :  0.0382162225517
Iteration :  94   Loss :  0.0377383918557
Iteration :  95   Loss :  0.0372728497364
Iteration :  96   Loss :  0.0368194358205
Iteration :  97   Loss :  0.0363779815184
Iteration :  98   Loss :  0.0359483097782
Iteration :  99   Loss :  0.0355302350374
[ -2.65067140e-04  -6.96493434e-06  -3.67093079e-04 ...,   1.96548443e-04
  -8.91883080e-05   1.52238080e-04]
CROSS VALIDATION 35
Iteration :  0   Loss :  11.5391141899
Iteration :  1   Loss :  0.223855103471
Iteration :  2   Loss :  0.210614389145
Iteration :  3   Loss :  0.205930907607
Iteration :  4   Loss :  0.201498773535
Iteration :  5   Loss :  0.197232743396
Iteration :  6   Loss :  0.193097919807
Iteration :  7   Loss :  0.18907649977
Iteration :  8   Loss :  0.185157956044
Iteration :  9   Loss :  0.181335335356
Iteration :  10   Loss :  0.177603627467
Iteration :  11   Loss :  0.173958962631
Iteration :  12   Loss :  0.170398182187
Iteration :  13   Loss :  0.166918592994
Iteration :  14   Loss :  0.163517819127
Iteration :  15   Loss :  0.160193708125
Iteration :  16   Loss :  0.156944269451
Iteration :  17   Loss :  0.153767632822
Iteration :  18   Loss :  0.150662019379
Iteration :  19   Loss :  0.14762572147
Iteration :  20   Loss :  0.144657088481
Iteration :  21   Loss :  0.141754517055
Iteration :  22   Loss :  0.138916444604
Iteration :  23   Loss :  0.136141345345
Iteration :  24   Loss :  0.13342772829
Iteration :  25   Loss :  0.130774136718
Iteration :  26   Loss :  0.128179148761
Iteration :  27   Loss :  0.125641378742
Iteration :  28   Loss :  0.123159478987
Iteration :  29   Loss :  0.120732141825
Iteration :  30   Loss :  0.118358101545
Iteration :  31   Loss :  0.116036136133
Iteration :  32   Loss :  0.113765068617
Iteration :  33   Loss :  0.111543767925
Iteration :  34   Loss :  0.109371149202
Iteration :  35   Loss :  0.107246173536
Iteration :  36   Loss :  0.105167847135
Iteration :  37   Loss :  0.103135219972
Iteration :  38   Loss :  0.101147383968
Iteration :  39   Loss :  0.0992034707765
Iteration :  40   Loss :  0.0973026492619
Iteration :  41   Loss :  0.0954441227266
Iteration :  42   Loss :  0.0936271259793
Iteration :  43   Loss :  0.0918509222992
Iteration :  44   Loss :  0.0901148003562
Iteration :  45   Loss :  0.088418071136
Iteration :  46   Loss :  0.0867600649124
Iteration :  47   Loss :  0.0851401283013
Iteration :  48   Loss :  0.0835576214291
Iteration :  49   Loss :  0.0820119152452
Iteration :  50   Loss :  0.0805023890054
Iteration :  51   Loss :  0.0790284279548
Iteration :  52   Loss :  0.0775894212369
Iteration :  53   Loss :  0.076184760056
Iteration :  54   Loss :  0.0748138361183
Iteration :  55   Loss :  0.0734760403749
Iteration :  56   Loss :  0.072170762086
Iteration :  57   Loss :  0.0708973882186
Iteration :  58   Loss :  0.0696553031856
Iteration :  59   Loss :  0.0684438889218
Iteration :  60   Loss :  0.0672625252847
Iteration :  61   Loss :  0.0661105907574
Iteration :  62   Loss :  0.0649874634174
Iteration :  63   Loss :  0.0638925221294
Iteration :  64   Loss :  0.0628251479049
Iteration :  65   Loss :  0.0617847253712
Iteration :  66   Loss :  0.0607706442803
Iteration :  67   Loss :  0.0597823009916
Iteration :  68   Loss :  0.0588190998604
Iteration :  69   Loss :  0.0578804544684
Iteration :  70   Loss :  0.0569657886394
Iteration :  71   Loss :  0.0560745371949
Iteration :  72   Loss :  0.0552061464127
Iteration :  73   Loss :  0.0543600741692
Iteration :  74   Loss :  0.0535357897582
Iteration :  75   Loss :  0.0527327733965
Iteration :  76   Loss :  0.0519505154406
Iteration :  77   Loss :  0.0511885153554
Iteration :  78   Loss :  0.0504462804875
Iteration :  79   Loss :  0.0497233247075
Iteration :  80   Loss :  0.0490191669967
Iteration :  81   Loss :  0.0483333300557
Iteration :  82   Loss :  0.0476653390173
Iteration :  83   Loss :  0.0470147203416
Iteration :  84   Loss :  0.0463810009671
Iteration :  85   Loss :  0.0457637077776
Iteration :  86   Loss :  0.0451623674328
Iteration :  87   Loss :  0.0445765065911
Iteration :  88   Loss :  0.0440056525328
Iteration :  89   Loss :  0.0434493341729
Iteration :  90   Loss :  0.0429070834286
Iteration :  91   Loss :  0.0423784368932
Iteration :  92   Loss :  0.0418629377478
Iteration :  93   Loss :  0.0413601378345
Iteration :  94   Loss :  0.0408695998065
Iteration :  95   Loss :  0.0403908992707
Iteration :  96   Loss :  0.0399236268402
Iteration :  97   Loss :  0.0394673900222
Iteration :  98   Loss :  0.0390218148768
Iteration :  99   Loss :  0.0385865473966
[ -4.52450034e-04  -1.09130622e-04  -3.49365835e-04 ...,   6.93241156e-05
  -5.00218604e-05   1.46751390e-04]
CROSS VALIDATION 36
Iteration :  0   Loss :  8.01099697842
Iteration :  1   Loss :  0.211557755833
Iteration :  2   Loss :  0.195056924644
Iteration :  3   Loss :  0.190537839978
Iteration :  4   Loss :  0.186289107367
Iteration :  5   Loss :  0.182229743069
Iteration :  6   Loss :  0.178319288889
Iteration :  7   Loss :  0.174534545521
Iteration :  8   Loss :  0.170860830196
Iteration :  9   Loss :  0.167288112774
Iteration :  10   Loss :  0.163809104345
Iteration :  11   Loss :  0.160418229312
Iteration :  12   Loss :  0.157111035663
Iteration :  13   Loss :  0.153883838747
Iteration :  14   Loss :  0.150733496915
Iteration :  15   Loss :  0.147657265269
Iteration :  16   Loss :  0.144652697563
Iteration :  17   Loss :  0.141717578816
Iteration :  18   Loss :  0.13884987804
Iteration :  19   Loss :  0.136047714476
Iteration :  20   Loss :  0.133309333015
Iteration :  21   Loss :  0.130633085965
Iteration :  22   Loss :  0.128017419199
Iteration :  23   Loss :  0.125460861334
Iteration :  24   Loss :  0.122962014976
Iteration :  25   Loss :  0.120519549361
Iteration :  26   Loss :  0.11813219391
Iteration :  27   Loss :  0.115798732371
Iteration :  28   Loss :  0.113517997337
Iteration :  29   Loss :  0.111288865013
Iteration :  30   Loss :  0.109110250173
Iteration :  31   Loss :  0.106981101298
Iteration :  32   Loss :  0.10490039592
Iteration :  33   Loss :  0.102867136234
Iteration :  34   Loss :  0.100880345035
Iteration :  35   Loss :  0.0989390620617
Iteration :  36   Loss :  0.0970423408109
Iteration :  37   Loss :  0.0951892458926
Iteration :  38   Loss :  0.0933788509643
Iteration :  39   Loss :  0.0916102372764
Iteration :  40   Loss :  0.089882492833
Iteration :  41   Loss :  0.0881947121494
Iteration :  42   Loss :  0.0865459965623
Iteration :  43   Loss :  0.0849354550271
Iteration :  44   Loss :  0.0833622053167
Iteration :  45   Loss :  0.081825375518
Iteration :  46   Loss :  0.0803241057169
Iteration :  47   Loss :  0.0788575497519
Iteration :  48   Loss :  0.0774248769256
Iteration :  49   Loss :  0.0760252735678
Iteration :  50   Loss :  0.0746579443606
Iteration :  51   Loss :  0.073322113355
Iteration :  52   Loss :  0.0720170246319
Iteration :  53   Loss :  0.0707419425813
Iteration :  54   Loss :  0.0694961518023
Iteration :  55   Loss :  0.0682789566432
Iteration :  56   Loss :  0.067089680424
Iteration :  57   Loss :  0.0659276643962
Iteration :  58   Loss :  0.0647922665071
Iteration :  59   Loss :  0.0636828600399
Iteration :  60   Loss :  0.0625988322036
Iteration :  61   Loss :  0.0615395827431
Iteration :  62   Loss :  0.0605045226341
Iteration :  63   Loss :  0.0594930729173
Iteration :  64   Loss :  0.0585046637155
Iteration :  65   Loss :  0.0575387334653
Iteration :  66   Loss :  0.0565947283791
Iteration :  67   Loss :  0.0556721021448
Iteration :  68   Loss :  0.0547703158542
Iteration :  69   Loss :  0.0538888381436
Iteration :  70   Loss :  0.0530271455199
Iteration :  71   Loss :  0.052184722842
Iteration :  72   Loss :  0.0513610639201
Iteration :  73   Loss :  0.0505556721986
Iteration :  74   Loss :  0.0497680614839
Iteration :  75   Loss :  0.0489977566881
Iteration :  76   Loss :  0.0482442945558
Iteration :  77   Loss :  0.0475072243535
Iteration :  78   Loss :  0.0467861085011
Iteration :  79   Loss :  0.0460805231327
Iteration :  80   Loss :  0.0453900585789
Iteration :  81   Loss :  0.0447143197657
Iteration :  82   Loss :  0.0440529265295
Iteration :  83   Loss :  0.0434055138491
Iteration :  84   Loss :  0.0427717319993
Iteration :  85   Loss :  0.0421512466288
Iteration :  86   Loss :  0.0415437387685
Iteration :  87   Loss :  0.0409489047745
Iteration :  88   Loss :  0.0403664562098
Iteration :  89   Loss :  0.0397961196705
Iteration :  90   Loss :  0.0392376365598
Iteration :  91   Loss :  0.0386907628126
Iteration :  92   Loss :  0.0381552685773
Iteration :  93   Loss :  0.0376309378547
Iteration :  94   Loss :  0.0371175681019
Iteration :  95   Loss :  0.0366149698018
Iteration :  96   Loss :  0.0361229660043
Iteration :  97   Loss :  0.0356413918438
Iteration :  98   Loss :  0.035170094037
Iteration :  99   Loss :  0.0347089303664
[ -4.20820868e-04   1.75994295e-04  -1.58341952e-04 ...,   1.30620093e-04
  -4.45161157e-05   1.47424748e-04]
CROSS VALIDATION 37
Iteration :  0   Loss :  8.01135129475
Iteration :  1   Loss :  0.211564784276
Iteration :  2   Loss :  0.195056298407
Iteration :  3   Loss :  0.190537633104
Iteration :  4   Loss :  0.186289111403
Iteration :  5   Loss :  0.182229868875
Iteration :  6   Loss :  0.178319492095
Iteration :  7   Loss :  0.174534801958
Iteration :  8   Loss :  0.170861126033
Iteration :  9   Loss :  0.167288439995
Iteration :  10   Loss :  0.163809458478
Iteration :  11   Loss :  0.1604186082
Iteration :  12   Loss :  0.157111438767
Iteration :  13   Loss :  0.153884266737
Iteration :  14   Loss :  0.15073395143
Iteration :  15   Loss :  0.147657748773
Iteration :  16   Loss :  0.144653213275
Iteration :  17   Loss :  0.141718130676
Iteration :  18   Loss :  0.138850470712
Iteration :  19   Loss :  0.136048353376
Iteration :  20   Loss :  0.133310024357
Iteration :  21   Loss :  0.130633836829
Iteration :  22   Loss :  0.128018237607
Iteration :  23   Loss :  0.125461756345
Iteration :  24   Loss :  0.122962996792
Iteration :  25   Loss :  0.120520629442
Iteration :  26   Loss :  0.118133385103
Iteration :  27   Loss :  0.115800049043
Iteration :  28   Loss :  0.113519455524
Iteration :  29   Loss :  0.111290482575
Iteration :  30   Loss :  0.109112046955
Iteration :  31   Loss :  0.106983099301
Iteration :  32   Loss :  0.104902619478
Iteration :  33   Loss :  0.102869612199
Iteration :  34   Loss :  0.100883102968
Iteration :  35   Loss :  0.0989421344289
Iteration :  36   Loss :  0.0970457631868
Iteration :  37   Loss :  0.0951930571669
Iteration :  38   Loss :  0.0933830935526
Iteration :  39   Loss :  0.0916149573336
Iteration :  40   Loss :  0.0898877404682
Iteration :  41   Loss :  0.0882005416394
Iteration :  42   Loss :  0.0865524665626
Iteration :  43   Loss :  0.0849426287773
Iteration :  44   Loss :  0.0833701508365
Iteration :  45   Loss :  0.0818341657911
Iteration :  46   Loss :  0.080333818857
Iteration :  47   Loss :  0.0788682691474
Iteration :  48   Loss :  0.077436691356
Iteration :  49   Loss :  0.0760382772861
Iteration :  50   Loss :  0.0746722371358
Iteration :  51   Loss :  0.0733378004666
Iteration :  52   Loss :  0.0720342168086
Iteration :  53   Loss :  0.0707607558779
Iteration :  54   Loss :  0.0695167074049
Iteration :  55   Loss :  0.0683013805963
Iteration :  56   Loss :  0.0671141032716
Iteration :  57   Loss :  0.0659542207299
Iteration :  58   Loss :  0.0648210944148
Iteration :  59   Loss :  0.0637141004499
Iteration :  60   Loss :  0.0626326281205
Iteration :  61   Loss :  0.0615760783728
Iteration :  62   Loss :  0.0605438623973
Iteration :  63   Loss :  0.0595354003538
Iteration :  64   Loss :  0.0585501202834
Iteration :  65   Loss :  0.0575874572419
Iteration :  66   Loss :  0.0566468526748
Iteration :  67   Loss :  0.0557277540429
Iteration :  68   Loss :  0.0548296146934
Iteration :  69   Loss :  0.0539518939642
Iteration :  70   Loss :  0.0530940574975
Iteration :  71   Loss :  0.052255577735
Iteration :  72   Loss :  0.0514359345607
Iteration :  73   Loss :  0.0506346160581
Iteration :  74   Loss :  0.0498511193466
Iteration :  75   Loss :  0.0490849514646
Iteration :  76   Loss :  0.0483356302694
Iteration :  77   Loss :  0.0476026853297
Iteration :  78   Loss :  0.0468856587866
Iteration :  79   Loss :  0.0461841061687
Iteration :  80   Loss :  0.0454975971449
Iteration :  81   Loss :  0.0448257162065
Iteration :  82   Loss :  0.0441680632698
Iteration :  83   Loss :  0.0435242541943
Iteration :  84   Loss :  0.0428939212121
Iteration :  85   Loss :  0.0422767132661
Iteration :  86   Loss :  0.0416722962546
Iteration :  87   Loss :  0.041080353182
Iteration :  88   Loss :  0.040500584215
Iteration :  89   Loss :  0.0399327066452
Iteration :  90   Loss :  0.0393764547585
Iteration :  91   Loss :  0.0388315796165
Iteration :  92   Loss :  0.0382978487499
Iteration :  93   Loss :  0.0377750457719
Iteration :  94   Loss :  0.0372629699153
Iteration :  95   Loss :  0.0367614355018
Iteration :  96   Loss :  0.0362702713496
Iteration :  97   Loss :  0.0357893201299
Iteration :  98   Loss :  0.0353184376795
Iteration :  99   Loss :  0.0348574922816
[ -4.20762630e-04   1.75248716e-04  -1.58957810e-04 ...,   1.30193490e-04
  -4.33675118e-05   1.47916059e-04]
CROSS VALIDATION 38
Iteration :  0   Loss :  11.8507778301
Iteration :  1   Loss :  0.210637816737
Iteration :  2   Loss :  0.197953809146
Iteration :  3   Loss :  0.193137667421
Iteration :  4   Loss :  0.188736356713
Iteration :  5   Loss :  0.184580110879
Iteration :  6   Loss :  0.18060020075
Iteration :  7   Loss :  0.176761681934
Iteration :  8   Loss :  0.173044162043
Iteration :  9   Loss :  0.169434533172
Iteration :  10   Loss :  0.165923725675
Iteration :  11   Loss :  0.16250508238
Iteration :  12   Loss :  0.159173472635
Iteration :  13   Loss :  0.155924776865
Iteration :  14   Loss :  0.152755570429
Iteration :  15   Loss :  0.149662921087
Iteration :  16   Loss :  0.146644254389
Iteration :  17   Loss :  0.143697261389
Iteration :  18   Loss :  0.14081983368
Iteration :  19   Loss :  0.138010016672
Iteration :  20   Loss :  0.135265975424
Iteration :  21   Loss :  0.132585969343
Iteration :  22   Loss :  0.129968333345
Iteration :  23   Loss :  0.127411463809
Iteration :  24   Loss :  0.124913808173
Iteration :  25   Loss :  0.122473857333
Iteration :  26   Loss :  0.120090140198
Iteration :  27   Loss :  0.117761219931
Iteration :  28   Loss :  0.11548569146
Iteration :  29   Loss :  0.113262179938
Iteration :  30   Loss :  0.11108933989
Iteration :  31   Loss :  0.108965854812
Iteration :  32   Loss :  0.106890437051
Iteration :  33   Loss :  0.104861827839
Iteration :  34   Loss :  0.102878797379
Iteration :  35   Loss :  0.100940144931
Iteration :  36   Loss :  0.099044698893
Iteration :  37   Loss :  0.0971913168669
Iteration :  38   Loss :  0.0953788857531
Iteration :  39   Loss :  0.093606321903
Iteration :  40   Loss :  0.0918725713692
Iteration :  41   Loss :  0.090176610281
Iteration :  42   Loss :  0.0885174453546
Iteration :  43   Loss :  0.0868941145291
Iteration :  44   Loss :  0.0853056876951
Iteration :  45   Loss :  0.0837512674637
Iteration :  46   Loss :  0.0822299899107
Iteration :  47   Loss :  0.0807410252208
Iteration :  48   Loss :  0.0792835781589
Iteration :  49   Loss :  0.0778568883037
Iteration :  50   Loss :  0.0764602299927
Iteration :  51   Loss :  0.0750929119463
Iteration :  52   Loss :  0.0737542765594
Iteration :  53   Loss :  0.0724436988678
Iteration :  54   Loss :  0.0711605852156
Iteration :  55   Loss :  0.0699043716614
Iteration :  56   Loss :  0.0686745221716
Iteration :  57   Loss :  0.067470526654
Iteration :  58   Loss :  0.0662918988832
Iteration :  59   Loss :  0.0651381743714
Iteration :  60   Loss :  0.0640089082282
Iteration :  61   Loss :  0.062903673051
Iteration :  62   Loss :  0.0618220568786
Iteration :  63   Loss :  0.0607636612331
Iteration :  64   Loss :  0.0597280992715
Iteration :  65   Loss :  0.0587149940591
Iteration :  66   Loss :  0.057723976974
Iteration :  67   Loss :  0.0567546862474
Iteration :  68   Loss :  0.0558067656422
Iteration :  69   Loss :  0.0548798632679
Iteration :  70   Loss :  0.0539736305316
Iteration :  71   Loss :  0.0530877212207
Iteration :  72   Loss :  0.0522217907175
Iteration :  73   Loss :  0.0513754953403
Iteration :  74   Loss :  0.0505484918109
Iteration :  75   Loss :  0.0497404368475
Iteration :  76   Loss :  0.0489509868805
Iteration :  77   Loss :  0.0481797978935
Iteration :  78   Loss :  0.0474265253867
Iteration :  79   Loss :  0.046690824464
Iteration :  80   Loss :  0.0459723500413
Iteration :  81   Loss :  0.0452707571746
Iteration :  82   Loss :  0.0445857015029
Iteration :  83   Loss :  0.0439168398009
Iteration :  84   Loss :  0.0432638306326
Iteration :  85   Loss :  0.0426263350957
Iteration :  86   Loss :  0.0420040176434
Iteration :  87   Loss :  0.0413965469684
Iteration :  88   Loss :  0.0408035969306
Iteration :  89   Loss :  0.0402248475091
Iteration :  90   Loss :  0.0396599857558
Iteration :  91   Loss :  0.0391087067298
Iteration :  92   Loss :  0.0385707143859
Iteration :  93   Loss :  0.0380457223969
Iteration :  94   Loss :  0.0375334548855
Iteration :  95   Loss :  0.0370336470443
Iteration :  96   Loss :  0.0365460456268
Iteration :  97   Loss :  0.0360704092916
Iteration :  98   Loss :  0.0356065087894
Iteration :  99   Loss :  0.035154126983
[ -3.39247642e-04   8.92794328e-05   1.02677376e-06 ...,   2.20808311e-04
   1.40319140e-05   1.82546807e-04]
CROSS VALIDATION 39
Iteration :  0   Loss :  8.00816702322
Iteration :  1   Loss :  0.211518067202
Iteration :  2   Loss :  0.195074360086
Iteration :  3   Loss :  0.190551639265
Iteration :  4   Loss :  0.18630098097
Iteration :  5   Loss :  0.182240420241
Iteration :  6   Loss :  0.178329131719
Iteration :  7   Loss :  0.17454375166
Iteration :  8   Loss :  0.170869514168
Iteration :  9   Loss :  0.167296343128
Iteration :  10   Loss :  0.163816922316
Iteration :  11   Loss :  0.160425658888
Iteration :  12   Loss :  0.157118089318
Iteration :  13   Loss :  0.153890520855
Iteration :  14   Loss :  0.150739805842
Iteration :  15   Loss :  0.147663194673
Iteration :  16   Loss :  0.144658237207
Iteration :  17   Loss :  0.141722715055
Iteration :  18   Loss :  0.138854594089
Iteration :  19   Loss :  0.136051990519
Iteration :  20   Loss :  0.133313146199
Iteration :  21   Loss :  0.130636410303
Iteration :  22   Loss :  0.128020225405
Iteration :  23   Loss :  0.1254631166
Iteration :  24   Loss :  0.122963682711
Iteration :  25   Loss :  0.120520588897
Iteration :  26   Loss :  0.118132560184
Iteration :  27   Loss :  0.115798375599
Iteration :  28   Loss :  0.11351686268
Iteration :  29   Loss :  0.111286892253
Iteration :  30   Loss :  0.109107373394
Iteration :  31   Loss :  0.106977248592
Iteration :  32   Loss :  0.104895489116
Iteration :  33   Loss :  0.102861090664
Iteration :  34   Loss :  0.100873069337
Iteration :  35   Loss :  0.0989304580351
Iteration :  36   Loss :  0.0970323033282
Iteration :  37   Loss :  0.0951776628757
Iteration :  38   Loss :  0.0933656034369
Iteration :  39   Loss :  0.0915951995023
Iteration :  40   Loss :  0.0898655325511
Iteration :  41   Loss :  0.0881756909168
Iteration :  42   Loss :  0.0865247702185
Iteration :  43   Loss :  0.0849118742922
Iteration :  44   Loss :  0.0833361165347
Iteration :  45   Loss :  0.0817966215602
Iteration :  46   Loss :  0.0802925270533
Iteration :  47   Loss :  0.0788229857036
Iteration :  48   Loss :  0.077387167103
Iteration :  49   Loss :  0.0759842595
Iteration :  50   Loss :  0.0746134713151
Iteration :  51   Loss :  0.0732740323422
Iteration :  52   Loss :  0.0719651945816
Iteration :  53   Loss :  0.0706862326728
Iteration :  54   Loss :  0.0694364439188
Iteration :  55   Loss :  0.068215147915
Iteration :  56   Loss :  0.0670216858147
Iteration :  57   Loss :  0.0658554192785
Iteration :  58   Loss :  0.0647157291655
Iteration :  59   Loss :  0.0636020140339
Iteration :  60   Loss :  0.0625136885186
Iteration :  61   Loss :  0.0614501816564
Iteration :  62   Loss :  0.0604109352228
Iteration :  63   Loss :  0.0593954021418
Iteration :  64   Loss :  0.0584030450173
Iteration :  65   Loss :  0.0574333348314
Iteration :  66   Loss :  0.0564857498376
Iteration :  67   Loss :  0.0555597746725
Iteration :  68   Loss :  0.0546548996948
Iteration :  69   Loss :  0.0537706205536
Iteration :  70   Loss :  0.0529064379773
Iteration :  71   Loss :  0.0520618577699
Iteration :  72   Loss :  0.0512363909938
Iteration :  73   Loss :  0.0504295543155
Iteration :  74   Loss :  0.0496408704889
Iteration :  75   Loss :  0.0488698689491
Iteration :  76   Loss :  0.0481160864919
Iteration :  77   Loss :  0.0473790680141
Iteration :  78   Loss :  0.0466583672927
Iteration :  79   Loss :  0.0459535477827
Iteration :  80   Loss :  0.0452641834163
Iteration :  81   Loss :  0.044589859388
Iteration :  82   Loss :  0.043930172911
Iteration :  83   Loss :  0.0432847339335
Iteration :  84   Loss :  0.042653165804
Iteration :  85   Loss :  0.0420351058739
Iteration :  86   Loss :  0.0414302060303
Iteration :  87   Loss :  0.0408381331495
Iteration :  88   Loss :  0.0402585694648
Iteration :  89   Loss :  0.0396912128418
Iteration :  90   Loss :  0.0391357769581
Iteration :  91   Loss :  0.0385919913839
Iteration :  92   Loss :  0.0380596015625
Iteration :  93   Loss :  0.0375383686924
Iteration :  94   Loss :  0.0370280695134
Iteration :  95   Loss :  0.0365284960016
Iteration :  96   Loss :  0.0360394549814
Iteration :  97   Loss :  0.0355607676602
Iteration :  98   Loss :  0.035092269098
Iteration :  99   Loss :  0.0346338076211
[ -4.20090077e-04   1.73511049e-04  -1.58899098e-04 ...,   1.25747443e-04
  -4.54811989e-05   1.47039930e-04]
CROSS VALIDATION 40
Iteration :  0   Loss :  8.00595083801
Iteration :  1   Loss :  0.210959203599
Iteration :  2   Loss :  0.194532319136
Iteration :  3   Loss :  0.19003141638
Iteration :  4   Loss :  0.185798456349
Iteration :  5   Loss :  0.181752505171
Iteration :  6   Loss :  0.177853458625
Iteration :  7   Loss :  0.174078468466
Iteration :  8   Loss :  0.170413148185
Iteration :  9   Loss :  0.166847708462
Iteration :  10   Loss :  0.163375054979
Iteration :  11   Loss :  0.15998977008
Iteration :  12   Loss :  0.156687530988
Iteration :  13   Loss :  0.153464759785
Iteration :  14   Loss :  0.150318403798
Iteration :  15   Loss :  0.147245792969
Iteration :  16   Loss :  0.14424454454
Iteration :  17   Loss :  0.141312497805
Iteration :  18   Loss :  0.138447668519
Iteration :  19   Loss :  0.135648216447
Iteration :  20   Loss :  0.132912421837
Iteration :  21   Loss :  0.130238668025
Iteration :  22   Loss :  0.127625428271
Iteration :  23   Loss :  0.12507125549
Iteration :  24   Loss :  0.12257477396
Iteration :  25   Loss :  0.120134672342
Iteration :  26   Loss :  0.117749697534
Iteration :  27   Loss :  0.115418649075
Iteration :  28   Loss :  0.113140373855
Iteration :  29   Loss :  0.110913761039
Iteration :  30   Loss :  0.108737737141
Iteration :  31   Loss :  0.106611261237
Iteration :  32   Loss :  0.104533320367
Iteration :  33   Loss :  0.102502925166
Iteration :  34   Loss :  0.100519105819
Iteration :  35   Loss :  0.0985809083948
Iteration :  36   Loss :  0.096687391657
Iteration :  37   Loss :  0.0948376244088
Iteration :  38   Loss :  0.0930306834271
Iteration :  39   Loss :  0.0912656520192
Iteration :  40   Loss :  0.0895416192122
Iteration :  41   Loss :  0.0878576795612
Iteration :  42   Loss :  0.0862129335335
Iteration :  43   Loss :  0.0846064884057
Iteration :  44   Loss :  0.0830374595862
Iteration :  45   Loss :  0.0815049722576
Iteration :  46   Loss :  0.080008163222
Iteration :  47   Loss :  0.0785461828259
Iteration :  48   Loss :  0.0771181968425
Iteration :  49   Loss :  0.0757233881978
Iteration :  50   Loss :  0.0743609584396
Iteration :  51   Loss :  0.0730301288713
Iteration :  52   Loss :  0.071730141295
Iteration :  53   Loss :  0.0704602583335
Iteration :  54   Loss :  0.0692197633292
Iteration :  55   Loss :  0.0680079598408
Iteration :  56   Loss :  0.0668241707831
Iteration :  57   Loss :  0.065667737269
Iteration :  58   Loss :  0.0645380172283
Iteration :  59   Loss :  0.0634343838849
Iteration :  60   Loss :  0.0623562241737
Iteration :  61   Loss :  0.0613029371772
Iteration :  62   Loss :  0.0602739326548
Iteration :  63   Loss :  0.0592686297261
Iteration :  64   Loss :  0.0582864557561
Iteration :  65   Loss :  0.0573268454788
Iteration :  66   Loss :  0.0563892403756
Iteration :  67   Loss :  0.0554730883163
Iteration :  68   Loss :  0.0545778434536
Iteration :  69   Loss :  0.0537029663519
Iteration :  70   Loss :  0.0528479243241
Iteration :  71   Loss :  0.052012191942
Iteration :  72   Loss :  0.0511952516842
Iteration :  73   Loss :  0.0503965946845
Iteration :  74   Loss :  0.049615721544
Iteration :  75   Loss :  0.0488521431752
Iteration :  76   Loss :  0.0481053816483
Iteration :  77   Loss :  0.0473749710168
Iteration :  78   Loss :  0.0466604581024
Iteration :  79   Loss :  0.0459614032244
Iteration :  80   Loss :  0.045277380864
Iteration :  81   Loss :  0.0446079802538
Iteration :  82   Loss :  0.0439528058895
Iteration :  83   Loss :  0.0433114779582
Iteration :  84   Loss :  0.0426836326827
Iteration :  85   Loss :  0.0420689225801
Iteration :  86   Loss :  0.0414670166335
Iteration :  87   Loss :  0.0408776003774
Iteration :  88   Loss :  0.0403003758974
Iteration :  89   Loss :  0.0397350617456
Iteration :  90   Loss :  0.0391813927737
Iteration :  91   Loss :  0.0386391198876
Iteration :  92   Loss :  0.0381080097273
Iteration :  93   Loss :  0.0375878442767
Iteration :  94   Loss :  0.0370784204118
Iteration :  95   Loss :  0.0365795493906
Iteration :  96   Loss :  0.0360910562962
Iteration :  97   Loss :  0.0356127794383
Iteration :  98   Loss :  0.0351445697233
Iteration :  99   Loss :  0.0346862900001
[ -4.00381032e-04   1.82313503e-04  -1.58807821e-04 ...,   1.28000576e-04
  -3.97244904e-05   1.46059969e-04]
CROSS VALIDATION 41
Iteration :  0   Loss :  8.00821125732
Iteration :  1   Loss :  0.211519098418
Iteration :  2   Loss :  0.195074239043
Iteration :  3   Loss :  0.190551537396
Iteration :  4   Loss :  0.186300882514
Iteration :  5   Loss :  0.18224032608
Iteration :  6   Loss :  0.178329048124
Iteration :  7   Loss :  0.174543687013
Iteration :  8   Loss :  0.170869477912
Iteration :  9   Loss :  0.167296345461
Iteration :  10   Loss :  0.163816974161
Iteration :  11   Loss :  0.160425771975
Iteration :  12   Loss :  0.15711827632
Iteration :  13   Loss :  0.153890795544
Iteration :  14   Loss :  0.15074018326
Iteration :  15   Loss :  0.14766369131
Iteration :  16   Loss :  0.144658871193
Iteration :  17   Loss :  0.141723506355
Iteration :  18   Loss :  0.138855564712
Iteration :  19   Loss :  0.136053164738
Iteration :  20   Loss :  0.133314550777
Iteration :  21   Loss :  0.130638074738
Iteration :  22   Loss :  0.12802218218
Iteration :  23   Loss :  0.125465401447
Iteration :  24   Loss :  0.122966334888
Iteration :  25   Loss :  0.12052365147
Iteration :  26   Loss :  0.118136080324
Iteration :  27   Loss :  0.11580240488
Iteration :  28   Loss :  0.113521457387
Iteration :  29   Loss :  0.111292113684
Iteration :  30   Loss :  0.109113288165
Iteration :  31   Loss :  0.10698392893
Iteration :  32   Loss :  0.104903013142
Iteration :  33   Loss :  0.10286954265
Iteration :  34   Loss :  0.100882539937
Iteration :  35   Loss :  0.098941044477
Iteration :  36   Loss :  0.0970441095549
Iteration :  37   Loss :  0.0951907996281
Iteration :  38   Loss :  0.0933801882621
Iteration :  39   Loss :  0.0916113566753
Iteration :  40   Loss :  0.089883392896
Iteration :  41   Loss :  0.0881953915129
Iteration :  42   Loss :  0.0865464539765
Iteration :  43   Loss :  0.084935689387
Iteration :  44   Loss :  0.0833622156811
Iteration :  45   Loss :  0.0818251611191
Iteration :  46   Loss :  0.0803236659588
Iteration :  47   Loss :  0.0788568842028
Iteration :  48   Loss :  0.0774239853039
Iteration :  49   Loss :  0.076024155727
Iteration :  50   Loss :  0.0746566002759
Iteration :  51   Loss :  0.0733205431161
Iteration :  52   Loss :  0.0720152284454
Iteration :  53   Loss :  0.0707399207878
Iteration :  54   Loss :  0.0694939049096
Iteration :  55   Loss :  0.0682764853809
Iteration :  56   Loss :  0.0670869858204
Iteration :  57   Loss :  0.0659247478793
Iteration :  58   Loss :  0.0647891300305
Iteration :  59   Loss :  0.063679506233
Iteration :  60   Loss :  0.0625952645453
Iteration :  61   Loss :  0.0615358057565
Iteration :  62   Loss :  0.0605005420985
Iteration :  63   Loss :  0.059488896094
Iteration :  64   Loss :  0.0585002995817
Iteration :  65   Loss :  0.057534192949
Iteration :  66   Loss :  0.0565900245904
Iteration :  67   Loss :  0.0556672505938
Iteration :  68   Loss :  0.0547653346487
Iteration :  69   Loss :  0.0538837481589
Iteration :  70   Loss :  0.0530219705333
Iteration :  71   Loss :  0.0521794896253
Iteration :  72   Loss :  0.0513558022845
Iteration :  73   Loss :  0.0505504149883
Iteration :  74   Loss :  0.0497628445172
Iteration :  75   Loss :  0.0489926186439
Iteration :  76   Loss :  0.048239276811
Iteration :  77   Loss :  0.047502370773
Iteration :  78   Loss :  0.0467814651882
Iteration :  79   Loss :  0.0460761381478
Iteration :  80   Loss :  0.0453859816364
Iteration :  81   Loss :  0.0447106019175
Iteration :  82   Loss :  0.0440496198471
Iteration :  83   Loss :  0.0434026711132
Iteration :  84   Loss :  0.0427694064048
Iteration :  85   Loss :  0.0421494915136
Iteration :  86   Loss :  0.0415426073703
Iteration :  87   Loss :  0.0409484500194
Iteration :  88   Loss :  0.0403667305339
Iteration :  89   Loss :  0.0397971748728
Iteration :  90   Loss :  0.0392395236836
Iteration :  91   Loss :  0.0386935320524
Iteration :  92   Loss :  0.038158969203
Iteration :  93   Loss :  0.0376356181494
Iteration :  94   Loss :  0.0371232753033
Iteration :  95   Loss :  0.036621750043
Iteration :  96   Loss :  0.0361308642455
Iteration :  97   Loss :  0.0356504517897
Iteration :  98   Loss :  0.0351803580344
Iteration :  99   Loss :  0.0347204392783
[ -4.19276079e-04   1.77497254e-04  -1.59011200e-04 ...,   1.32223761e-04
  -4.43184584e-05   1.48251581e-04]
CROSS VALIDATION 42
Iteration :  0   Loss :  12.4256678962
Iteration :  1   Loss :  0.185892449844
Iteration :  2   Loss :  0.172590901472
Iteration :  3   Loss :  0.168788179445
Iteration :  4   Loss :  0.165182357022
Iteration :  5   Loss :  0.161712917282
Iteration :  6   Loss :  0.158353085183
Iteration :  7   Loss :  0.155088523806
Iteration :  8   Loss :  0.151910465427
Iteration :  9   Loss :  0.148812979064
Iteration :  10   Loss :  0.145791720776
Iteration :  11   Loss :  0.142843301273
Iteration :  12   Loss :  0.139964940132
Iteration :  13   Loss :  0.137154264681
Iteration :  14   Loss :  0.134409186931
Iteration :  15   Loss :  0.131727824955
Iteration :  16   Loss :  0.129108450772
Iteration :  17   Loss :  0.126549454634
Iteration :  18   Loss :  0.124049319817
Iteration :  19   Loss :  0.12160660435
Iteration :  20   Loss :  0.119219927434
Iteration :  21   Loss :  0.11688795914
Iteration :  22   Loss :  0.114609412446
Iteration :  23   Loss :  0.112383037011
Iteration :  24   Loss :  0.110207614252
Iteration :  25   Loss :  0.108081953484
Iteration :  26   Loss :  0.106004888902
Iteration :  27   Loss :  0.1039752773
Iteration :  28   Loss :  0.101991996429
Iteration :  29   Loss :  0.100053943919
Iteration :  30   Loss :  0.0981600367224
Iteration :  31   Loss :  0.0963092110016
Iteration :  32   Loss :  0.0945004224141
Iteration :  33   Loss :  0.092732646721
Iteration :  34   Loss :  0.0910048806395
Iteration :  35   Loss :  0.0893161428557
Iteration :  36   Loss :  0.0876654751041
Iteration :  37   Loss :  0.0860519432212
Iteration :  38   Loss :  0.0844746380821
Iteration :  39   Loss :  0.0829326763395
Iteration :  40   Loss :  0.0814252008958
Iteration :  41   Loss :  0.0799513810585
Iteration :  42   Loss :  0.0785104123484
Iteration :  43   Loss :  0.077101515953
Iteration :  44   Loss :  0.0757239378376
Iteration :  45   Loss :  0.074376947547
Iteration :  46   Loss :  0.0730598367489
Iteration :  47   Loss :  0.0717719175814
Iteration :  48   Loss :  0.0705125208768
Iteration :  49   Loss :  0.069280994339
Iteration :  50   Loss :  0.0680767007498
Iteration :  51   Loss :  0.0668990162798
Iteration :  52   Loss :  0.0657473289664
Iteration :  53   Loss :  0.0646210374176
Iteration :  54   Loss :  0.0635195497824
Iteration :  55   Loss :  0.062442283018
Iteration :  56   Loss :  0.0613886624694
Iteration :  57   Loss :  0.0603581217581
Iteration :  58   Loss :  0.0593501029687
Iteration :  59   Loss :  0.0583640571026
Iteration :  60   Loss :  0.0573994447632
Iteration :  61   Loss :  0.0564557370215
Iteration :  62   Loss :  0.0555324164117
Iteration :  63   Loss :  0.0546289779975
Iteration :  64   Loss :  0.0537449304526
Iteration :  65   Loss :  0.0528797971005
Iteration :  66   Loss :  0.0520331168629
Iteration :  67   Loss :  0.0512044450751
Iteration :  68   Loss :  0.0503933541312
Iteration :  69   Loss :  0.0495994339362
Iteration :  70   Loss :  0.0488222921484
Iteration :  71   Loss :  0.048061554207
Iteration :  72   Loss :  0.047316863148
Iteration :  73   Loss :  0.0465878792207
Iteration :  74   Loss :  0.0458742793222
Iteration :  75   Loss :  0.0451757562753
Iteration :  76   Loss :  0.0444920179762
Iteration :  77   Loss :  0.0438227864413
Iteration :  78   Loss :  0.0431677967865
Iteration :  79   Loss :  0.0425267961656
Iteration :  80   Loss :  0.0418995426993
Iteration :  81   Loss :  0.0412858044196
Iteration :  82   Loss :  0.0406853582539
Iteration :  83   Loss :  0.0400979890679
Iteration :  84   Loss :  0.0395234887857
Iteration :  85   Loss :  0.0389616555986
Iteration :  86   Loss :  0.0384122932743
Iteration :  87   Loss :  0.0378752105737
Iteration :  88   Loss :  0.0373502207785
Iteration :  89   Loss :  0.0368371413354
Iteration :  90   Loss :  0.0363357936136
Iteration :  91   Loss :  0.0358460027784
Iteration :  92   Loss :  0.0353675977756
Iteration :  93   Loss :  0.0349004114252
Iteration :  94   Loss :  0.034444280618
Iteration :  95   Loss :  0.0339990466103
Iteration :  96   Loss :  0.0335645554078
Iteration :  97   Loss :  0.0331406582312
Iteration :  98   Loss :  0.0327272120506
Iteration :  99   Loss :  0.0323240801772
[ -5.16153470e-04   2.34189287e-04  -8.77487068e-05 ...,  -4.23680812e-05
   1.11740324e-04   9.03621284e-05]
CROSS VALIDATION 43
Iteration :  0   Loss :  7.91884047636
Iteration :  1   Loss :  0.210756794606
Iteration :  2   Loss :  0.194442749808
Iteration :  3   Loss :  0.189968018743
Iteration :  4   Loss :  0.185756604209
Iteration :  5   Loss :  0.181727802895
Iteration :  6   Loss :  0.177842308339
Iteration :  7   Loss :  0.174078007447
Iteration :  8   Loss :  0.170421097602
Iteration :  9   Loss :  0.166862237415
Iteration :  10   Loss :  0.163394675038
Iteration :  11   Loss :  0.160013256736
Iteration :  12   Loss :  0.156713865653
Iteration :  13   Loss :  0.153493086782
Iteration :  14   Loss :  0.150347998111
Iteration :  15   Loss :  0.147276035691
Iteration :  16   Loss :  0.144274903819
Iteration :  17   Loss :  0.141342513748
Iteration :  18   Loss :  0.138476940942
Iteration :  19   Loss :  0.135676394712
Iteration :  20   Loss :  0.132939196242
Iteration :  21   Loss :  0.130263762387
Iteration :  22   Loss :  0.12764859348
Iteration :  23   Loss :  0.125092263886
Iteration :  24   Loss :  0.12259341447
Iteration :  25   Loss :  0.120150746326
Iteration :  26   Loss :  0.117763015362
Iteration :  27   Loss :  0.115429027416
Iteration :  28   Loss :  0.1131476337
Iteration :  29   Loss :  0.110917726453
Iteration :  30   Loss :  0.108738234727
Iteration :  31   Loss :  0.106608120293
Iteration :  32   Loss :  0.104526373669
Iteration :  33   Loss :  0.102492010333
Iteration :  34   Loss :  0.100504067151
Iteration :  35   Loss :  0.0985615991035
Iteration :  36   Loss :  0.0966636763657
Iteration :  37   Loss :  0.0948093818113
Iteration :  38   Loss :  0.09299780898
Iteration :  39   Loss :  0.0912280605501
Iteration :  40   Loss :  0.0894992473318
Iteration :  41   Loss :  0.0878104877761
Iteration :  42   Loss :  0.0861609079749
Iteration :  43   Loss :  0.0845496421032
Iteration :  44   Loss :  0.0829758332387
Iteration :  45   Loss :  0.0814386344732
Iteration :  46   Loss :  0.0799372102199
Iteration :  47   Loss :  0.0784707376148
Iteration :  48   Loss :  0.0770384079043
Iteration :  49   Loss :  0.0756394277238
Iteration :  50   Loss :  0.0742730201749
Iteration :  51   Loss :  0.0729384256311
Iteration :  52   Loss :  0.0716349022201
Iteration :  53   Loss :  0.0703617259522
Iteration :  54   Loss :  0.0691181904916
Iteration :  55   Loss :  0.0679036065865
Iteration :  56   Loss :  0.0667173011985
Iteration :  57   Loss :  0.0655586163865
Iteration :  58   Loss :  0.0644269080136
Iteration :  59   Loss :  0.0633215443548
Iteration :  60   Loss :  0.0622419046835
Iteration :  61   Loss :  0.0611873779141
Iteration :  62   Loss :  0.0601573613699
Iteration :  63   Loss :  0.0591512597344
Iteration :  64   Loss :  0.0581684842318
Iteration :  65   Loss :  0.0572084520668
Iteration :  66   Loss :  0.056270586135
Iteration :  67   Loss :  0.0553543150055
Iteration :  68   Loss :  0.054459073157
Iteration :  69   Loss :  0.0535843014434
Iteration :  70   Loss :  0.0527294477494
Iteration :  71   Loss :  0.0518939677988
Iteration :  72   Loss :  0.0510773260679
Iteration :  73   Loss :  0.0502789967638
Iteration :  74   Loss :  0.0494984648261
Iteration :  75   Loss :  0.0487352269168
Iteration :  76   Loss :  0.0479887923695
Iteration :  77   Loss :  0.0472586840748
Iteration :  78   Loss :  0.0465444392853
Iteration :  79   Loss :  0.0458456103292
Iteration :  80   Loss :  0.0451617652266
Iteration :  81   Loss :  0.0444924882056
Iteration :  82   Loss :  0.0438373801187
Iteration :  83   Loss :  0.043196058761
Iteration :  84   Loss :  0.0425681590939
Iteration :  85   Loss :  0.0419533333765
Iteration :  86   Loss :  0.0413512512092
Iteration :  87   Loss :  0.0407615994932
Iteration :  88   Loss :  0.0401840823088
Iteration :  89   Loss :  0.0396184207173
Iteration :  90   Loss :  0.039064352491
Iteration :  91   Loss :  0.0385216317749
Iteration :  92   Loss :  0.0379900286862
Iteration :  93   Loss :  0.0374693288578
Iteration :  94   Loss :  0.0369593329311
Iteration :  95   Loss :  0.0364598560058
Iteration :  96   Loss :  0.0359707270533
Iteration :  97   Loss :  0.035491788302
Iteration :  98   Loss :  0.0350228946006
Iteration :  99   Loss :  0.0345639127679
[ -4.07782910e-04   1.85578174e-04  -1.58375681e-04 ...,   1.24330944e-04
  -4.52524527e-05   1.45939943e-04]
CROSS VALIDATION 44
Iteration :  0   Loss :  0.442918129321
Iteration :  1   Loss :  0.195608166674
Iteration :  2   Loss :  0.189751430945
Iteration :  3   Loss :  0.184837935622
Iteration :  4   Loss :  0.180394779035
Iteration :  5   Loss :  0.176246821413
Iteration :  6   Loss :  0.172310727295
Iteration :  7   Loss :  0.168540601595
Iteration :  8   Loss :  0.164908519751
Iteration :  9   Loss :  0.161396181164
Iteration :  10   Loss :  0.157990867545
Iteration :  11   Loss :  0.154683303456
Iteration :  12   Loss :  0.151466443444
Iteration :  13   Loss :  0.148334745868
Iteration :  14   Loss :  0.145283718186
Iteration :  15   Loss :  0.142309621335
Iteration :  16   Loss :  0.139409271241
Iteration :  17   Loss :  0.13657990177
Iteration :  18   Loss :  0.133819067716
Iteration :  19   Loss :  0.13112457458
Iteration :  20   Loss :  0.128494426699
Iteration :  21   Loss :  0.125926788187
Iteration :  22   Loss :  0.123419953013
Iteration :  23   Loss :  0.120972321688
Iteration :  24   Loss :  0.118582382825
Iteration :  25   Loss :  0.116248698344
Iteration :  26   Loss :  0.113969891471
Iteration :  27   Loss :  0.11174463689
Iteration :  28   Loss :  0.10957165263
Iteration :  29   Loss :  0.107449693352
Iteration :  30   Loss :  0.105377544808
Iteration :  31   Loss :  0.103354019311
Iteration :  32   Loss :  0.101377952075
Iteration :  33   Loss :  0.0994481983346
Iteration :  34   Loss :  0.0975636311641
Iteration :  35   Loss :  0.0957231399254
Iteration :  36   Loss :  0.0939256292879
Iteration :  37   Loss :  0.0921700187668
Iteration :  38   Loss :  0.0904552427314
Iteration :  39   Loss :  0.0887802508355
Iteration :  40   Loss :  0.0871440088267
Iteration :  41   Loss :  0.0855454996849
Iteration :  42   Loss :  0.083983725042
Iteration :  43   Loss :  0.082457706825
Iteration :  44   Loss :  0.0809664890603
Iteration :  45   Loss :  0.0795091397685
Iteration :  46   Loss :  0.078084752875
Iteration :  47   Loss :  0.076692450056
Iteration :  48   Loss :  0.0753313824432
Iteration :  49   Loss :  0.0740007321147
Iteration :  50   Loss :  0.0726997133099
Iteration :  51   Loss :  0.0714275733174
Iteration :  52   Loss :  0.0701835930055
Iteration :  53   Loss :  0.0689670869757
Iteration :  54   Loss :  0.0677774033383
Iteration :  55   Loss :  0.0666139231237
Iteration :  56   Loss :  0.0654760593488
Iteration :  57   Loss :  0.0643632557709
Iteration :  58   Loss :  0.0632749853621
Iteration :  59   Loss :  0.0622107485382
Iteration :  60   Loss :  0.0611700711805
Iteration :  61   Loss :  0.0601525024826
Iteration :  62   Loss :  0.0591576126563
Iteration :  63   Loss :  0.0581849905306
Iteration :  64   Loss :  0.057234241075
Iteration :  65   Loss :  0.0563049828809
Iteration :  66   Loss :  0.0553968456364
Iteration :  67   Loss :  0.0545094676286
Iteration :  68   Loss :  0.0536424933114
Iteration :  69   Loss :  0.0527955709759
Iteration :  70   Loss :  0.0519683505608
Iteration :  71   Loss :  0.0511604816399
Iteration :  72   Loss :  0.0503716116207
Iteration :  73   Loss :  0.0496013841871
Iteration :  74   Loss :  0.0488494380148
Iteration :  75   Loss :  0.048115405782
Iteration :  76   Loss :  0.0473989134967
Iteration :  77   Loss :  0.0466995801526
Iteration :  78   Loss :  0.0460170177214
Iteration :  79   Loss :  0.045350831483
Iteration :  80   Loss :  0.0447006206863
Iteration :  81   Loss :  0.0440659795291
Iteration :  82   Loss :  0.043446498435
Iteration :  83   Loss :  0.0428417655993
Iteration :  84   Loss :  0.0422513687697
Iteration :  85   Loss :  0.0416748972173
Iteration :  86   Loss :  0.0411119438509
Iteration :  87   Loss :  0.0405621074205
Iteration :  88   Loss :  0.0400249947523
Iteration :  89   Loss :  0.0395002229588
Iteration :  90   Loss :  0.038987421564
Iteration :  91   Loss :  0.0384862344901
Iteration :  92   Loss :  0.0379963218553
Iteration :  93   Loss :  0.0375173615402
Iteration :  94   Loss :  0.0370490504876
Iteration :  95   Loss :  0.0365911057114
Iteration :  96   Loss :  0.0361432650009
Iteration :  97   Loss :  0.0357052873138
Iteration :  98   Loss :  0.0352769528665
Iteration :  99   Loss :  0.0348580629334
[ -3.17171815e-04   2.23725349e-04  -2.37739000e-04 ...,   1.50266400e-04
  -7.76994348e-05   1.42073356e-04]
CROSS VALIDATION 45
Iteration :  0   Loss :  8.01409852272
Iteration :  1   Loss :  0.211532131563
Iteration :  2   Loss :  0.195037054837
Iteration :  3   Loss :  0.19051154881
Iteration :  4   Loss :  0.186256473212
Iteration :  5   Loss :  0.182190566786
Iteration :  6   Loss :  0.178273267221
Iteration :  7   Loss :  0.174481330195
Iteration :  8   Loss :  0.170800053323
Iteration :  9   Loss :  0.167219400331
Iteration :  10   Loss :  0.163732084993
Iteration :  11   Loss :  0.160332541266
Iteration :  12   Loss :  0.15701633272
Iteration :  13   Loss :  0.153779795938
Iteration :  14   Loss :  0.150619815936
Iteration :  15   Loss :  0.147533679708
Iteration :  16   Loss :  0.144518977884
Iteration :  17   Loss :  0.141573537004
Iteration :  18   Loss :  0.138695371818
Iteration :  19   Loss :  0.135882650982
Iteration :  20   Loss :  0.133133671863
Iteration :  21   Loss :  0.130446841606
Iteration :  22   Loss :  0.127820662545
Iteration :  23   Loss :  0.125253720613
Iteration :  24   Loss :  0.122744675834
Iteration :  25   Loss :  0.12029225424
Iteration :  26   Loss :  0.117895240752
Iteration :  27   Loss :  0.115552472738
Iteration :  28   Loss :  0.113262834016
Iteration :  29   Loss :  0.111025249205
Iteration :  30   Loss :  0.108838678348
Iteration :  31   Loss :  0.10670211179
Iteration :  32   Loss :  0.10461456533
Iteration :  33   Loss :  0.102575075673
Iteration :  34   Loss :  0.100582696243
Iteration :  35   Loss :  0.0986364933943
Iteration :  36   Loss :  0.0967355431005
Iteration :  37   Loss :  0.0948789281552
Iteration :  38   Loss :  0.0930657359385
Iteration :  39   Loss :  0.0912950567801
Iteration :  40   Loss :  0.0895659829369
Iteration :  41   Loss :  0.0878776081848
Iteration :  42   Loss :  0.0862290280047
Iteration :  43   Loss :  0.0846193403227
Iteration :  44   Loss :  0.0830476467422
Iteration :  45   Loss :  0.0815130541868
Iteration :  46   Loss :  0.0800146768561
Iteration :  47   Loss :  0.0785516383841
Iteration :  48   Loss :  0.0771230740821
Iteration :  49   Loss :  0.0757281331467
Iteration :  50   Loss :  0.0743659807206
Iteration :  51   Loss :  0.0730357997042
Iteration :  52   Loss :  0.071736792235
Iteration :  53   Loss :  0.0704681807734
Iteration :  54   Loss :  0.0692292087594
Iteration :  55   Loss :  0.0680191408308
Iteration :  56   Loss :  0.0668372626184
Iteration :  57   Loss :  0.065682880156
Iteration :  58   Loss :  0.0645553189636
Iteration :  59   Loss :  0.0634539228721
Iteration :  60   Loss :  0.062378052671
Iteration :  61   Loss :  0.0613270846582
Iteration :  62   Loss :  0.0603004091724
Iteration :  63   Loss :  0.0592974291796
Iteration :  64   Loss :  0.058317558977
Iteration :  65   Loss :  0.057360223063
Iteration :  66   Loss :  0.05642485521
Iteration :  67   Loss :  0.055510897761
Iteration :  68   Loss :  0.0546178011606
Iteration :  69   Loss :  0.0537450237143
Iteration :  70   Loss :  0.0528920315654
Iteration :  71   Loss :  0.0520582988669
Iteration :  72   Loss :  0.0512433081231
Iteration :  73   Loss :  0.0504465506721
Iteration :  74   Loss :  0.049667527278
Iteration :  75   Loss :  0.0489057488049
Iteration :  76   Loss :  0.0481607369443
Iteration :  77   Loss :  0.0474320249709
Iteration :  78   Loss :  0.0467191585052
Iteration :  79   Loss :  0.046021696263
Iteration :  80   Loss :  0.0453392107738
Iteration :  81   Loss :  0.0446712890553
Iteration :  82   Loss :  0.0440175332293
Iteration :  83   Loss :  0.0433775610678
Iteration :  84   Loss :  0.0427510064598
Iteration :  85   Loss :  0.0421375197899
Iteration :  86   Loss :  0.0415367682217
Iteration :  87   Loss :  0.0409484358803
Iteration :  88   Loss :  0.0403722239318
Iteration :  89   Loss :  0.0398078505566
Iteration :  90   Loss :  0.0392550508189
Iteration :  91   Loss :  0.0387135764353
Iteration :  92   Loss :  0.038183195447
Iteration :  93   Loss :  0.0376636918031
Iteration :  94   Loss :  0.0371548648647
Iteration :  95   Loss :  0.0366565288383
Iteration :  96   Loss :  0.0361685121516
Iteration :  97   Loss :  0.0356906567815
Iteration :  98   Loss :  0.0352228175481
Iteration :  99   Loss :  0.0347648613841
[ -4.26520004e-04   1.84873647e-04  -1.63570129e-04 ...,   1.34272899e-04
  -4.66929621e-05   1.46523752e-04]
CROSS VALIDATION 46
Iteration :  0   Loss :  7.14555728737
Iteration :  1   Loss :  0.202685257986
Iteration :  2   Loss :  0.198382377028
Iteration :  3   Loss :  0.194207608861
Iteration :  4   Loss :  0.190145682311
Iteration :  5   Loss :  0.18618689161
Iteration :  6   Loss :  0.182324470557
Iteration :  7   Loss :  0.178553348187
Iteration :  8   Loss :  0.174869500667
Iteration :  9   Loss :  0.171269588272
Iteration :  10   Loss :  0.167750739891
Iteration :  11   Loss :  0.164310418877
Iteration :  12   Loss :  0.160946336103
Iteration :  13   Loss :  0.157656391639
Iteration :  14   Loss :  0.154438634406
Iteration :  15   Loss :  0.151291233506
Iteration :  16   Loss :  0.148212457324
Iteration :  17   Loss :  0.145200657943
Iteration :  18   Loss :  0.14225425929
Iteration :  19   Loss :  0.139371747941
Iteration :  20   Loss :  0.136551665883
Iteration :  21   Loss :  0.133792604754
Iteration :  22   Loss :  0.131093201222
Iteration :  23   Loss :  0.128452133271
Iteration :  24   Loss :  0.125868117236
Iteration :  25   Loss :  0.123339905465
Iteration :  26   Loss :  0.120866284516
Iteration :  27   Loss :  0.118446073823
Iteration :  28   Loss :  0.11607812477
Iteration :  29   Loss :  0.113761320112
Iteration :  30   Loss :  0.111494573708
Iteration :  31   Loss :  0.109276830489
Iteration :  32   Loss :  0.107107066634
Iteration :  33   Loss :  0.104984289878
Iteration :  34   Loss :  0.102907539904
Iteration :  35   Loss :  0.100875888767
Iteration :  36   Loss :  0.0988884412851
Iteration :  37   Loss :  0.0969443353357
Iteration :  38   Loss :  0.0950427420268
Iteration :  39   Loss :  0.0931828656707
Iteration :  40   Loss :  0.0913639435312
Iteration :  41   Loss :  0.0895852453039
Iteration :  42   Loss :  0.0878460723012
Iteration :  43   Loss :  0.0861457563204
Iteration :  44   Loss :  0.0844836581826
Iteration :  45   Loss :  0.082859165938
Iteration :  46   Loss :  0.0812716927392
Iteration :  47   Loss :  0.0797206743951
Iteration :  48   Loss :  0.0782055666234
Iteration :  49   Loss :  0.0767258420287
Iteration :  50   Loss :  0.07528098684
Iteration :  51   Loss :  0.0738704974516
Iteration :  52   Loss :  0.0724938768161
Iteration :  53   Loss :  0.0711506307507
Iteration :  54   Loss :  0.0698402642225
Iteration :  55   Loss :  0.0685622776897
Iteration :  56   Loss :  0.0673161635782
Iteration :  57   Loss :  0.066101402982
Iteration :  58   Loss :  0.0649174626739
Iteration :  59   Loss :  0.063763792515
Iteration :  60   Loss :  0.0626398233444
Iteration :  61   Loss :  0.0615449654218
Iteration :  62   Loss :  0.0604786074835
Iteration :  63   Loss :  0.0594401164515
Iteration :  64   Loss :  0.0584288378191
Iteration :  65   Loss :  0.0574440967112
Iteration :  66   Loss :  0.0564851995936
Iteration :  67   Loss :  0.0555514365854
Iteration :  68   Loss :  0.0546420843045
Iteration :  69   Loss :  0.0537564091605
Iteration :  70   Loss :  0.0528936709961
Iteration :  71   Loss :  0.0520531269654
Iteration :  72   Loss :  0.0512340355388
Iteration :  73   Loss :  0.0504356605201
Iteration :  74   Loss :  0.0496572749695
Iteration :  75   Loss :  0.0488981649358
Iteration :  76   Loss :  0.0481576329113
Iteration :  77   Loss :  0.0474350009407
Iteration :  78   Loss :  0.0467296133321
Iteration :  79   Loss :  0.0460408389319
Iteration :  80   Loss :  0.045368072948
Iteration :  81   Loss :  0.0447107383167
Iteration :  82   Loss :  0.0440682866268
Iteration :  83   Loss :  0.0434401986233
Iteration :  84   Loss :  0.0428259843258
Iteration :  85   Loss :  0.042225182802
Iteration :  86   Loss :  0.0416373616421
Iteration :  87   Loss :  0.0410621161838
Iteration :  88   Loss :  0.0404990685355
Iteration :  89   Loss :  0.039947866449
Iteration :  90   Loss :  0.0394081820855
Iteration :  91   Loss :  0.0388797107216
Iteration :  92   Loss :  0.0383621694314
Iteration :  93   Loss :  0.0378552957819
Iteration :  94   Loss :  0.0373588465702
Iteration :  95   Loss :  0.0368725966257
Iteration :  96   Loss :  0.036396337695
Iteration :  97   Loss :  0.0359298774228
Iteration :  98   Loss :  0.0354730384334
Iteration :  99   Loss :  0.0350256575139
[ -4.15049382e-04   2.08178919e-04  -1.54419558e-04 ...,   1.19480824e-04
  -8.32966306e-06   1.51206090e-04]
CROSS VALIDATION 47
Iteration :  0   Loss :  7.35653211012
Iteration :  1   Loss :  0.356035347312
Iteration :  2   Loss :  0.212667803783
Iteration :  3   Loss :  0.207761601429
Iteration :  4   Loss :  0.20313677801
Iteration :  5   Loss :  0.198712859234
Iteration :  6   Loss :  0.194448459063
Iteration :  7   Loss :  0.190319335205
Iteration :  8   Loss :  0.186309905661
Iteration :  9   Loss :  0.182409409631
Iteration :  10   Loss :  0.178609971291
Iteration :  11   Loss :  0.174905541714
Iteration :  12   Loss :  0.171291283535
Iteration :  13   Loss :  0.167763194736
Iteration :  14   Loss :  0.164317868951
Iteration :  15   Loss :  0.160952337359
Iteration :  16   Loss :  0.157663961226
Iteration :  17   Loss :  0.154450356975
Iteration :  18   Loss :  0.151309342725
Iteration :  19   Loss :  0.148238899361
Iteration :  20   Loss :  0.145237141686
Iteration :  21   Loss :  0.142302296671
Iteration :  22   Loss :  0.139432686814
Iteration :  23   Loss :  0.136626717232
Iteration :  24   Loss :  0.133882865485
Iteration :  25   Loss :  0.131199673463
Iteration :  26   Loss :  0.128575740784
Iteration :  27   Loss :  0.126009719353
Iteration :  28   Loss :  0.123500308768
Iteration :  29   Loss :  0.121046252376
Iteration :  30   Loss :  0.118646333806
Iteration :  31   Loss :  0.116299373869
Iteration :  32   Loss :  0.114004227744
Iteration :  33   Loss :  0.11175978239
Iteration :  34   Loss :  0.109564954167
Iteration :  35   Loss :  0.107418686633
Iteration :  36   Loss :  0.105319948541
Iteration :  37   Loss :  0.103267732007
Iteration :  38   Loss :  0.101261050884
Iteration :  39   Loss :  0.0992989393322
Iteration :  40   Loss :  0.0973804505913
Iteration :  41   Loss :  0.0955046559496
Iteration :  42   Loss :  0.0936706439058
Iteration :  43   Loss :  0.0918775195073
Iteration :  44   Loss :  0.0901244038483
Iteration :  45   Loss :  0.0884104337088
Iteration :  46   Loss :  0.086734761312
Iteration :  47   Loss :  0.0850965541807
Iteration :  48   Loss :  0.0834949950723
Iteration :  49   Loss :  0.081929281976
Iteration :  50   Loss :  0.0803986281579
Iteration :  51   Loss :  0.0789022622441
Iteration :  52   Loss :  0.0774394283319
Iteration :  53   Loss :  0.0760093861248
Iteration :  54   Loss :  0.0746114110855
Iteration :  55   Loss :  0.0732447946047
Iteration :  56   Loss :  0.0719088441799
Iteration :  57   Loss :  0.0706028836009
Iteration :  58   Loss :  0.0693262531357
Iteration :  59   Loss :  0.0680783097086
Iteration :  60   Loss :  0.0668584270614
Iteration :  61   Loss :  0.0656659958854
Iteration :  62   Loss :  0.0645004239113
Iteration :  63   Loss :  0.0633611359412
Iteration :  64   Loss :  0.0622475738077
Iteration :  65   Loss :  0.0611591962415
Iteration :  66   Loss :  0.0600954786328
Iteration :  67   Loss :  0.0590559126705
Iteration :  68   Loss :  0.0580400058452
Iteration :  69   Loss :  0.0570472808068
Iteration :  70   Loss :  0.056077274571
Iteration :  71   Loss :  0.0551295375738
Iteration :  72   Loss :  0.0542036325794
Iteration :  73   Loss :  0.0532991334566
Iteration :  74   Loss :  0.0524156238399
Iteration :  75   Loss :  0.0515526957064
Iteration :  76   Loss :  0.0507099478986
Iteration :  77   Loss :  0.0498869846334
Iteration :  78   Loss :  0.0490834140396
Iteration :  79   Loss :  0.0482988467678
Iteration :  80   Loss :  0.0475328947173
Iteration :  81   Loss :  0.0467851699214
Iteration :  82   Loss :  0.0460552836309
Iteration :  83   Loss :  0.0453428456261
Iteration :  84   Loss :  0.044647463786
Iteration :  85   Loss :  0.0439687439318
Iteration :  86   Loss :  0.0433062899555
Iteration :  87   Loss :  0.0426597042375
Iteration :  88   Loss :  0.042028588347
Iteration :  89   Loss :  0.0414125440122
Iteration :  90   Loss :  0.0408111743399
Iteration :  91   Loss :  0.0402240852541
Iteration :  92   Loss :  0.0396508871206
Iteration :  93   Loss :  0.0390911965117
Iteration :  94   Loss :  0.0385446380662
Iteration :  95   Loss :  0.0380108463915
Iteration :  96   Loss :  0.0374894679537
Iteration :  97   Loss :  0.0369801629029
Iteration :  98   Loss :  0.0364826067826
Iteration :  99   Loss :  0.0359964920757
[ -4.71202628e-04   2.48978277e-04  -1.44684383e-04 ...,   7.41829719e-05
   6.59772723e-05   1.42467092e-04]
CROSS VALIDATION 48
Iteration :  0   Loss :  8.01541974632
Iteration :  1   Loss :  0.211497349356
Iteration :  2   Loss :  0.194965897618
Iteration :  3   Loss :  0.190438577949
Iteration :  4   Loss :  0.186180508526
Iteration :  5   Loss :  0.182111126655
Iteration :  6   Loss :  0.178190153591
Iteration :  7   Loss :  0.174394494313
Iteration :  8   Loss :  0.170709543099
Iteration :  9   Loss :  0.167125336586
Iteration :  10   Loss :  0.163634649119
Iteration :  11   Loss :  0.160231967523
Iteration :  12   Loss :  0.156912902271
Iteration :  13   Loss :  0.153673831256
Iteration :  14   Loss :  0.150511674961
Iteration :  15   Loss :  0.1474237495
Iteration :  16   Loss :  0.144407667708
Iteration :  17   Loss :  0.141461270925
Iteration :  18   Loss :  0.138582580964
Iteration :  19   Loss :  0.135769765678
Iteration :  20   Loss :  0.133021113851
Iteration :  21   Loss :  0.130335016594
Iteration :  22   Loss :  0.127709953272
Iteration :  23   Loss :  0.125144480627
Iteration :  24   Loss :  0.12263722411
Iteration :  25   Loss :  0.120186870726
Iteration :  26   Loss :  0.1177921629
Iteration :  27   Loss :  0.115451893008
Iteration :  28   Loss :  0.113164898321
Iteration :  29   Loss :  0.110930056241
Iteration :  30   Loss :  0.10874627972
Iteration :  31   Loss :  0.106612512858
Iteration :  32   Loss :  0.104527726683
Iteration :  33   Loss :  0.102490915171
Iteration :  34   Loss :  0.100501091553
Iteration :  35   Loss :  0.0985572849988
Iteration :  36   Loss :  0.0966585377273
Iteration :  37   Loss :  0.0948039026228
Iteration :  38   Loss :  0.0929924413934
Iteration :  39   Loss :  0.0912232233039
Iteration :  40   Loss :  0.0894953244872
Iteration :  41   Loss :  0.0878078278168
Iteration :  42   Loss :  0.0861598232957
Iteration :  43   Loss :  0.0845504088983
Iteration :  44   Loss :  0.082978691779
Iteration :  45   Loss :  0.0814437897501
Iteration :  46   Loss :  0.0799448329188
Iteration :  47   Loss :  0.0784809653726
Iteration :  48   Loss :  0.0770513468053
Iteration :  49   Loss :  0.0756551539837
Iteration :  50   Loss :  0.0742915819727
Iteration :  51   Loss :  0.0729598450521
Iteration :  52   Loss :  0.0716591772837
Iteration :  53   Loss :  0.0703888327061
Iteration :  54   Loss :  0.0691480851611
Iteration :  55   Loss :  0.0679362277723
Iteration :  56   Loss :  0.0667525721172
Iteration :  57   Loss :  0.0655964471461
Iteration :  58   Loss :  0.0644671979122
Iteration :  59   Loss :  0.0633641841817
Iteration :  60   Loss :  0.0622867789962
Iteration :  61   Loss :  0.0612343672557
Iteration :  62   Loss :  0.0602063443867
Iteration :  63   Loss :  0.0592021151521
Iteration :  64   Loss :  0.0582210926477
Iteration :  65   Loss :  0.0572626975224
Iteration :  66   Loss :  0.0563263574427
Iteration :  67   Loss :  0.0554115068139
Iteration :  68   Loss :  0.0545175867548
Iteration :  69   Loss :  0.053644045314
Iteration :  70   Loss :  0.0527903379053
Iteration :  71   Loss :  0.0519559279314
Iteration :  72   Loss :  0.0511402875599
Iteration :  73   Loss :  0.050342898612
Iteration :  74   Loss :  0.0495632535219
Iteration :  75   Loss :  0.0488008563276
Iteration :  76   Loss :  0.0480552236538
Iteration :  77   Loss :  0.0473258856535
Iteration :  78   Loss :  0.0466123868801
Iteration :  79   Loss :  0.0459142870643
Iteration :  80   Loss :  0.0452311617821
Iteration :  81   Loss :  0.0445626029986
Iteration :  82   Loss :  0.0439082194846
Iteration :  83   Loss :  0.0432676371027
Iteration :  84   Loss :  0.0426404989667
Iteration :  85   Loss :  0.0420264654805
Iteration :  86   Loss :  0.0414252142639
Iteration :  87   Loss :  0.0408364399765
Iteration :  88   Loss :  0.04025985405
Iteration :  89   Loss :  0.039695184341
Iteration :  90   Loss :  0.0391421747142
Iteration :  91   Loss :  0.0386005845684
Iteration :  92   Loss :  0.0380701883138
Iteration :  93   Loss :  0.037550774811
Iteration :  94   Loss :  0.0370421467792
Iteration :  95   Loss :  0.0365441201828
Iteration :  96   Loss :  0.0360565236006
Iteration :  97   Loss :  0.0355791975877
Iteration :  98   Loss :  0.0351119940326
Iteration :  99   Loss :  0.0346547755179
[ -4.08178847e-04   1.89818224e-04  -1.53044201e-04 ...,   1.29781957e-04
  -4.43591372e-05   1.49661672e-04]
CROSS VALIDATION 49
Iteration :  0   Loss :  8.01364290577
Iteration :  1   Loss :  0.211559464872
Iteration :  2   Loss :  0.195113279805
Iteration :  3   Loss :  0.190589886464
Iteration :  4   Loss :  0.186338290865
Iteration :  5   Loss :  0.182276621842
Iteration :  6   Loss :  0.17836409796
Iteration :  7   Loss :  0.174577378309
Iteration :  8   Loss :  0.170901709163
Iteration :  9   Loss :  0.16732702051
Iteration :  10   Loss :  0.163845998482
Iteration :  11   Loss :  0.160453050118
Iteration :  12   Loss :  0.15714371007
Iteration :  13   Loss :  0.153914282533
Iteration :  14   Loss :  0.150761615883
Iteration :  15   Loss :  0.147682955869
Iteration :  16   Loss :  0.144675847185
Iteration :  17   Loss :  0.141738065901
Iteration :  18   Loss :  0.138867572097
Iteration :  19   Loss :  0.136062476044
Iteration :  20   Loss :  0.133321013632
Iteration :  21   Loss :  0.130641528165
Iteration :  22   Loss :  0.128022456578
Iteration :  23   Loss :  0.125462318711
Iteration :  24   Loss :  0.122959708676
Iteration :  25   Loss :  0.120513287662
Iteration :  26   Loss :  0.118121777672
Iteration :  27   Loss :  0.115783955884
Iteration :  28   Loss :  0.113498649413
Iteration :  29   Loss :  0.111264730343
Iteration :  30   Loss :  0.109081110964
Iteration :  31   Loss :  0.106946739212
Iteration :  32   Loss :  0.104860594313
Iteration :  33   Loss :  0.10282168269
Iteration :  34   Loss :  0.100829034192
Iteration :  35   Loss :  0.0988816986964
Iteration :  36   Loss :  0.0969787431611
Iteration :  37   Loss :  0.0951192491635
Iteration :  38   Loss :  0.0933023109678
Iteration :  39   Loss :  0.091527034137
Iteration :  40   Loss :  0.0897925346826
Iteration :  41   Loss :  0.0880979387259
Iteration :  42   Loss :  0.0864423826216
Iteration :  43   Loss :  0.0848250134734
Iteration :  44   Loss :  0.0832449899561
Iteration :  45   Loss :  0.0817014833472
Iteration :  46   Loss :  0.0801936786623
Iteration :  47   Loss :  0.0787207757922
Iteration :  48   Loss :  0.0772819905426
Iteration :  49   Loss :  0.0758765554899
Iteration :  50   Loss :  0.0745037205854
Iteration :  51   Loss :  0.0731627534563
Iteration :  52   Loss :  0.0718529393787
Iteration :  53   Loss :  0.0705735809159
Iteration :  54   Loss :  0.0693239972412
Iteration :  55   Loss :  0.0681035231786
Iteration :  56   Loss :  0.0669115080156
Iteration :  57   Loss :  0.065747314149
Iteration :  58   Loss :  0.0646103156344
Iteration :  59   Loss :  0.0634998967117
Iteration :  60   Loss :  0.062415450377
Iteration :  61   Loss :  0.0613563770652
Iteration :  62   Loss :  0.0603220835016
Iteration :  63   Loss :  0.0593119817644
Iteration :  64   Loss :  0.0583254885941
Iteration :  65   Loss :  0.0573620249654
Iteration :  66   Loss :  0.0564210159294
Iteration :  67   Loss :  0.0555018907156
Iteration :  68   Loss :  0.0546040830768
Iteration :  69   Loss :  0.0537270318473
Iteration :  70   Loss :  0.0528701816781
Iteration :  71   Loss :  0.0520329839107
Iteration :  72   Loss :  0.0512148975474
Iteration :  73   Loss :  0.0504153902775
Iteration :  74   Loss :  0.0496339395237
Iteration :  75   Loss :  0.0488700334754
Iteration :  76   Loss :  0.0481231720823
Iteration :  77   Loss :  0.0473928679891
Iteration :  78   Loss :  0.0466786473961
Iteration :  79   Loss :  0.0459800508368
Iteration :  80   Loss :  0.0452966338677
Iteration :  81   Loss :  0.0446279676688
Iteration :  82   Loss :  0.0439736395552
Iteration :  83   Loss :  0.0433332534009
Iteration :  84   Loss :  0.0427064299778
Iteration :  85   Loss :  0.0420928072091
Iteration :  86   Loss :  0.0414920403413
Iteration :  87   Loss :  0.0409038020328
Iteration :  88   Loss :  0.0403277823602
Iteration :  89   Loss :  0.0397636887443
Iteration :  90   Loss :  0.0392112457928
Iteration :  91   Loss :  0.038670195065
Iteration :  92   Loss :  0.038140294758
Iteration :  93   Loss :  0.0376213193188
Iteration :  94   Loss :  0.037113058987
Iteration :  95   Loss :  0.0366153192744
Iteration :  96   Loss :  0.0361279203879
Iteration :  97   Loss :  0.0356506966046
Iteration :  98   Loss :  0.0351834956079
Iteration :  99   Loss :  0.0347261777945
[ -4.15855716e-04   1.72517252e-04  -1.55055465e-04 ...,   1.29491984e-04
  -4.45686749e-05   1.46863123e-04]
CROSS VALIDATION 50
Iteration :  0   Loss :  7.28001375945
Iteration :  1   Loss :  0.306931684961
Iteration :  2   Loss :  0.18928966452
Iteration :  3   Loss :  0.184666169832
Iteration :  4   Loss :  0.180462682059
Iteration :  5   Loss :  0.176493807713
Iteration :  6   Loss :  0.172688747499
Iteration :  7   Loss :  0.169013349735
Iteration :  8   Loss :  0.165448536294
Iteration :  9   Loss :  0.161982454067
Iteration :  10   Loss :  0.158607099276
Iteration :  11   Loss :  0.155316686938
Iteration :  12   Loss :  0.15210679238
Iteration :  13   Loss :  0.148973867894
Iteration :  14   Loss :  0.145914955566
Iteration :  15   Loss :  0.142927508933
Iteration :  16   Loss :  0.140009278048
Iteration :  17   Loss :  0.137158233065
Iteration :  18   Loss :  0.134372512047
Iteration :  19   Loss :  0.13165038453
Iteration :  20   Loss :  0.128990225584
Iteration :  21   Loss :  0.126390497081
Iteration :  22   Loss :  0.123849734001
Iteration :  23   Loss :  0.121366534341
Iteration :  24   Loss :  0.11893955164
Iteration :  25   Loss :  0.116567489429
Iteration :  26   Loss :  0.114249097083
Iteration :  27   Loss :  0.111983166704
Iteration :  28   Loss :  0.109768530729
Iteration :  29   Loss :  0.107604060004
Iteration :  30   Loss :  0.105488662145
Iteration :  31   Loss :  0.103421279999
Iteration :  32   Loss :  0.10140089008
Iteration :  33   Loss :  0.0994265008781
Iteration :  34   Loss :  0.0974971509764
Iteration :  35   Loss :  0.0956119069387
Iteration :  36   Loss :  0.0937698609699
Iteration :  37   Loss :  0.0919701283817
Iteration :  38   Loss :  0.0902118449218
Iteration :  39   Loss :  0.0884941640491
Iteration :  40   Loss :  0.0868162542512
Iteration :  41   Loss :  0.0851772965081
Iteration :  42   Loss :  0.0835764820043
Iteration :  43   Loss :  0.0820130101848
Iteration :  44   Loss :  0.0804860872288
Iteration :  45   Loss :  0.0789949249987
Iteration :  46   Loss :  0.07753874049
Iteration :  47   Loss :  0.0761167557816
Iteration :  48   Loss :  0.0747281984568
Iteration :  49   Loss :  0.0733723024378
Iteration :  50   Loss :  0.0720483091563
Iteration :  51   Loss :  0.0707554689647
Iteration :  52   Loss :  0.0694930426847
Iteration :  53   Loss :  0.0682603031882
Iteration :  54   Loss :  0.0670565369105
Iteration :  55   Loss :  0.0658810452092
Iteration :  56   Loss :  0.0647331454978
Iteration :  57   Loss :  0.0636121721045
Iteration :  58   Loss :  0.0625174768286
Iteration :  59   Loss :  0.0614484291857
Iteration :  60   Loss :  0.0604044163553
Iteration :  61   Loss :  0.0593848428536
Iteration :  62   Loss :  0.0583891299716
Iteration :  63   Loss :  0.0574167150175
Iteration :  64   Loss :  0.0564670504081
Iteration :  65   Loss :  0.055539602652
Iteration :  66   Loss :  0.0546338512589
Iteration :  67   Loss :  0.053749287611
Iteration :  68   Loss :  0.0528854138214
Iteration :  69   Loss :  0.0520417416056
Iteration :  70   Loss :  0.051217791188
Iteration :  71   Loss :  0.0504130902684
Iteration :  72   Loss :  0.0496271730729
Iteration :  73   Loss :  0.0488595795205
Iteration :  74   Loss :  0.0481098545361
Iteration :  75   Loss :  0.047377547546
Iteration :  76   Loss :  0.0466622121874
Iteration :  77   Loss :  0.0459634062649
Iteration :  78   Loss :  0.0452806919752
Iteration :  79   Loss :  0.0446136364131
Iteration :  80   Loss :  0.0439618123589
Iteration :  81   Loss :  0.0433247993329
Iteration :  82   Loss :  0.0427021848855
Iteration :  83   Loss :  0.0420935660799
Iteration :  84   Loss :  0.041498551112
Iteration :  85   Loss :  0.0409167610017
Iteration :  86   Loss :  0.0403478312893
Iteration :  87   Loss :  0.0397914136648
Iteration :  88   Loss :  0.039247177468
Iteration :  89   Loss :  0.0387148109983
Iteration :  90   Loss :  0.0381940225874
Iteration :  91   Loss :  0.0376845413968
Iteration :  92   Loss :  0.0371861179152
Iteration :  93   Loss :  0.0366985241439
Iteration :  94   Loss :  0.0362215534668
Iteration :  95   Loss :  0.0357550202138
Iteration :  96   Loss :  0.0352987589336
Iteration :  97   Loss :  0.034852623396
Iteration :  98   Loss :  0.0344164853507
Iteration :  99   Loss :  0.0339902330691
[ -5.24649287e-04   2.32434052e-04  -3.44437165e-04 ...,   1.24902510e-04
  -6.25666401e-05   1.44997819e-04]
CROSS VALIDATION 51
Iteration :  0   Loss :  11.3585116316
Iteration :  1   Loss :  0.209468129379
Iteration :  2   Loss :  0.192152193302
Iteration :  3   Loss :  0.187995020453
Iteration :  4   Loss :  0.183999453765
Iteration :  5   Loss :  0.18013118689
Iteration :  6   Loss :  0.17637257331
Iteration :  7   Loss :  0.172713181481
Iteration :  8   Loss :  0.169146161723
Iteration :  9   Loss :  0.165666623917
Iteration :  10   Loss :  0.162270831315
Iteration :  11   Loss :  0.158955765697
Iteration :  12   Loss :  0.155718876844
Iteration :  13   Loss :  0.152557929989
Iteration :  14   Loss :  0.149470908407
Iteration :  15   Loss :  0.146455948585
Iteration :  16   Loss :  0.14351129553
Iteration :  17   Loss :  0.140635271073
Iteration :  18   Loss :  0.137826250963
Iteration :  19   Loss :  0.135082648192
Iteration :  20   Loss :  0.132402900966
Iteration :  21   Loss :  0.129785464332
Iteration :  22   Loss :  0.12722880478
Iteration :  23   Loss :  0.12473139736
Iteration :  24   Loss :  0.12229172496
Iteration :  25   Loss :  0.119908279411
Iteration :  26   Loss :  0.117579564143
Iteration :  27   Loss :  0.115304098078
Iteration :  28   Loss :  0.113080420453
Iteration :  29   Loss :  0.11090709626
Iteration :  30   Loss :  0.108782721972
Iteration :  31   Loss :  0.106705931262
Iteration :  32   Loss :  0.104675400424
Iteration :  33   Loss :  0.10268985323
Iteration :  34   Loss :  0.100748065049
Iteration :  35   Loss :  0.0988488660237
Iteration :  36   Loss :  0.0969911432454
Iteration :  37   Loss :  0.0951738418432
Iteration :  38   Loss :  0.0933959650036
Iteration :  39   Loss :  0.0916565729603
Iteration :  40   Loss :  0.0899547810345
Iteration :  41   Loss :  0.0882897568386
Iteration :  42   Loss :  0.0866607167741
Iteration :  43   Loss :  0.0850669219668
Iteration :  44   Loss :  0.0835076737894
Iteration :  45   Loss :  0.0819823091182
Iteration :  46   Loss :  0.080490195466
Iteration :  47   Loss :  0.0790307261203
Iteration :  48   Loss :  0.0776033154053
Iteration :  49   Loss :  0.076207394168
Iteration :  50   Loss :  0.0748424055739
Iteration :  51   Loss :  0.0735078012811
Iteration :  52   Loss :  0.0722030380429
Iteration :  53   Loss :  0.0709275747747
Iteration :  54   Loss :  0.0696808701065
Iteration :  55   Loss :  0.0684623804263
Iteration :  56   Loss :  0.0672715584093
Iteration :  57   Loss :  0.0661078520177
Iteration :  58   Loss :  0.0649707039437
Iteration :  59   Loss :  0.0638595514667
Iteration :  60   Loss :  0.0627738266838
Iteration :  61   Loss :  0.0617129570742
Iteration :  62   Loss :  0.0606763663513
Iteration :  63   Loss :  0.0596634755597
Iteration :  64   Loss :  0.0586737043694
Iteration :  65   Loss :  0.0577064725249
Iteration :  66   Loss :  0.0567612014068
Iteration :  67   Loss :  0.0558373156662
Iteration :  68   Loss :  0.0549342448968
Iteration :  69   Loss :  0.0540514253103
Iteration :  70   Loss :  0.053188301388
Iteration :  71   Loss :  0.0523443274809
Iteration :  72   Loss :  0.0515189693372
Iteration :  73   Loss :  0.0507117055367
Iteration :  74   Loss :  0.0499220288142
Iteration :  75   Loss :  0.0491494472593
Iteration :  76   Loss :  0.0483934853764
Iteration :  77   Loss :  0.0476536849962
Iteration :  78   Loss :  0.0469296060271
Iteration :  79   Loss :  0.0462208270414
Iteration :  80   Loss :  0.0455269456876
Iteration :  81   Loss :  0.0448475789291
Iteration :  82   Loss :  0.0441823631071
Iteration :  83   Loss :  0.0435309538313
Iteration :  84   Loss :  0.0428930257057
Iteration :  85   Loss :  0.0422682718976
Iteration :  86   Loss :  0.0416564035654
Iteration :  87   Loss :  0.0410571491599
Iteration :  88   Loss :  0.040470253619
Iteration :  89   Loss :  0.0398954774774
Iteration :  90   Loss :  0.0393325959142
Iteration :  91   Loss :  0.0387813977617
Iteration :  92   Loss :  0.0382416844999
Iteration :  93   Loss :  0.0377132692591
Iteration :  94   Loss :  0.0371959758524
Iteration :  95   Loss :  0.0366896378579
Iteration :  96   Loss :  0.0361940977669
Iteration :  97   Loss :  0.0357092062118
Iteration :  98   Loss :  0.035234821285
Iteration :  99   Loss :  0.0347708079547
[ -3.63898477e-04   2.10532636e-04  -1.13267198e-04 ...,   1.48034958e-04
  -9.83719176e-05   1.47534779e-04]
CROSS VALIDATION 52
Iteration :  0   Loss :  8.01552259952
Iteration :  1   Loss :  0.211592046374
Iteration :  2   Loss :  0.195085208988
Iteration :  3   Loss :  0.19056562007
Iteration :  4   Loss :  0.186316355137
Iteration :  5   Loss :  0.182256439029
Iteration :  6   Loss :  0.178345419369
Iteration :  7   Loss :  0.174560101619
Iteration :  8   Loss :  0.170885806911
Iteration :  9   Loss :  0.167312508277
Iteration :  10   Loss :  0.163832919407
Iteration :  11   Loss :  0.160441466873
Iteration :  12   Loss :  0.157133700502
Iteration :  13   Loss :  0.153905937248
Iteration :  14   Loss :  0.150755036889
Iteration :  15   Loss :  0.147678255828
Iteration :  16   Loss :  0.144673149033
Iteration :  17   Loss :  0.141737502669
Iteration :  18   Loss :  0.138869286862
Iteration :  19   Loss :  0.13606662194
Iteration :  20   Loss :  0.133327753879
Iteration :  21   Loss :  0.130651036086
Iteration :  22   Loss :  0.128034915559
Iteration :  23   Loss :  0.125477922084
Iteration :  24   Loss :  0.1229786595
Iteration :  25   Loss :  0.12053579836
Iteration :  26   Loss :  0.1181480695
Iteration :  27   Loss :  0.115814258207
Iteration :  28   Loss :  0.11353319876
Iteration :  29   Loss :  0.111303769214
Iteration :  30   Loss :  0.109124886381
Iteration :  31   Loss :  0.106995500986
Iteration :  32   Loss :  0.10491459303
Iteration :  33   Loss :  0.102881167418
Iteration :  34   Loss :  0.100894249913
Iteration :  35   Loss :  0.0989528834859
Iteration :  36   Loss :  0.0970561251479
Iteration :  37   Loss :  0.0952030433064
Iteration :  38   Loss :  0.0933927157076
Iteration :  39   Loss :  0.0916242279837
Iteration :  40   Loss :  0.0898966728144
Iteration :  41   Loss :  0.0882091496817
Iteration :  42   Loss :  0.0865607651747
Iteration :  43   Loss :  0.0849506337792
Iteration :  44   Loss :  0.0833778790645
Iteration :  45   Loss :  0.0818416351648
Iteration :  46   Loss :  0.0803410484443
Iteration :  47   Loss :  0.0788752792267
Iteration :  48   Loss :  0.0774435034777
Iteration :  49   Loss :  0.076044914333
Iteration :  50   Loss :  0.0746787233826
Iteration :  51   Loss :  0.0733441616406
Iteration :  52   Loss :  0.0720404801516
Iteration :  53   Loss :  0.0707669502091
Iteration :  54   Loss :  0.0695228631862
Iteration :  55   Loss :  0.0683075299998
Iteration :  56   Loss :  0.0671202802482
Iteration :  57   Loss :  0.0659604610795
Iteration :  58   Loss :  0.064827435856
Iteration :  59   Loss :  0.0637205826879
Iteration :  60   Loss :  0.0626392929116
Iteration :  61   Loss :  0.0615829695821
Iteration :  62   Loss :  0.0605510260488
Iteration :  63   Loss :  0.0595428846678
Iteration :  64   Loss :  0.0585579757004
Iteration :  65   Loss :  0.0575957364285
Iteration :  66   Loss :  0.0566556105093
Iteration :  67   Loss :  0.0557370475779
Iteration :  68   Loss :  0.0548395030928
Iteration :  69   Loss :  0.0539624384118
Iteration :  70   Loss :  0.0531053210767
Iteration :  71   Loss :  0.0522676252758
Iteration :  72   Loss :  0.0514488324554
Iteration :  73   Loss :  0.0506484320427
Iteration :  74   Loss :  0.0498659222486
Iteration :  75   Loss :  0.0491008109162
Iteration :  76   Loss :  0.0483526163876
Iteration :  77   Loss :  0.0476208683618
Iteration :  78   Loss :  0.0469051087239
Iteration :  79   Loss :  0.0462048923278
Iteration :  80   Loss :  0.0455197877188
Iteration :  81   Loss :  0.0448493777875
Iteration :  82   Loss :  0.0441932603461
Iteration :  83   Loss :  0.0435510486229
Iteration :  84   Loss :  0.042922371672
Iteration :  85   Loss :  0.0423068746951
Iteration :  86   Loss :  0.0417042192754
Iteration :  87   Loss :  0.041114083522
Iteration :  88   Loss :  0.040536162127
Iteration :  89   Loss :  0.0399701663353
Iteration :  90   Loss :  0.0394158238302
Iteration :  91   Loss :  0.0388728785372
Iteration :  92   Loss :  0.0383410903513
Iteration :  93   Loss :  0.0378202347917
Iteration :  94   Loss :  0.0373101025906
Iteration :  95   Loss :  0.0368104992232
Iteration :  96   Loss :  0.0363212443856
Iteration :  97   Loss :  0.0358421714299
Iteration :  98   Loss :  0.0353731267641
Iteration :  99   Loss :  0.0349139692251
[ -4.20524918e-04   1.75238664e-04  -1.58763121e-04 ...,   1.30283336e-04
  -4.31243478e-05   1.47855984e-04]
CROSS VALIDATION 53
Iteration :  0   Loss :  13.724966164
Iteration :  1   Loss :  0.190999591643
Iteration :  2   Loss :  0.181848459744
Iteration :  3   Loss :  0.177286639369
Iteration :  4   Loss :  0.17320289386
Iteration :  5   Loss :  0.169367076051
Iteration :  6   Loss :  0.165699428793
Iteration :  7   Loss :  0.162162845883
Iteration :  8   Loss :  0.158736943917
Iteration :  9   Loss :  0.155409180831
Iteration :  10   Loss :  0.152171150051
Iteration :  11   Loss :  0.149016819171
Iteration :  12   Loss :  0.145941610527
Iteration :  13   Loss :  0.142941885696
Iteration :  14   Loss :  0.14001463959
Iteration :  15   Loss :  0.137157310282
Iteration :  16   Loss :  0.13436765605
Iteration :  17   Loss :  0.13164367313
Iteration :  18   Loss :  0.128983539005
Iteration :  19   Loss :  0.126385572223
Iteration :  20   Loss :  0.123848203192
Iteration :  21   Loss :  0.121369952453
Iteration :  22   Loss :  0.118949414153
Iteration :  23   Loss :  0.116585243244
Iteration :  24   Loss :  0.114276145384
Iteration :  25   Loss :  0.112020868885
Iteration :  26   Loss :  0.10981819822
Iteration :  27   Loss :  0.107666948784
Iteration :  28   Loss :  0.105565962666
Iteration :  29   Loss :  0.103514105274
Iteration :  30   Loss :  0.101510262687
Iteration :  31   Loss :  0.0995533396364
Iteration :  32   Loss :  0.0976422580457
Iteration :  33   Loss :  0.095775956054
Iteration :  34   Loss :  0.0939533874735
Iteration :  35   Loss :  0.092173521625
Iteration :  36   Loss :  0.0904353435053
Iteration :  37   Loss :  0.0887378542392
Iteration :  38   Loss :  0.0870800717715
Iteration :  39   Loss :  0.0854610317528
Iteration :  40   Loss :  0.0838797885697
Iteration :  41   Loss :  0.0823354164674
Iteration :  42   Loss :  0.0808270107073
Iteration :  43   Loss :  0.0793536886987
Iteration :  44   Loss :  0.0779145910382
Iteration :  45   Loss :  0.0765088823896
Iteration :  46   Loss :  0.0751357521381
Iteration :  47   Loss :  0.0737944147579
Iteration :  48   Loss :  0.0724841098404
Iteration :  49   Loss :  0.0712041017451
Iteration :  50   Loss :  0.0699536788536
Iteration :  51   Loss :  0.0687321524269
Iteration :  52   Loss :  0.0675388550886
Iteration :  53   Loss :  0.06637313898
Iteration :  54   Loss :  0.0652343736527
Iteration :  55   Loss :  0.0641219437782
Iteration :  56   Loss :  0.0630352467701
Iteration :  57   Loss :  0.0619736904126
Iteration :  58   Loss :  0.0609366905946
Iteration :  59   Loss :  0.0599236692355
Iteration :  60   Loss :  0.0589340524807
Iteration :  61   Loss :  0.0579672692287
Iteration :  62   Loss :  0.0570227500304
Iteration :  63   Loss :  0.0560999263899
Iteration :  64   Loss :  0.0551982304715
Iteration :  65   Loss :  0.0543170952062
Iteration :  66   Loss :  0.0534559547772
Iteration :  67   Loss :  0.0526142454497
Iteration :  68   Loss :  0.0517914067059
Iteration :  69   Loss :  0.050986882635
Iteration :  70   Loss :  0.0502001235262
Iteration :  71   Loss :  0.0494305876086
Iteration :  72   Loss :  0.0486777428795
Iteration :  73   Loss :  0.0479410689618
Iteration :  74   Loss :  0.0472200589355
Iteration :  75   Loss :  0.0465142210867
Iteration :  76   Loss :  0.0458230805248
Iteration :  77   Loss :  0.0451461806255
Iteration :  78   Loss :  0.044483084261
Iteration :  79   Loss :  0.0438333747927
Iteration :  80   Loss :  0.0431966568067
Iteration :  81   Loss :  0.0425725565847
Iteration :  82   Loss :  0.0419607223132
Iteration :  83   Loss :  0.0413608240386
Iteration :  84   Loss :  0.040772553389
Iteration :  85   Loss :  0.0401956230858
Iteration :  86   Loss :  0.0396297662737
Iteration :  87   Loss :  0.0390747357021
Iteration :  88   Loss :  0.0385303027906
Iteration :  89   Loss :  0.037996256612
Iteration :  90   Loss :  0.037472402825
Iteration :  91   Loss :  0.036958562587
Iteration :  92   Loss :  0.0364545714719
Iteration :  93   Loss :  0.0359602784172
Iteration :  94   Loss :  0.0354755447189
Iteration :  95   Loss :  0.0350002430883
Iteration :  96   Loss :  0.0345342567815
Iteration :  97   Loss :  0.0340774788094
Iteration :  98   Loss :  0.0336298112295
Iteration :  99   Loss :  0.0331911645204
[ -4.42781457e-04   2.45333669e-04  -1.61192144e-04 ...,   1.30569778e-04
   9.66993185e-06   1.72477901e-04]
1   RFEF   0.000571515892168
2   LT   0.000509995953642
3   LFEF   0.000238462630591
4   LTRIA   0.000185340075806
5   LIT   -3.609247628e-05
6   RT   -9.89635797238e-05
7   LIFG   -0.000105767093443
8   LIPS   -0.000143015557731
9   LSGA   -0.000196331374515
10   LOPER   -0.000300412715486
11   RIT   -0.000342502244078
12   LIPL   -0.000506917379178
13   LDLPFC   -0.000569905372075
14   LPPREC   -0.000574169748458
15   SMA   -0.000690718300866
16   RIPS   -0.000994216123826
17   RPPREC   -0.00103991382611
18   LSPL   -0.00104180249592
19   RSPL   -0.00117855988743
20   CALC   -0.00126904968588
21   ROPER   -0.0012942850994
22   RTRIA   -0.00149556334261
23   RDLPFC   -0.00174464288825
24   RSGA   -0.00250841377638
25   RIPL   -0.00279909784526
Accuracy (Logistic Loss):	0.852941176471
CROSS VALIDATION 20
Iteration :  0   Loss :  21.0465072664
Iteration :  1   Loss :  1.63710708006
Iteration :  2   Loss :  1.10283688419
Iteration :  3   Loss :  0.30860030422
Iteration :  4   Loss :  0.30212619836
Iteration :  5   Loss :  0.295787912348
Iteration :  6   Loss :  0.28958259683
Iteration :  7   Loss :  0.283507462225
Iteration :  8   Loss :  0.277559777477
Iteration :  9   Loss :  0.271736868824
Iteration :  10   Loss :  0.266036118595
Iteration :  11   Loss :  0.260454964037
Iteration :  12   Loss :  0.254990896161
Iteration :  13   Loss :  0.249641458611
Iteration :  14   Loss :  0.244404246567
Iteration :  15   Loss :  0.239276905656
Iteration :  16   Loss :  0.234257130899
Iteration :  17   Loss :  0.229342665673
Iteration :  18   Loss :  0.224531300695
Iteration :  19   Loss :  0.219820873032
Iteration :  20   Loss :  0.215209265128
Iteration :  21   Loss :  0.210694403848
Iteration :  22   Loss :  0.206274259551
Iteration :  23   Loss :  0.201946845176
Iteration :  24   Loss :  0.197710215348
Iteration :  25   Loss :  0.193562465504
Iteration :  26   Loss :  0.189501731035
Iteration :  27   Loss :  0.185526186453
Iteration :  28   Loss :  0.181634044565
Iteration :  29   Loss :  0.177823555669
Iteration :  30   Loss :  0.174093006775
Iteration :  31   Loss :  0.170440720824
Iteration :  32   Loss :  0.166865055945
Iteration :  33   Loss :  0.163364404708
Iteration :  34   Loss :  0.159937193408
Iteration :  35   Loss :  0.156581881353
Iteration :  36   Loss :  0.153296960172
Iteration :  37   Loss :  0.150080953141
Iteration :  38   Loss :  0.146932414513
Iteration :  39   Loss :  0.143849928875
Iteration :  40   Loss :  0.140832110503
Iteration :  41   Loss :  0.137877602749
Iteration :  42   Loss :  0.134985077421
Iteration :  43   Loss :  0.132153234196
Iteration :  44   Loss :  0.129380800027
Iteration :  45   Loss :  0.126666528576
Iteration :  46   Loss :  0.12400919965
Iteration :  47   Loss :  0.121407618656
Iteration :  48   Loss :  0.118860616062
Iteration :  49   Loss :  0.116367046871
Iteration :  50   Loss :  0.113925790106
Iteration :  51   Loss :  0.11153574831
Iteration :  52   Loss :  0.109195847047
Iteration :  53   Loss :  0.106905034421
Iteration :  54   Loss :  0.104662280605
Iteration :  55   Loss :  0.102466577377
Iteration :  56   Loss :  0.100316937665
Iteration :  57   Loss :  0.0982123951058
Iteration :  58   Loss :  0.0961520036091
Iteration :  59   Loss :  0.0941348369325
Iteration :  60   Loss :  0.0921599882655
Iteration :  61   Loss :  0.0902265698212
Iteration :  62   Loss :  0.0883337124376
Iteration :  63   Loss :  0.0864805651868
Iteration :  64   Loss :  0.0846662949926
Iteration :  65   Loss :  0.0828900862556
Iteration :  66   Loss :  0.0811511404871
Iteration :  67   Loss :  0.0794486759497
Iteration :  68   Loss :  0.0777819273058
Iteration :  69   Loss :  0.0761501452741
Iteration :  70   Loss :  0.0745525962924
Iteration :  71   Loss :  0.0729885621876
Iteration :  72   Loss :  0.0714573398533
Iteration :  73   Loss :  0.0699582409335
Iteration :  74   Loss :  0.0684905915132
Iteration :  75   Loss :  0.0670537318153
Iteration :  76   Loss :  0.0656470159043
Iteration :  77   Loss :  0.0642698113955
Iteration :  78   Loss :  0.0629214991713
Iteration :  79   Loss :  0.0616014731021
Iteration :  80   Loss :  0.0603091397746
Iteration :  81   Loss :  0.0590439182246
Iteration :  82   Loss :  0.0578052396758
Iteration :  83   Loss :  0.0565925472843
Iteration :  84   Loss :  0.0554052958882
Iteration :  85   Loss :  0.0542429517626
Iteration :  86   Loss :  0.0531049923792
Iteration :  87   Loss :  0.0519909061724
Iteration :  88   Loss :  0.0509001923081
Iteration :  89   Loss :  0.0498323604596
Iteration :  90   Loss :  0.0487869305865
Iteration :  91   Loss :  0.0477634327192
Iteration :  92   Loss :  0.0467614067476
Iteration :  93   Loss :  0.0457804022142
Iteration :  94   Loss :  0.0448199781115
Iteration :  95   Loss :  0.0438797026841
Iteration :  96   Loss :  0.0429591532342
Iteration :  97   Loss :  0.0420579159318
Iteration :  98   Loss :  0.0411755856285
Iteration :  99   Loss :  0.0403117656757
[ -1.02917761e-03  -1.03769365e-04  -1.84274226e-04 ...,   7.82773867e-04
   4.72392452e-04   7.07149782e-05]
CROSS VALIDATION 21
Iteration :  0   Loss :  21.0465072664
Iteration :  1   Loss :  1.63710708006
Iteration :  2   Loss :  1.10283688419
Iteration :  3   Loss :  0.30860030422
Iteration :  4   Loss :  0.30212619836
Iteration :  5   Loss :  0.295787912348
Iteration :  6   Loss :  0.28958259683
Iteration :  7   Loss :  0.283507462225
Iteration :  8   Loss :  0.277559777477
Iteration :  9   Loss :  0.271736868824
Iteration :  10   Loss :  0.266036118595
Iteration :  11   Loss :  0.260454964037
Iteration :  12   Loss :  0.254990896161
Iteration :  13   Loss :  0.249641458611
Iteration :  14   Loss :  0.244404246567
Iteration :  15   Loss :  0.239276905656
Iteration :  16   Loss :  0.234257130899
Iteration :  17   Loss :  0.229342665673
Iteration :  18   Loss :  0.224531300695
Iteration :  19   Loss :  0.219820873032
Iteration :  20   Loss :  0.215209265128
Iteration :  21   Loss :  0.210694403848
Iteration :  22   Loss :  0.206274259551
Iteration :  23   Loss :  0.201946845176
Iteration :  24   Loss :  0.197710215348
Iteration :  25   Loss :  0.193562465504
Iteration :  26   Loss :  0.189501731035
Iteration :  27   Loss :  0.185526186453
Iteration :  28   Loss :  0.181634044565
Iteration :  29   Loss :  0.177823555669
Iteration :  30   Loss :  0.174093006775
Iteration :  31   Loss :  0.170440720824
Iteration :  32   Loss :  0.166865055945
Iteration :  33   Loss :  0.163364404708
Iteration :  34   Loss :  0.159937193408
Iteration :  35   Loss :  0.156581881353
Iteration :  36   Loss :  0.153296960172
Iteration :  37   Loss :  0.150080953141
Iteration :  38   Loss :  0.146932414513
Iteration :  39   Loss :  0.143849928875
Iteration :  40   Loss :  0.140832110503
Iteration :  41   Loss :  0.137877602749
Iteration :  42   Loss :  0.134985077421
Iteration :  43   Loss :  0.132153234196
Iteration :  44   Loss :  0.129380800027
Iteration :  45   Loss :  0.126666528576
Iteration :  46   Loss :  0.12400919965
Iteration :  47   Loss :  0.121407618656
Iteration :  48   Loss :  0.118860616062
Iteration :  49   Loss :  0.116367046871
Iteration :  50   Loss :  0.113925790106
Iteration :  51   Loss :  0.11153574831
Iteration :  52   Loss :  0.109195847047
Iteration :  53   Loss :  0.106905034421
Iteration :  54   Loss :  0.104662280605
Iteration :  55   Loss :  0.102466577377
Iteration :  56   Loss :  0.100316937665
Iteration :  57   Loss :  0.0982123951058
Iteration :  58   Loss :  0.0961520036091
Iteration :  59   Loss :  0.0941348369325
Iteration :  60   Loss :  0.0921599882655
Iteration :  61   Loss :  0.0902265698212
Iteration :  62   Loss :  0.0883337124376
Iteration :  63   Loss :  0.0864805651868
Iteration :  64   Loss :  0.0846662949926
Iteration :  65   Loss :  0.0828900862556
Iteration :  66   Loss :  0.0811511404871
Iteration :  67   Loss :  0.0794486759497
Iteration :  68   Loss :  0.0777819273058
Iteration :  69   Loss :  0.0761501452741
Iteration :  70   Loss :  0.0745525962924
Iteration :  71   Loss :  0.0729885621876
Iteration :  72   Loss :  0.0714573398533
Iteration :  73   Loss :  0.0699582409335
Iteration :  74   Loss :  0.0684905915132
Iteration :  75   Loss :  0.0670537318153
Iteration :  76   Loss :  0.0656470159043
Iteration :  77   Loss :  0.0642698113955
Iteration :  78   Loss :  0.0629214991713
Iteration :  79   Loss :  0.0616014731021
Iteration :  80   Loss :  0.0603091397746
Iteration :  81   Loss :  0.0590439182246
Iteration :  82   Loss :  0.0578052396758
Iteration :  83   Loss :  0.0565925472843
Iteration :  84   Loss :  0.0554052958882
Iteration :  85   Loss :  0.0542429517626
Iteration :  86   Loss :  0.0531049923792
Iteration :  87   Loss :  0.0519909061724
Iteration :  88   Loss :  0.0509001923081
Iteration :  89   Loss :  0.0498323604596
Iteration :  90   Loss :  0.0487869305865
Iteration :  91   Loss :  0.0477634327192
Iteration :  92   Loss :  0.0467614067476
Iteration :  93   Loss :  0.0457804022142
Iteration :  94   Loss :  0.0448199781115
Iteration :  95   Loss :  0.0438797026841
Iteration :  96   Loss :  0.0429591532342
Iteration :  97   Loss :  0.0420579159318
Iteration :  98   Loss :  0.0411755856285
Iteration :  99   Loss :  0.0403117656757
[ -1.02917761e-03  -1.03769365e-04  -1.84274226e-04 ...,   7.82773867e-04
   4.72392452e-04   7.07149782e-05]
CROSS VALIDATION 22
Iteration :  0   Loss :  21.0465072664
Iteration :  1   Loss :  1.63710708006
Iteration :  2   Loss :  1.10283688419
Iteration :  3   Loss :  0.30860030422
Iteration :  4   Loss :  0.30212619836
Iteration :  5   Loss :  0.295787912348
Iteration :  6   Loss :  0.28958259683
Iteration :  7   Loss :  0.283507462225
Iteration :  8   Loss :  0.277559777477
Iteration :  9   Loss :  0.271736868824
Iteration :  10   Loss :  0.266036118595
Iteration :  11   Loss :  0.260454964037
Iteration :  12   Loss :  0.254990896161
Iteration :  13   Loss :  0.249641458611
Iteration :  14   Loss :  0.244404246567
Iteration :  15   Loss :  0.239276905656
Iteration :  16   Loss :  0.234257130899
Iteration :  17   Loss :  0.229342665673
Iteration :  18   Loss :  0.224531300695
Iteration :  19   Loss :  0.219820873032
Iteration :  20   Loss :  0.215209265128
Iteration :  21   Loss :  0.210694403848
Iteration :  22   Loss :  0.206274259551
Iteration :  23   Loss :  0.201946845176
Iteration :  24   Loss :  0.197710215348
Iteration :  25   Loss :  0.193562465504
Iteration :  26   Loss :  0.189501731035
Iteration :  27   Loss :  0.185526186453
Iteration :  28   Loss :  0.181634044565
Iteration :  29   Loss :  0.177823555669
Iteration :  30   Loss :  0.174093006775
Iteration :  31   Loss :  0.170440720824
Iteration :  32   Loss :  0.166865055945
Iteration :  33   Loss :  0.163364404708
Iteration :  34   Loss :  0.159937193408
Iteration :  35   Loss :  0.156581881353
Iteration :  36   Loss :  0.153296960172
Iteration :  37   Loss :  0.150080953141
Iteration :  38   Loss :  0.146932414513
Iteration :  39   Loss :  0.143849928875
Iteration :  40   Loss :  0.140832110503
Iteration :  41   Loss :  0.137877602749
Iteration :  42   Loss :  0.134985077421
Iteration :  43   Loss :  0.132153234196
Iteration :  44   Loss :  0.129380800027
Iteration :  45   Loss :  0.126666528576
Iteration :  46   Loss :  0.12400919965
Iteration :  47   Loss :  0.121407618656
Iteration :  48   Loss :  0.118860616062
Iteration :  49   Loss :  0.116367046871
Iteration :  50   Loss :  0.113925790106
Iteration :  51   Loss :  0.11153574831
Iteration :  52   Loss :  0.109195847047
Iteration :  53   Loss :  0.106905034421
Iteration :  54   Loss :  0.104662280605
Iteration :  55   Loss :  0.102466577377
Iteration :  56   Loss :  0.100316937665
Iteration :  57   Loss :  0.0982123951058
Iteration :  58   Loss :  0.0961520036091
Iteration :  59   Loss :  0.0941348369325
Iteration :  60   Loss :  0.0921599882655
Iteration :  61   Loss :  0.0902265698212
Iteration :  62   Loss :  0.0883337124376
Iteration :  63   Loss :  0.0864805651868
Iteration :  64   Loss :  0.0846662949926
Iteration :  65   Loss :  0.0828900862556
Iteration :  66   Loss :  0.0811511404871
Iteration :  67   Loss :  0.0794486759497
Iteration :  68   Loss :  0.0777819273058
Iteration :  69   Loss :  0.0761501452741
Iteration :  70   Loss :  0.0745525962924
Iteration :  71   Loss :  0.0729885621876
Iteration :  72   Loss :  0.0714573398533
Iteration :  73   Loss :  0.0699582409335
Iteration :  74   Loss :  0.0684905915132
Iteration :  75   Loss :  0.0670537318153
Iteration :  76   Loss :  0.0656470159043
Iteration :  77   Loss :  0.0642698113955
Iteration :  78   Loss :  0.0629214991713
Iteration :  79   Loss :  0.0616014731021
Iteration :  80   Loss :  0.0603091397746
Iteration :  81   Loss :  0.0590439182246
Iteration :  82   Loss :  0.0578052396758
Iteration :  83   Loss :  0.0565925472843
Iteration :  84   Loss :  0.0554052958882
Iteration :  85   Loss :  0.0542429517626
Iteration :  86   Loss :  0.0531049923792
Iteration :  87   Loss :  0.0519909061724
Iteration :  88   Loss :  0.0509001923081
Iteration :  89   Loss :  0.0498323604596
Iteration :  90   Loss :  0.0487869305865
Iteration :  91   Loss :  0.0477634327192
Iteration :  92   Loss :  0.0467614067476
Iteration :  93   Loss :  0.0457804022142
Iteration :  94   Loss :  0.0448199781115
Iteration :  95   Loss :  0.0438797026841
Iteration :  96   Loss :  0.0429591532342
Iteration :  97   Loss :  0.0420579159318
Iteration :  98   Loss :  0.0411755856285
Iteration :  99   Loss :  0.0403117656757
[ -1.02917761e-03  -1.03769365e-04  -1.84274226e-04 ...,   7.82773867e-04
   4.72392452e-04   7.07149782e-05]
CROSS VALIDATION 23
Iteration :  0   Loss :  24.3124501954
Iteration :  1   Loss :  19.9294869013
Iteration :  2   Loss :  0.337836968679
Iteration :  3   Loss :  0.330749508722
Iteration :  4   Loss :  0.323810736131
Iteration :  5   Loss :  0.317017531601
Iteration :  6   Loss :  0.310366841271
Iteration :  7   Loss :  0.303855675344
Iteration :  8   Loss :  0.297481106747
Iteration :  9   Loss :  0.291240269813
Iteration :  10   Loss :  0.285130358994
Iteration :  11   Loss :  0.279148627599
Iteration :  12   Loss :  0.273292386561
Iteration :  13   Loss :  0.267559003226
Iteration :  14   Loss :  0.26194590017
Iteration :  15   Loss :  0.256450554041
Iteration :  16   Loss :  0.251070494423
Iteration :  17   Loss :  0.245803302729
Iteration :  18   Loss :  0.240646611109
Iteration :  19   Loss :  0.235598101389
Iteration :  20   Loss :  0.23065550403
Iteration :  21   Loss :  0.225816597101
Iteration :  22   Loss :  0.221079205288
Iteration :  23   Loss :  0.216441198912
Iteration :  24   Loss :  0.211900492973
Iteration :  25   Loss :  0.20745504621
Iteration :  26   Loss :  0.203102860188
Iteration :  27   Loss :  0.198841978396
Iteration :  28   Loss :  0.194670485368
Iteration :  29   Loss :  0.190586505822
Iteration :  30   Loss :  0.18658820382
Iteration :  31   Loss :  0.182673781938
Iteration :  32   Loss :  0.178841480459
Iteration :  33   Loss :  0.175089576586
Iteration :  34   Loss :  0.171416383662
Iteration :  35   Loss :  0.167820250415
Iteration :  36   Loss :  0.164299560215
Iteration :  37   Loss :  0.160852730348
Iteration :  38   Loss :  0.157478211302
Iteration :  39   Loss :  0.154174486073
Iteration :  40   Loss :  0.150940069483
Iteration :  41   Loss :  0.147773507509
Iteration :  42   Loss :  0.144673376635
Iteration :  43   Loss :  0.141638283206
Iteration :  44   Loss :  0.138666862806
Iteration :  45   Loss :  0.135757779643
Iteration :  46   Loss :  0.132909725948
Iteration :  47   Loss :  0.130121421387
Iteration :  48   Loss :  0.127391612488
Iteration :  49   Loss :  0.124719072074
Iteration :  50   Loss :  0.122102598712
Iteration :  51   Loss :  0.119541016176
Iteration :  52   Loss :  0.117033172915
Iteration :  53   Loss :  0.114577941535
Iteration :  54   Loss :  0.112174218297
Iteration :  55   Loss :  0.109820922612
Iteration :  56   Loss :  0.107516996567
Iteration :  57   Loss :  0.105261404436
Iteration :  58   Loss :  0.103053132228
Iteration :  59   Loss :  0.10089118722
Iteration :  60   Loss :  0.0987745975162
Iteration :  61   Loss :  0.0967024116114
Iteration :  62   Loss :  0.0946736979609
Iteration :  63   Loss :  0.0926875445631
Iteration :  64   Loss :  0.0907430585493
Iteration :  65   Loss :  0.088839365782
Iteration :  66   Loss :  0.0869756104624
Iteration :  67   Loss :  0.0851509547453
Iteration :  68   Loss :  0.0833645783627
Iteration :  69   Loss :  0.0816156782549
Iteration :  70   Loss :  0.0799034682096
Iteration :  71   Loss :  0.0782271785082
Iteration :  72   Loss :  0.0765860555803
Iteration :  73   Loss :  0.0749793616644
Iteration :  74   Loss :  0.0734063744764
Iteration :  75   Loss :  0.0718663868851
Iteration :  76   Loss :  0.070358706594
Iteration :  77   Loss :  0.0688826558305
Iteration :  78   Loss :  0.0674375710406
Iteration :  79   Loss :  0.0660228025912
Iteration :  80   Loss :  0.0646377144778
Iteration :  81   Loss :  0.0632816840386
Iteration :  82   Loss :  0.0619541016743
Iteration :  83   Loss :  0.0606543705748
Iteration :  84   Loss :  0.0593819064501
Iteration :  85   Loss :  0.0581361372682
Iteration :  86   Loss :  0.0569165029975
Iteration :  87   Loss :  0.0557224553554
Iteration :  88   Loss :  0.0545534575617
Iteration :  89   Loss :  0.0534089840973
Iteration :  90   Loss :  0.0522885204677
Iteration :  91   Loss :  0.0511915629724
Iteration :  92   Loss :  0.0501176184775
Iteration :  93   Loss :  0.0490662041949
Iteration :  94   Loss :  0.0480368474646
Iteration :  95   Loss :  0.0470290855427
Iteration :  96   Loss :  0.0460424653931
Iteration :  97   Loss :  0.0450765434839
Iteration :  98   Loss :  0.0441308855881
Iteration :  99   Loss :  0.0432050665883
[-0.00145382 -0.00032994 -0.00058449 ...,  0.00065603  0.00041546
  0.00013952]
CROSS VALIDATION 24
Iteration :  0   Loss :  21.0495713978
Iteration :  1   Loss :  1.63705936847
Iteration :  2   Loss :  1.1024810519
Iteration :  3   Loss :  0.308605440245
Iteration :  4   Loss :  0.302131226637
Iteration :  5   Loss :  0.295792835137
Iteration :  6   Loss :  0.289587416344
Iteration :  7   Loss :  0.283512180631
Iteration :  8   Loss :  0.277564396896
Iteration :  9   Loss :  0.271741391332
Iteration :  10   Loss :  0.266040546226
Iteration :  11   Loss :  0.260459298781
Iteration :  12   Loss :  0.254995139966
Iteration :  13   Loss :  0.249645613386
Iteration :  14   Loss :  0.244408314179
Iteration :  15   Loss :  0.239280887934
Iteration :  16   Loss :  0.234261029633
Iteration :  17   Loss :  0.229346482615
Iteration :  18   Loss :  0.224535037562
Iteration :  19   Loss :  0.219824531504
Iteration :  20   Loss :  0.215212846849
Iteration :  21   Loss :  0.210697910428
Iteration :  22   Loss :  0.206277692567
Iteration :  23   Loss :  0.201950206171
Iteration :  24   Loss :  0.197713505833
Iteration :  25   Loss :  0.193565686958
Iteration :  26   Loss :  0.189504884907
Iteration :  27   Loss :  0.18552927416
Iteration :  28   Loss :  0.181637067495
Iteration :  29   Loss :  0.177826515181
Iteration :  30   Loss :  0.174095904199
Iteration :  31   Loss :  0.170443557464
Iteration :  32   Loss :  0.166867833075
Iteration :  33   Loss :  0.163367123577
Iteration :  34   Loss :  0.159939855238
Iteration :  35   Loss :  0.15658448734
Iteration :  36   Loss :  0.153299511489
Iteration :  37   Loss :  0.150083450933
Iteration :  38   Loss :  0.146934859905
Iteration :  39   Loss :  0.143852322965
Iteration :  40   Loss :  0.140834454368
Iteration :  41   Loss :  0.137879897441
Iteration :  42   Loss :  0.134987323974
Iteration :  43   Loss :  0.132155433618
Iteration :  44   Loss :  0.129382953308
Iteration :  45   Loss :  0.126668636683
Iteration :  46   Loss :  0.124011263531
Iteration :  47   Loss :  0.121409639239
Iteration :  48   Loss :  0.118862594255
Iteration :  49   Loss :  0.116368983564
Iteration :  50   Loss :  0.11392768617
Iteration :  51   Loss :  0.111537604596
Iteration :  52   Loss :  0.10919766439
Iteration :  53   Loss :  0.106906813638
Iteration :  54   Loss :  0.104664022496
Iteration :  55   Loss :  0.102468282725
Iteration :  56   Loss :  0.100318607237
Iteration :  57   Loss :  0.0982140296517
Iteration :  58   Loss :  0.0961536038639
Iteration :  59   Loss :  0.0941364036157
Iteration :  60   Loss :  0.0921615220814
Iteration :  61   Loss :  0.0902280714592
Iteration :  62   Loss :  0.0883351825728
Iteration :  63   Loss :  0.0864820044802
Iteration :  64   Loss :  0.0846677040911
Iteration :  65   Loss :  0.0828914657928
Iteration :  66   Loss :  0.0811524910831
Iteration :  67   Loss :  0.0794499982115
Iteration :  68   Loss :  0.077783221828
Iteration :  69   Loss :  0.0761514126386
Iteration :  70   Loss :  0.0745538370689
Iteration :  71   Loss :  0.072989776934
Iteration :  72   Loss :  0.0714585291156
Iteration :  73   Loss :  0.0699594052463
Iteration :  74   Loss :  0.0684917314
Iteration :  75   Loss :  0.0670548477885
Iteration :  76   Loss :  0.0656481084655
Iteration :  77   Loss :  0.064270881036
Iteration :  78   Loss :  0.0629225463718
Iteration :  79   Loss :  0.0616024983335
Iteration :  80   Loss :  0.0603101434978
Iteration :  81   Loss :  0.0590449008907
Iteration :  82   Loss :  0.0578062017266
Iteration :  83   Loss :  0.0565934891524
Iteration :  84   Loss :  0.0554062179969
Iteration :  85   Loss :  0.0542438545263
Iteration :  86   Loss :  0.053105876204
Iteration :  87   Loss :  0.0519917714554
Iteration :  88   Loss :  0.0509010394384
Iteration :  89   Loss :  0.049833189818
Iteration :  90   Loss :  0.0487877425458
Iteration :  91   Loss :  0.0477642276445
Iteration :  92   Loss :  0.0467621849962
Iteration :  93   Loss :  0.045781164136
Iteration :  94   Loss :  0.044820724049
Iteration :  95   Loss :  0.0438804329726
Iteration :  96   Loss :  0.042959868202
Iteration :  97   Loss :  0.0420586159004
Iteration :  98   Loss :  0.0411762709125
Iteration :  99   Loss :  0.0403124365832
[ -1.02911210e-03  -1.03766398e-04  -1.84247476e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 25
Iteration :  0   Loss :  21.0495713978
Iteration :  1   Loss :  1.63705936847
Iteration :  2   Loss :  1.1024810519
Iteration :  3   Loss :  0.308605440245
Iteration :  4   Loss :  0.302131226637
Iteration :  5   Loss :  0.295792835137
Iteration :  6   Loss :  0.289587416344
Iteration :  7   Loss :  0.283512180631
Iteration :  8   Loss :  0.277564396896
Iteration :  9   Loss :  0.271741391332
Iteration :  10   Loss :  0.266040546226
Iteration :  11   Loss :  0.260459298781
Iteration :  12   Loss :  0.254995139966
Iteration :  13   Loss :  0.249645613386
Iteration :  14   Loss :  0.244408314179
Iteration :  15   Loss :  0.239280887934
Iteration :  16   Loss :  0.234261029633
Iteration :  17   Loss :  0.229346482615
Iteration :  18   Loss :  0.224535037562
Iteration :  19   Loss :  0.219824531504
Iteration :  20   Loss :  0.215212846849
Iteration :  21   Loss :  0.210697910428
Iteration :  22   Loss :  0.206277692567
Iteration :  23   Loss :  0.201950206171
Iteration :  24   Loss :  0.197713505833
Iteration :  25   Loss :  0.193565686958
Iteration :  26   Loss :  0.189504884907
Iteration :  27   Loss :  0.18552927416
Iteration :  28   Loss :  0.181637067495
Iteration :  29   Loss :  0.177826515181
Iteration :  30   Loss :  0.174095904199
Iteration :  31   Loss :  0.170443557464
Iteration :  32   Loss :  0.166867833075
Iteration :  33   Loss :  0.163367123577
Iteration :  34   Loss :  0.159939855238
Iteration :  35   Loss :  0.15658448734
Iteration :  36   Loss :  0.153299511489
Iteration :  37   Loss :  0.150083450933
Iteration :  38   Loss :  0.146934859905
Iteration :  39   Loss :  0.143852322965
Iteration :  40   Loss :  0.140834454368
Iteration :  41   Loss :  0.137879897441
Iteration :  42   Loss :  0.134987323974
Iteration :  43   Loss :  0.132155433618
Iteration :  44   Loss :  0.129382953308
Iteration :  45   Loss :  0.126668636683
Iteration :  46   Loss :  0.124011263531
Iteration :  47   Loss :  0.121409639239
Iteration :  48   Loss :  0.118862594255
Iteration :  49   Loss :  0.116368983564
Iteration :  50   Loss :  0.11392768617
Iteration :  51   Loss :  0.111537604596
Iteration :  52   Loss :  0.10919766439
Iteration :  53   Loss :  0.106906813638
Iteration :  54   Loss :  0.104664022496
Iteration :  55   Loss :  0.102468282725
Iteration :  56   Loss :  0.100318607237
Iteration :  57   Loss :  0.0982140296517
Iteration :  58   Loss :  0.0961536038639
Iteration :  59   Loss :  0.0941364036157
Iteration :  60   Loss :  0.0921615220814
Iteration :  61   Loss :  0.0902280714592
Iteration :  62   Loss :  0.0883351825728
Iteration :  63   Loss :  0.0864820044802
Iteration :  64   Loss :  0.0846677040911
Iteration :  65   Loss :  0.0828914657928
Iteration :  66   Loss :  0.0811524910831
Iteration :  67   Loss :  0.0794499982115
Iteration :  68   Loss :  0.077783221828
Iteration :  69   Loss :  0.0761514126386
Iteration :  70   Loss :  0.0745538370689
Iteration :  71   Loss :  0.072989776934
Iteration :  72   Loss :  0.0714585291156
Iteration :  73   Loss :  0.0699594052463
Iteration :  74   Loss :  0.0684917314
Iteration :  75   Loss :  0.0670548477885
Iteration :  76   Loss :  0.0656481084655
Iteration :  77   Loss :  0.064270881036
Iteration :  78   Loss :  0.0629225463718
Iteration :  79   Loss :  0.0616024983335
Iteration :  80   Loss :  0.0603101434978
Iteration :  81   Loss :  0.0590449008907
Iteration :  82   Loss :  0.0578062017266
Iteration :  83   Loss :  0.0565934891524
Iteration :  84   Loss :  0.0554062179969
Iteration :  85   Loss :  0.0542438545263
Iteration :  86   Loss :  0.053105876204
Iteration :  87   Loss :  0.0519917714554
Iteration :  88   Loss :  0.0509010394384
Iteration :  89   Loss :  0.049833189818
Iteration :  90   Loss :  0.0487877425458
Iteration :  91   Loss :  0.0477642276445
Iteration :  92   Loss :  0.0467621849962
Iteration :  93   Loss :  0.045781164136
Iteration :  94   Loss :  0.044820724049
Iteration :  95   Loss :  0.0438804329726
Iteration :  96   Loss :  0.042959868202
Iteration :  97   Loss :  0.0420586159004
Iteration :  98   Loss :  0.0411762709125
Iteration :  99   Loss :  0.0403124365832
[ -1.02911210e-03  -1.03766398e-04  -1.84247476e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 26
Iteration :  0   Loss :  21.0495713978
Iteration :  1   Loss :  1.63705936847
Iteration :  2   Loss :  1.1024810519
Iteration :  3   Loss :  0.308605440245
Iteration :  4   Loss :  0.302131226637
Iteration :  5   Loss :  0.295792835137
Iteration :  6   Loss :  0.289587416344
Iteration :  7   Loss :  0.283512180631
Iteration :  8   Loss :  0.277564396896
Iteration :  9   Loss :  0.271741391332
Iteration :  10   Loss :  0.266040546226
Iteration :  11   Loss :  0.260459298781
Iteration :  12   Loss :  0.254995139966
Iteration :  13   Loss :  0.249645613386
Iteration :  14   Loss :  0.244408314179
Iteration :  15   Loss :  0.239280887934
Iteration :  16   Loss :  0.234261029633
Iteration :  17   Loss :  0.229346482615
Iteration :  18   Loss :  0.224535037562
Iteration :  19   Loss :  0.219824531504
Iteration :  20   Loss :  0.215212846849
Iteration :  21   Loss :  0.210697910428
Iteration :  22   Loss :  0.206277692567
Iteration :  23   Loss :  0.201950206171
Iteration :  24   Loss :  0.197713505833
Iteration :  25   Loss :  0.193565686958
Iteration :  26   Loss :  0.189504884907
Iteration :  27   Loss :  0.18552927416
Iteration :  28   Loss :  0.181637067495
Iteration :  29   Loss :  0.177826515181
Iteration :  30   Loss :  0.174095904199
Iteration :  31   Loss :  0.170443557464
Iteration :  32   Loss :  0.166867833075
Iteration :  33   Loss :  0.163367123577
Iteration :  34   Loss :  0.159939855238
Iteration :  35   Loss :  0.15658448734
Iteration :  36   Loss :  0.153299511489
Iteration :  37   Loss :  0.150083450933
Iteration :  38   Loss :  0.146934859905
Iteration :  39   Loss :  0.143852322965
Iteration :  40   Loss :  0.140834454368
Iteration :  41   Loss :  0.137879897441
Iteration :  42   Loss :  0.134987323974
Iteration :  43   Loss :  0.132155433618
Iteration :  44   Loss :  0.129382953308
Iteration :  45   Loss :  0.126668636683
Iteration :  46   Loss :  0.124011263531
Iteration :  47   Loss :  0.121409639239
Iteration :  48   Loss :  0.118862594255
Iteration :  49   Loss :  0.116368983564
Iteration :  50   Loss :  0.11392768617
Iteration :  51   Loss :  0.111537604596
Iteration :  52   Loss :  0.10919766439
Iteration :  53   Loss :  0.106906813638
Iteration :  54   Loss :  0.104664022496
Iteration :  55   Loss :  0.102468282725
Iteration :  56   Loss :  0.100318607237
Iteration :  57   Loss :  0.0982140296517
Iteration :  58   Loss :  0.0961536038639
Iteration :  59   Loss :  0.0941364036157
Iteration :  60   Loss :  0.0921615220814
Iteration :  61   Loss :  0.0902280714592
Iteration :  62   Loss :  0.0883351825728
Iteration :  63   Loss :  0.0864820044802
Iteration :  64   Loss :  0.0846677040911
Iteration :  65   Loss :  0.0828914657928
Iteration :  66   Loss :  0.0811524910831
Iteration :  67   Loss :  0.0794499982115
Iteration :  68   Loss :  0.077783221828
Iteration :  69   Loss :  0.0761514126386
Iteration :  70   Loss :  0.0745538370689
Iteration :  71   Loss :  0.072989776934
Iteration :  72   Loss :  0.0714585291156
Iteration :  73   Loss :  0.0699594052463
Iteration :  74   Loss :  0.0684917314
Iteration :  75   Loss :  0.0670548477885
Iteration :  76   Loss :  0.0656481084655
Iteration :  77   Loss :  0.064270881036
Iteration :  78   Loss :  0.0629225463718
Iteration :  79   Loss :  0.0616024983335
Iteration :  80   Loss :  0.0603101434978
Iteration :  81   Loss :  0.0590449008907
Iteration :  82   Loss :  0.0578062017266
Iteration :  83   Loss :  0.0565934891524
Iteration :  84   Loss :  0.0554062179969
Iteration :  85   Loss :  0.0542438545263
Iteration :  86   Loss :  0.053105876204
Iteration :  87   Loss :  0.0519917714554
Iteration :  88   Loss :  0.0509010394384
Iteration :  89   Loss :  0.049833189818
Iteration :  90   Loss :  0.0487877425458
Iteration :  91   Loss :  0.0477642276445
Iteration :  92   Loss :  0.0467621849962
Iteration :  93   Loss :  0.045781164136
Iteration :  94   Loss :  0.044820724049
Iteration :  95   Loss :  0.0438804329726
Iteration :  96   Loss :  0.042959868202
Iteration :  97   Loss :  0.0420586159004
Iteration :  98   Loss :  0.0411762709125
Iteration :  99   Loss :  0.0403124365832
[ -1.02911210e-03  -1.03766398e-04  -1.84247476e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 27
Iteration :  0   Loss :  21.0495713978
Iteration :  1   Loss :  1.63705936847
Iteration :  2   Loss :  1.1024810519
Iteration :  3   Loss :  0.308605440245
Iteration :  4   Loss :  0.302131226637
Iteration :  5   Loss :  0.295792835137
Iteration :  6   Loss :  0.289587416344
Iteration :  7   Loss :  0.283512180631
Iteration :  8   Loss :  0.277564396896
Iteration :  9   Loss :  0.271741391332
Iteration :  10   Loss :  0.266040546226
Iteration :  11   Loss :  0.260459298781
Iteration :  12   Loss :  0.254995139966
Iteration :  13   Loss :  0.249645613386
Iteration :  14   Loss :  0.244408314179
Iteration :  15   Loss :  0.239280887934
Iteration :  16   Loss :  0.234261029633
Iteration :  17   Loss :  0.229346482615
Iteration :  18   Loss :  0.224535037562
Iteration :  19   Loss :  0.219824531504
Iteration :  20   Loss :  0.215212846849
Iteration :  21   Loss :  0.210697910428
Iteration :  22   Loss :  0.206277692567
Iteration :  23   Loss :  0.201950206171
Iteration :  24   Loss :  0.197713505833
Iteration :  25   Loss :  0.193565686958
Iteration :  26   Loss :  0.189504884907
Iteration :  27   Loss :  0.18552927416
Iteration :  28   Loss :  0.181637067495
Iteration :  29   Loss :  0.177826515181
Iteration :  30   Loss :  0.174095904199
Iteration :  31   Loss :  0.170443557464
Iteration :  32   Loss :  0.166867833075
Iteration :  33   Loss :  0.163367123577
Iteration :  34   Loss :  0.159939855238
Iteration :  35   Loss :  0.15658448734
Iteration :  36   Loss :  0.153299511489
Iteration :  37   Loss :  0.150083450933
Iteration :  38   Loss :  0.146934859905
Iteration :  39   Loss :  0.143852322965
Iteration :  40   Loss :  0.140834454368
Iteration :  41   Loss :  0.137879897441
Iteration :  42   Loss :  0.134987323974
Iteration :  43   Loss :  0.132155433618
Iteration :  44   Loss :  0.129382953308
Iteration :  45   Loss :  0.126668636683
Iteration :  46   Loss :  0.124011263531
Iteration :  47   Loss :  0.121409639239
Iteration :  48   Loss :  0.118862594255
Iteration :  49   Loss :  0.116368983564
Iteration :  50   Loss :  0.11392768617
Iteration :  51   Loss :  0.111537604596
Iteration :  52   Loss :  0.10919766439
Iteration :  53   Loss :  0.106906813638
Iteration :  54   Loss :  0.104664022496
Iteration :  55   Loss :  0.102468282725
Iteration :  56   Loss :  0.100318607237
Iteration :  57   Loss :  0.0982140296517
Iteration :  58   Loss :  0.0961536038639
Iteration :  59   Loss :  0.0941364036157
Iteration :  60   Loss :  0.0921615220814
Iteration :  61   Loss :  0.0902280714592
Iteration :  62   Loss :  0.0883351825728
Iteration :  63   Loss :  0.0864820044802
Iteration :  64   Loss :  0.0846677040911
Iteration :  65   Loss :  0.0828914657928
Iteration :  66   Loss :  0.0811524910831
Iteration :  67   Loss :  0.0794499982115
Iteration :  68   Loss :  0.077783221828
Iteration :  69   Loss :  0.0761514126386
Iteration :  70   Loss :  0.0745538370689
Iteration :  71   Loss :  0.072989776934
Iteration :  72   Loss :  0.0714585291156
Iteration :  73   Loss :  0.0699594052463
Iteration :  74   Loss :  0.0684917314
Iteration :  75   Loss :  0.0670548477885
Iteration :  76   Loss :  0.0656481084655
Iteration :  77   Loss :  0.064270881036
Iteration :  78   Loss :  0.0629225463718
Iteration :  79   Loss :  0.0616024983335
Iteration :  80   Loss :  0.0603101434978
Iteration :  81   Loss :  0.0590449008907
Iteration :  82   Loss :  0.0578062017266
Iteration :  83   Loss :  0.0565934891524
Iteration :  84   Loss :  0.0554062179969
Iteration :  85   Loss :  0.0542438545263
Iteration :  86   Loss :  0.053105876204
Iteration :  87   Loss :  0.0519917714554
Iteration :  88   Loss :  0.0509010394384
Iteration :  89   Loss :  0.049833189818
Iteration :  90   Loss :  0.0487877425458
Iteration :  91   Loss :  0.0477642276445
Iteration :  92   Loss :  0.0467621849962
Iteration :  93   Loss :  0.045781164136
Iteration :  94   Loss :  0.044820724049
Iteration :  95   Loss :  0.0438804329726
Iteration :  96   Loss :  0.042959868202
Iteration :  97   Loss :  0.0420586159004
Iteration :  98   Loss :  0.0411762709125
Iteration :  99   Loss :  0.0403124365832
[ -1.02911210e-03  -1.03766398e-04  -1.84247476e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 28
Iteration :  0   Loss :  19.6750597735
Iteration :  1   Loss :  1.63705936847
Iteration :  2   Loss :  1.1024810519
Iteration :  3   Loss :  0.308605440245
Iteration :  4   Loss :  0.302131226637
Iteration :  5   Loss :  0.295792835137
Iteration :  6   Loss :  0.289587416344
Iteration :  7   Loss :  0.283512180631
Iteration :  8   Loss :  0.277564396896
Iteration :  9   Loss :  0.271741391332
Iteration :  10   Loss :  0.266040546226
Iteration :  11   Loss :  0.260459298781
Iteration :  12   Loss :  0.254995139966
Iteration :  13   Loss :  0.249645613386
Iteration :  14   Loss :  0.244408314179
Iteration :  15   Loss :  0.239280887934
Iteration :  16   Loss :  0.234261029633
Iteration :  17   Loss :  0.229346482615
Iteration :  18   Loss :  0.224535037562
Iteration :  19   Loss :  0.219824531504
Iteration :  20   Loss :  0.215212846849
Iteration :  21   Loss :  0.210697910428
Iteration :  22   Loss :  0.206277692567
Iteration :  23   Loss :  0.201950206171
Iteration :  24   Loss :  0.197713505833
Iteration :  25   Loss :  0.193565686958
Iteration :  26   Loss :  0.189504884907
Iteration :  27   Loss :  0.18552927416
Iteration :  28   Loss :  0.181637067495
Iteration :  29   Loss :  0.177826515181
Iteration :  30   Loss :  0.174095904199
Iteration :  31   Loss :  0.170443557464
Iteration :  32   Loss :  0.166867833075
Iteration :  33   Loss :  0.163367123577
Iteration :  34   Loss :  0.159939855238
Iteration :  35   Loss :  0.15658448734
Iteration :  36   Loss :  0.153299511489
Iteration :  37   Loss :  0.150083450933
Iteration :  38   Loss :  0.146934859905
Iteration :  39   Loss :  0.143852322965
Iteration :  40   Loss :  0.140834454368
Iteration :  41   Loss :  0.137879897441
Iteration :  42   Loss :  0.134987323974
Iteration :  43   Loss :  0.132155433618
Iteration :  44   Loss :  0.129382953308
Iteration :  45   Loss :  0.126668636683
Iteration :  46   Loss :  0.124011263531
Iteration :  47   Loss :  0.121409639239
Iteration :  48   Loss :  0.118862594255
Iteration :  49   Loss :  0.116368983564
Iteration :  50   Loss :  0.11392768617
Iteration :  51   Loss :  0.111537604596
Iteration :  52   Loss :  0.10919766439
Iteration :  53   Loss :  0.106906813638
Iteration :  54   Loss :  0.104664022496
Iteration :  55   Loss :  0.102468282725
Iteration :  56   Loss :  0.100318607237
Iteration :  57   Loss :  0.0982140296517
Iteration :  58   Loss :  0.0961536038639
Iteration :  59   Loss :  0.0941364036157
Iteration :  60   Loss :  0.0921615220814
Iteration :  61   Loss :  0.0902280714592
Iteration :  62   Loss :  0.0883351825728
Iteration :  63   Loss :  0.0864820044802
Iteration :  64   Loss :  0.0846677040911
Iteration :  65   Loss :  0.0828914657928
Iteration :  66   Loss :  0.0811524910831
Iteration :  67   Loss :  0.0794499982115
Iteration :  68   Loss :  0.077783221828
Iteration :  69   Loss :  0.0761514126386
Iteration :  70   Loss :  0.0745538370689
Iteration :  71   Loss :  0.072989776934
Iteration :  72   Loss :  0.0714585291156
Iteration :  73   Loss :  0.0699594052463
Iteration :  74   Loss :  0.0684917314
Iteration :  75   Loss :  0.0670548477885
Iteration :  76   Loss :  0.0656481084655
Iteration :  77   Loss :  0.064270881036
Iteration :  78   Loss :  0.0629225463718
Iteration :  79   Loss :  0.0616024983335
Iteration :  80   Loss :  0.0603101434978
Iteration :  81   Loss :  0.0590449008907
Iteration :  82   Loss :  0.0578062017266
Iteration :  83   Loss :  0.0565934891524
Iteration :  84   Loss :  0.0554062179969
Iteration :  85   Loss :  0.0542438545263
Iteration :  86   Loss :  0.053105876204
Iteration :  87   Loss :  0.0519917714554
Iteration :  88   Loss :  0.0509010394384
Iteration :  89   Loss :  0.049833189818
Iteration :  90   Loss :  0.0487877425458
Iteration :  91   Loss :  0.0477642276445
Iteration :  92   Loss :  0.0467621849962
Iteration :  93   Loss :  0.045781164136
Iteration :  94   Loss :  0.044820724049
Iteration :  95   Loss :  0.0438804329726
Iteration :  96   Loss :  0.042959868202
Iteration :  97   Loss :  0.0420586159004
Iteration :  98   Loss :  0.0411762709125
Iteration :  99   Loss :  0.0403124365832
[ -1.02911210e-03  -1.03766398e-04  -1.84247476e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 29
Iteration :  0   Loss :  21.0495713978
Iteration :  1   Loss :  1.63705936847
Iteration :  2   Loss :  1.1024810519
Iteration :  3   Loss :  0.308605440245
Iteration :  4   Loss :  0.302131226637
Iteration :  5   Loss :  0.295792835137
Iteration :  6   Loss :  0.289587416344
Iteration :  7   Loss :  0.283512180631
Iteration :  8   Loss :  0.277564396896
Iteration :  9   Loss :  0.271741391332
Iteration :  10   Loss :  0.266040546226
Iteration :  11   Loss :  0.260459298781
Iteration :  12   Loss :  0.254995139966
Iteration :  13   Loss :  0.249645613386
Iteration :  14   Loss :  0.244408314179
Iteration :  15   Loss :  0.239280887934
Iteration :  16   Loss :  0.234261029633
Iteration :  17   Loss :  0.229346482615
Iteration :  18   Loss :  0.224535037562
Iteration :  19   Loss :  0.219824531504
Iteration :  20   Loss :  0.215212846849
Iteration :  21   Loss :  0.210697910428
Iteration :  22   Loss :  0.206277692567
Iteration :  23   Loss :  0.201950206171
Iteration :  24   Loss :  0.197713505833
Iteration :  25   Loss :  0.193565686958
Iteration :  26   Loss :  0.189504884907
Iteration :  27   Loss :  0.18552927416
Iteration :  28   Loss :  0.181637067495
Iteration :  29   Loss :  0.177826515181
Iteration :  30   Loss :  0.174095904199
Iteration :  31   Loss :  0.170443557464
Iteration :  32   Loss :  0.166867833075
Iteration :  33   Loss :  0.163367123577
Iteration :  34   Loss :  0.159939855238
Iteration :  35   Loss :  0.15658448734
Iteration :  36   Loss :  0.153299511489
Iteration :  37   Loss :  0.150083450933
Iteration :  38   Loss :  0.146934859905
Iteration :  39   Loss :  0.143852322965
Iteration :  40   Loss :  0.140834454368
Iteration :  41   Loss :  0.137879897441
Iteration :  42   Loss :  0.134987323974
Iteration :  43   Loss :  0.132155433618
Iteration :  44   Loss :  0.129382953308
Iteration :  45   Loss :  0.126668636683
Iteration :  46   Loss :  0.124011263531
Iteration :  47   Loss :  0.121409639239
Iteration :  48   Loss :  0.118862594255
Iteration :  49   Loss :  0.116368983564
Iteration :  50   Loss :  0.11392768617
Iteration :  51   Loss :  0.111537604596
Iteration :  52   Loss :  0.10919766439
Iteration :  53   Loss :  0.106906813638
Iteration :  54   Loss :  0.104664022496
Iteration :  55   Loss :  0.102468282725
Iteration :  56   Loss :  0.100318607237
Iteration :  57   Loss :  0.0982140296517
Iteration :  58   Loss :  0.0961536038639
Iteration :  59   Loss :  0.0941364036157
Iteration :  60   Loss :  0.0921615220814
Iteration :  61   Loss :  0.0902280714592
Iteration :  62   Loss :  0.0883351825728
Iteration :  63   Loss :  0.0864820044802
Iteration :  64   Loss :  0.0846677040911
Iteration :  65   Loss :  0.0828914657928
Iteration :  66   Loss :  0.0811524910831
Iteration :  67   Loss :  0.0794499982115
Iteration :  68   Loss :  0.077783221828
Iteration :  69   Loss :  0.0761514126386
Iteration :  70   Loss :  0.0745538370689
Iteration :  71   Loss :  0.072989776934
Iteration :  72   Loss :  0.0714585291156
Iteration :  73   Loss :  0.0699594052463
Iteration :  74   Loss :  0.0684917314
Iteration :  75   Loss :  0.0670548477885
Iteration :  76   Loss :  0.0656481084655
Iteration :  77   Loss :  0.064270881036
Iteration :  78   Loss :  0.0629225463718
Iteration :  79   Loss :  0.0616024983335
Iteration :  80   Loss :  0.0603101434978
Iteration :  81   Loss :  0.0590449008907
Iteration :  82   Loss :  0.0578062017266
Iteration :  83   Loss :  0.0565934891524
Iteration :  84   Loss :  0.0554062179969
Iteration :  85   Loss :  0.0542438545263
Iteration :  86   Loss :  0.053105876204
Iteration :  87   Loss :  0.0519917714554
Iteration :  88   Loss :  0.0509010394384
Iteration :  89   Loss :  0.049833189818
Iteration :  90   Loss :  0.0487877425458
Iteration :  91   Loss :  0.0477642276445
Iteration :  92   Loss :  0.0467621849962
Iteration :  93   Loss :  0.045781164136
Iteration :  94   Loss :  0.044820724049
Iteration :  95   Loss :  0.0438804329726
Iteration :  96   Loss :  0.042959868202
Iteration :  97   Loss :  0.0420586159004
Iteration :  98   Loss :  0.0411762709125
Iteration :  99   Loss :  0.0403124365832
[ -1.02911210e-03  -1.03766398e-04  -1.84247476e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 30
Iteration :  0   Loss :  32.1658728605
Iteration :  1   Loss :  0.270158321935
Iteration :  2   Loss :  0.264490687939
Iteration :  3   Loss :  0.258941954871
Iteration :  4   Loss :  0.253509628316
Iteration :  5   Loss :  0.248191266189
Iteration :  6   Loss :  0.242984477638
Iteration :  7   Loss :  0.237886921968
Iteration :  8   Loss :  0.232896307589
Iteration :  9   Loss :  0.228010390987
Iteration :  10   Loss :  0.223226975714
Iteration :  11   Loss :  0.218543911401
Iteration :  12   Loss :  0.213959092792
Iteration :  13   Loss :  0.209470458797
Iteration :  14   Loss :  0.205075991564
Iteration :  15   Loss :  0.200773715576
Iteration :  16   Loss :  0.196561696758
Iteration :  17   Loss :  0.192438041611
Iteration :  18   Loss :  0.188400896359
Iteration :  19   Loss :  0.184448446117
Iteration :  20   Loss :  0.180578914073
Iteration :  21   Loss :  0.176790560692
Iteration :  22   Loss :  0.173081682932
Iteration :  23   Loss :  0.169450613479
Iteration :  24   Loss :  0.165895719998
Iteration :  25   Loss :  0.162415404398
Iteration :  26   Loss :  0.159008102114
Iteration :  27   Loss :  0.155672281405
Iteration :  28   Loss :  0.152406442663
Iteration :  29   Loss :  0.149209117741
Iteration :  30   Loss :  0.146078869292
Iteration :  31   Loss :  0.143014290124
Iteration :  32   Loss :  0.140014002563
Iteration :  33   Loss :  0.137076657842
Iteration :  34   Loss :  0.134200935487
Iteration :  35   Loss :  0.131385542725
Iteration :  36   Loss :  0.128629213905
Iteration :  37   Loss :  0.125930709931
Iteration :  38   Loss :  0.123288817697
Iteration :  39   Loss :  0.120702349549
Iteration :  40   Loss :  0.11817014275
Iteration :  41   Loss :  0.115691058954
Iteration :  42   Loss :  0.113263983697
Iteration :  43   Loss :  0.110887825895
Iteration :  44   Loss :  0.108561517354
Iteration :  45   Loss :  0.106284012289
Iteration :  46   Loss :  0.104054286857
Iteration :  47   Loss :  0.10187133869
Iteration :  48   Loss :  0.0997341864522
Iteration :  49   Loss :  0.097641869393
Iteration :  50   Loss :  0.0955934469184
Iteration :  51   Loss :  0.0935879981666
Iteration :  52   Loss :  0.0916246215948
Iteration :  53   Loss :  0.0897024345732
Iteration :  54   Loss :  0.0878205729892
Iteration :  55   Loss :  0.0859781908578
Iteration :  56   Loss :  0.0841744599422
Iteration :  57   Loss :  0.082408569381
Iteration :  58   Loss :  0.0806797253239
Iteration :  59   Loss :  0.0789871505747
Iteration :  60   Loss :  0.0773300842419
Iteration :  61   Loss :  0.0757077813967
Iteration :  62   Loss :  0.0741195127382
Iteration :  63   Loss :  0.0725645642653
Iteration :  64   Loss :  0.0710422369561
Iteration :  65   Loss :  0.0695518464532
Iteration :  66   Loss :  0.0680927227564
Iteration :  67   Loss :  0.0666642099215
Iteration :  68   Loss :  0.0652656657651
Iteration :  69   Loss :  0.0638964615763
Iteration :  70   Loss :  0.0625559818338
Iteration :  71   Loss :  0.0612436239293
Iteration :  72   Loss :  0.0599587978965
Iteration :  73   Loss :  0.0587009261461
Iteration :  74   Loss :  0.057469443206
Iteration :  75   Loss :  0.056263795467
Iteration :  76   Loss :  0.0550834409341
Iteration :  77   Loss :  0.0539278489827
Iteration :  78   Loss :  0.0527965001202
Iteration :  79   Loss :  0.0516888857525
Iteration :  80   Loss :  0.0506045079552
Iteration :  81   Loss :  0.0495428792496
Iteration :  82   Loss :  0.0485035223841
Iteration :  83   Loss :  0.0474859701192
Iteration :  84   Loss :  0.0464897650176
Iteration :  85   Loss :  0.0455144592385
Iteration :  86   Loss :  0.0445596143363
Iteration :  87   Loss :  0.0436248010638
Iteration :  88   Loss :  0.0427095991785
Iteration :  89   Loss :  0.0418135972545
Iteration :  90   Loss :  0.040936392497
Iteration :  91   Loss :  0.0400775905615
Iteration :  92   Loss :  0.0392368053763
Iteration :  93   Loss :  0.0384136589693
Iteration :  94   Loss :  0.0376077812976
Iteration :  95   Loss :  0.0368188100816
Iteration :  96   Loss :  0.0360463906418
Iteration :  97   Loss :  0.0352901757395
Iteration :  98   Loss :  0.0345498254209
Iteration :  99   Loss :  0.0338250068638
[ -9.58101994e-04  -1.42795238e-04  -2.74520679e-04 ...,   4.90014772e-04
   2.62467876e-04  -7.63320070e-07]
CROSS VALIDATION 31
Iteration :  0   Loss :  21.0502580916
Iteration :  1   Loss :  1.63840268476
Iteration :  2   Loss :  1.10299929051
Iteration :  3   Loss :  0.308611104602
Iteration :  4   Loss :  0.302136772162
Iteration :  5   Loss :  0.295798264323
Iteration :  6   Loss :  0.289592731631
Iteration :  7   Loss :  0.283517384409
Iteration :  8   Loss :  0.277569491505
Iteration :  9   Loss :  0.271746379061
Iteration :  10   Loss :  0.266045429318
Iteration :  11   Loss :  0.260464079431
Iteration :  12   Loss :  0.254999820323
Iteration :  13   Loss :  0.249650195554
Iteration :  14   Loss :  0.244412800218
Iteration :  15   Loss :  0.239285279861
Iteration :  16   Loss :  0.234265329422
Iteration :  17   Loss :  0.229350692199
Iteration :  18   Loss :  0.224539158833
Iteration :  19   Loss :  0.219828566315
Iteration :  20   Loss :  0.215216797014
Iteration :  21   Loss :  0.210701777723
Iteration :  22   Loss :  0.20628147873
Iteration :  23   Loss :  0.201953912905
Iteration :  24   Loss :  0.197717134803
Iteration :  25   Loss :  0.193569239796
Iteration :  26   Loss :  0.18950836321
Iteration :  27   Loss :  0.185532679492
Iteration :  28   Loss :  0.181640401387
Iteration :  29   Loss :  0.177829779132
Iteration :  30   Loss :  0.174099099675
Iteration :  31   Loss :  0.170446685902
Iteration :  32   Loss :  0.166870895882
Iteration :  33   Loss :  0.16337012213
Iteration :  34   Loss :  0.159942790884
Iteration :  35   Loss :  0.1565873614
Iteration :  36   Loss :  0.153302325254
Iteration :  37   Loss :  0.150086205669
Iteration :  38   Loss :  0.146937556849
Iteration :  39   Loss :  0.143854963329
Iteration :  40   Loss :  0.14083703934
Iteration :  41   Loss :  0.137882428184
Iteration :  42   Loss :  0.134989801624
Iteration :  43   Loss :  0.13215785929
Iteration :  44   Loss :  0.129385328092
Iteration :  45   Loss :  0.126670961647
Iteration :  46   Loss :  0.124013539719
Iteration :  47   Loss :  0.121411867676
Iteration :  48   Loss :  0.118864775941
Iteration :  49   Loss :  0.11637111948
Iteration :  50   Loss :  0.113929777277
Iteration :  51   Loss :  0.111539651835
Iteration :  52   Loss :  0.109199668679
Iteration :  53   Loss :  0.10690877588
Iteration :  54   Loss :  0.104665943572
Iteration :  55   Loss :  0.102470163499
Iteration :  56   Loss :  0.100320448554
Iteration :  57   Loss :  0.0982158323397
Iteration :  58   Loss :  0.0961553687335
Iteration :  59   Loss :  0.0941381314602
Iteration :  60   Loss :  0.0921632136775
Iteration :  61   Loss :  0.0902297275675
Iteration :  62   Loss :  0.0883368039377
Iteration :  63   Loss :  0.0864835918306
Iteration :  64   Loss :  0.0846692581406
Iteration :  65   Loss :  0.08289298724
Iteration :  66   Loss :  0.0811539806119
Iteration :  67   Loss :  0.0794514564916
Iteration :  68   Loss :  0.0777846495149
Iteration :  69   Loss :  0.0761528103742
Iteration :  70   Loss :  0.0745552054815
Iteration :  71   Loss :  0.0729911166387
Iteration :  72   Loss :  0.0714598407147
Iteration :  73   Loss :  0.0699606893295
Iteration :  74   Loss :  0.0684929885445
Iteration :  75   Loss :  0.0670560785594
Iteration :  76   Loss :  0.0656493134162
Iteration :  77   Loss :  0.0642720607081
Iteration :  78   Loss :  0.0629237012957
Iteration :  79   Loss :  0.0616036290283
Iteration :  80   Loss :  0.0603112504718
Iteration :  81   Loss :  0.0590459846416
Iteration :  82   Loss :  0.0578072627416
Iteration :  83   Loss :  0.0565945279083
Iteration :  84   Loss :  0.0554072349608
Iteration :  85   Loss :  0.0542448501555
Iteration :  86   Loss :  0.0531068509459
Iteration :  87   Loss :  0.0519927257482
Iteration :  88   Loss :  0.0509019737112
Iteration :  89   Loss :  0.0498341044908
Iteration :  90   Loss :  0.0487886380297
Iteration :  91   Loss :  0.0477651043421
Iteration :  92   Loss :  0.0467630433016
Iteration :  93   Loss :  0.045782004435
Iteration :  94   Loss :  0.0448215467195
Iteration :  95   Loss :  0.0438812383844
Iteration :  96   Loss :  0.0429606567171
Iteration :  97   Loss :  0.0420593878732
Iteration :  98   Loss :  0.0411770266902
Iteration :  99   Loss :  0.0403131765055
[ -1.02914392e-03  -1.03745346e-04  -1.84240165e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 32
Iteration :  0   Loss :  9.39021951139
Iteration :  1   Loss :  2.85457324045
Iteration :  2   Loss :  0.312337093123
Iteration :  3   Loss :  0.30578459341
Iteration :  4   Loss :  0.299369558165
Iteration :  5   Loss :  0.29308910353
Iteration :  6   Loss :  0.286940406148
Iteration :  7   Loss :  0.280920701891
Iteration :  8   Loss :  0.275027284621
Iteration :  9   Loss :  0.269257504972
Iteration :  10   Loss :  0.263608769157
Iteration :  11   Loss :  0.258078537807
Iteration :  12   Loss :  0.252664324823
Iteration :  13   Loss :  0.247363696263
Iteration :  14   Loss :  0.242174269248
Iteration :  15   Loss :  0.237093710887
Iteration :  16   Loss :  0.232119737232
Iteration :  17   Loss :  0.22725011225
Iteration :  18   Loss :  0.222482646815
Iteration :  19   Loss :  0.21781519773
Iteration :  20   Loss :  0.213245666758
Iteration :  21   Loss :  0.208771999682
Iteration :  22   Loss :  0.204392185378
Iteration :  23   Loss :  0.200104254915
Iteration :  24   Loss :  0.19590628067
Iteration :  25   Loss :  0.191796375454
Iteration :  26   Loss :  0.187772691675
Iteration :  27   Loss :  0.183833420498
Iteration :  28   Loss :  0.179976791037
Iteration :  29   Loss :  0.176201069557
Iteration :  30   Loss :  0.172504558693
Iteration :  31   Loss :  0.168885596693
Iteration :  32   Loss :  0.165342556662
Iteration :  33   Loss :  0.16187384584
Iteration :  34   Loss :  0.158477904878
Iteration :  35   Loss :  0.155153207142
Iteration :  36   Loss :  0.151898258026
Iteration :  37   Loss :  0.148711594276
Iteration :  38   Loss :  0.14559178334
Iteration :  39   Loss :  0.142537422716
Iteration :  40   Loss :  0.139547139327
Iteration :  41   Loss :  0.1366195889
Iteration :  42   Loss :  0.133753455364
Iteration :  43   Loss :  0.130947450258
Iteration :  44   Loss :  0.128200312153
Iteration :  45   Loss :  0.12551080608
Iteration :  46   Loss :  0.122877722982
Iteration :  47   Loss :  0.120299879164
Iteration :  48   Loss :  0.117776115765
Iteration :  49   Loss :  0.115305298236
Iteration :  50   Loss :  0.112886315828
Iteration :  51   Loss :  0.110518081095
Iteration :  52   Loss :  0.108199529407
Iteration :  53   Loss :  0.105929618464
Iteration :  54   Loss :  0.103707327837
Iteration :  55   Loss :  0.101531658501
Iteration :  56   Loss :  0.0994016323917
Iteration :  57   Loss :  0.0973162919627
Iteration :  58   Loss :  0.095274699756
Iteration :  59   Loss :  0.0932759379804
Iteration :  60   Loss :  0.091319108099
Iteration :  61   Loss :  0.0894033304254
Iteration :  62   Loss :  0.0875277437279
Iteration :  63   Loss :  0.0856915048427
Iteration :  64   Loss :  0.0838937882945
Iteration :  65   Loss :  0.0821337859257
Iteration :  66   Loss :  0.080410706533
Iteration :  67   Loss :  0.0787237755116
Iteration :  68   Loss :  0.0770722345073
Iteration :  69   Loss :  0.075455341075
Iteration :  70   Loss :  0.0738723683457
Iteration :  71   Loss :  0.0723226046991
Iteration :  72   Loss :  0.070805353444
Iteration :  73   Loss :  0.069319932505
Iteration :  74   Loss :  0.067865674116
Iteration :  75   Loss :  0.0664419245198
Iteration :  76   Loss :  0.0650480436745
Iteration :  77   Loss :  0.0636834049655
Iteration :  78   Loss :  0.0623473949239
Iteration :  79   Loss :  0.0610394129507
Iteration :  80   Loss :  0.0597588710469
Iteration :  81   Loss :  0.058505193549
Iteration :  82   Loss :  0.0572778168704
Iteration :  83   Loss :  0.0560761892479
Iteration :  84   Loss :  0.0548997704937
Iteration :  85   Loss :  0.0537480317526
Iteration :  86   Loss :  0.0526204552642
Iteration :  87   Loss :  0.0515165341302
Iteration :  88   Loss :  0.0504357720864
Iteration :  89   Loss :  0.0493776832797
Iteration :  90   Loss :  0.0483417920498
Iteration :  91   Loss :  0.0473276327151
Iteration :  92   Loss :  0.0463347493637
Iteration :  93   Loss :  0.045362695648
Iteration :  94   Loss :  0.0444110345844
Iteration :  95   Loss :  0.0434793383569
Iteration :  96   Loss :  0.0425671881243
Iteration :  97   Loss :  0.0416741738326
Iteration :  98   Loss :  0.0407998940301
Iteration :  99   Loss :  0.0399439556871
[ -9.23787000e-04  -1.16482153e-04  -2.87974339e-05 ...,   7.37686944e-04
   5.88057205e-04   7.02666526e-05]
CROSS VALIDATION 33
Iteration :  0   Loss :  21.0502580916
Iteration :  1   Loss :  1.63801517722
Iteration :  2   Loss :  1.10268973519
Iteration :  3   Loss :  0.30861285613
Iteration :  4   Loss :  0.302138486944
Iteration :  5   Loss :  0.295799943131
Iteration :  6   Loss :  0.28959437522
Iteration :  7   Loss :  0.283518993517
Iteration :  8   Loss :  0.277571066855
Iteration :  9   Loss :  0.271747921362
Iteration :  10   Loss :  0.266046939263
Iteration :  11   Loss :  0.260465557699
Iteration :  12   Loss :  0.255001267579
Iteration :  13   Loss :  0.249651612448
Iteration :  14   Loss :  0.244414187387
Iteration :  15   Loss :  0.239286637928
Iteration :  16   Loss :  0.234266658999
Iteration :  17   Loss :  0.229351993883
Iteration :  18   Loss :  0.224540433209
Iteration :  19   Loss :  0.219829813956
Iteration :  20   Loss :  0.215218018481
Iteration :  21   Loss :  0.210702973565
Iteration :  22   Loss :  0.206282649484
Iteration :  23   Loss :  0.201955059098
Iteration :  24   Loss :  0.19771825695
Iteration :  25   Loss :  0.193570338402
Iteration :  26   Loss :  0.189509438768
Iteration :  27   Loss :  0.185533732486
Iteration :  28   Loss :  0.18164143229
Iteration :  29   Loss :  0.177830788408
Iteration :  30   Loss :  0.174100087778
Iteration :  31   Loss :  0.170447653276
Iteration :  32   Loss :  0.166871842961
Iteration :  33   Loss :  0.16337104934
Iteration :  34   Loss :  0.159943698643
Iteration :  35   Loss :  0.156588250114
Iteration :  36   Loss :  0.153303195324
Iteration :  37   Loss :  0.150087057486
Iteration :  38   Loss :  0.146938390796
Iteration :  39   Loss :  0.143855779781
Iteration :  40   Loss :  0.140837838664
Iteration :  41   Loss :  0.137883210738
Iteration :  42   Loss :  0.134990567761
Iteration :  43   Loss :  0.132158609355
Iteration :  44   Loss :  0.129386062421
Iteration :  45   Loss :  0.12667168057
Iteration :  46   Loss :  0.124014243561
Iteration :  47   Loss :  0.121412556751
Iteration :  48   Loss :  0.118865450561
Iteration :  49   Loss :  0.116371779947
Iteration :  50   Loss :  0.113930423888
Iteration :  51   Loss :  0.11154028488
Iteration :  52   Loss :  0.109200288444
Iteration :  53   Loss :  0.106909382642
Iteration :  54   Loss :  0.104666537605
Iteration :  55   Loss :  0.10247074507
Iteration :  56   Loss :  0.100321017924
Iteration :  57   Loss :  0.0982163897654
Iteration :  58   Loss :  0.096155914465
Iteration :  59   Loss :  0.0941386657429
Iteration :  60   Loss :  0.0921637367515
Iteration :  61   Loss :  0.0902302396679
Iteration :  62   Loss :  0.0883373052948
Iteration :  63   Loss :  0.0864840826697
Iteration :  64   Loss :  0.0846697386824
Iteration :  65   Loss :  0.0828934577006
Iteration :  66   Loss :  0.0811544412027
Iteration :  67   Loss :  0.0794519074197
Iteration :  68   Loss :  0.0777850909831
Iteration :  69   Loss :  0.0761532425808
Iteration :  70   Loss :  0.0745556286209
Iteration :  71   Loss :  0.072991530901
Iteration :  72   Loss :  0.0714602462863
Iteration :  73   Loss :  0.0699610863927
Iteration :  74   Loss :  0.0684933772776
Iteration :  75   Loss :  0.0670564591374
Iteration :  76   Loss :  0.06564968601
Iteration :  77   Loss :  0.0642724254853
Iteration :  78   Loss :  0.0629240584202
Iteration :  79   Loss :  0.0616039786608
Iteration :  80   Loss :  0.0603115927693
Iteration :  81   Loss :  0.0590463197581
Iteration :  82   Loss :  0.0578075908277
Iteration :  83   Loss :  0.0565948491115
Iteration :  84   Loss :  0.0554075494256
Iteration :  85   Loss :  0.0542451580231
Iteration :  86   Loss :  0.0531071523547
Iteration :  87   Loss :  0.0519930208339
Iteration :  88   Loss :  0.0509022626063
Iteration :  89   Loss :  0.0498343873251
Iteration :  90   Loss :  0.0487889149305
Iteration :  91   Loss :  0.0477653754338
Iteration :  92   Loss :  0.0467633087061
Iteration :  93   Loss :  0.0457822642716
Iteration :  94   Loss :  0.044821801105
Iteration :  95   Loss :  0.0438814874331
Iteration :  96   Loss :  0.0429609005411
Iteration :  97   Loss :  0.042059626582
Iteration :  98   Loss :  0.0411772603911
Iteration :  99   Loss :  0.0403134053036
[ -1.02919175e-03  -1.03760037e-04  -1.84294908e-04 ...,   7.82772652e-04
   4.72390873e-04   7.07080165e-05]
CROSS VALIDATION 34
Iteration :  0   Loss :  35.67661079
Iteration :  1   Loss :  0.272746646615
Iteration :  2   Loss :  0.267024712323
Iteration :  3   Loss :  0.261422818121
Iteration :  4   Loss :  0.255938445696
Iteration :  5   Loss :  0.250569129566
Iteration :  6   Loss :  0.245312455973
Iteration :  7   Loss :  0.240166061795
Iteration :  8   Loss :  0.235127633489
Iteration :  9   Loss :  0.230194906045
Iteration :  10   Loss :  0.225365661972
Iteration :  11   Loss :  0.220637730298
Iteration :  12   Loss :  0.216008985597
Iteration :  13   Loss :  0.211477347033
Iteration :  14   Loss :  0.207040777422
Iteration :  15   Loss :  0.202697282318
Iteration :  16   Loss :  0.198444909118
Iteration :  17   Loss :  0.19428174618
Iteration :  18   Loss :  0.190205921969
Iteration :  19   Loss :  0.186215604211
Iteration :  20   Loss :  0.182308999072
Iteration :  21   Loss :  0.178484350349
Iteration :  22   Loss :  0.174739938685
Iteration :  23   Loss :  0.171074080792
Iteration :  24   Loss :  0.167485128695
Iteration :  25   Loss :  0.163971468992
Iteration :  26   Loss :  0.16053152213
Iteration :  27   Loss :  0.15716374169
Iteration :  28   Loss :  0.153866613699
Iteration :  29   Loss :  0.150638655943
Iteration :  30   Loss :  0.147478417305
Iteration :  31   Loss :  0.144384477109
Iteration :  32   Loss :  0.141355444485
Iteration :  33   Loss :  0.13838995774
Iteration :  34   Loss :  0.135486683751
Iteration :  35   Loss :  0.132644317359
Iteration :  36   Loss :  0.129861580788
Iteration :  37   Loss :  0.127137223068
Iteration :  38   Loss :  0.124470019472
Iteration :  39   Loss :  0.121858770969
Iteration :  40   Loss :  0.11930230368
Iteration :  41   Loss :  0.116799468353
Iteration :  42   Loss :  0.114349139846
Iteration :  43   Loss :  0.111950216623
Iteration :  44   Loss :  0.109601620256
Iteration :  45   Loss :  0.10730229494
Iteration :  46   Loss :  0.105051207021
Iteration :  47   Loss :  0.102847344531
Iteration :  48   Loss :  0.100689716729
Iteration :  49   Loss :  0.0985773536622
Iteration :  50   Loss :  0.0965093057235
Iteration :  51   Loss :  0.094484643229
Iteration :  52   Loss :  0.0925024559982
Iteration :  53   Loss :  0.0905618529454
Iteration :  54   Loss :  0.0886619616788
Iteration :  55   Loss :  0.0868019281084
Iteration :  56   Loss :  0.0849809160622
Iteration :  57   Loss :  0.0831981069102
Iteration :  58   Loss :  0.0814526991962
Iteration :  59   Loss :  0.079743908278
Iteration :  60   Loss :  0.0780709659742
Iteration :  61   Loss :  0.076433120219
Iteration :  62   Loss :  0.0748296347241
Iteration :  63   Loss :  0.073259788648
Iteration :  64   Loss :  0.0717228762713
Iteration :  65   Loss :  0.0702182066801
Iteration :  66   Loss :  0.0687451034552
Iteration :  67   Loss :  0.0673029043677
Iteration :  68   Loss :  0.0658909610818
Iteration :  69   Loss :  0.0645086388629
Iteration :  70   Loss :  0.0631553162926
Iteration :  71   Loss :  0.0618303849892
Iteration :  72   Loss :  0.060533249334
Iteration :  73   Loss :  0.059263326204
Iteration :  74   Loss :  0.0580200447094
Iteration :  75   Loss :  0.056802845937
Iteration :  76   Loss :  0.055611182699
Iteration :  77   Loss :  0.0544445192872
Iteration :  78   Loss :  0.0533023312318
Iteration :  79   Loss :  0.0521841050659
Iteration :  80   Loss :  0.0510893380945
Iteration :  81   Loss :  0.0500175381687
Iteration :  82   Loss :  0.0489682234644
Iteration :  83   Loss :  0.0479409222655
Iteration :  84   Loss :  0.0469351727522
Iteration :  85   Loss :  0.045950522793
Iteration :  86   Loss :  0.0522554312808
Iteration :  87   Loss :  8.19156841911
Iteration :  88   Loss :  0.123041645194
Iteration :  89   Loss :  0.120460362463
Iteration :  90   Loss :  0.117933232295
Iteration :  91   Loss :  0.115459118628
Iteration :  92   Loss :  0.113036909232
Iteration :  93   Loss :  0.11066551521
Iteration :  94   Loss :  0.108343870511
Iteration :  95   Loss :  0.106070931446
Iteration :  96   Loss :  0.103845676222
Iteration :  97   Loss :  0.101667104485
Iteration :  98   Loss :  0.099534236863
Iteration :  99   Loss :  0.0974461145333
[-0.00152152 -0.00033293 -0.00026675 ...,  0.00103262  0.00066118
  0.00012261]
CROSS VALIDATION 35
Iteration :  0   Loss :  6.3033513121
Iteration :  1   Loss :  13.6997679582
Iteration :  2   Loss :  0.313819601895
Iteration :  3   Loss :  0.307236000725
Iteration :  4   Loss :  0.3007905165
Iteration :  5   Loss :  0.294480251672
Iteration :  6   Loss :  0.288302369483
Iteration :  7   Loss :  0.282254092685
Iteration :  8   Loss :  0.276332702296
Iteration :  9   Loss :  0.270535536373
Iteration :  10   Loss :  0.26485998882
Iteration :  11   Loss :  0.259303508213
Iteration :  12   Loss :  0.253863596654
Iteration :  13   Loss :  0.248537808648
Iteration :  14   Loss :  0.243323750005
Iteration :  15   Loss :  0.238219076762
Iteration :  16   Loss :  0.233221494129
Iteration :  17   Loss :  0.228328755459
Iteration :  18   Loss :  0.223538661239
Iteration :  19   Loss :  0.218849058095
Iteration :  20   Loss :  0.214257837834
Iteration :  21   Loss :  0.209762936485
Iteration :  22   Loss :  0.205362333382
Iteration :  23   Loss :  0.201054050248
Iteration :  24   Loss :  0.196836150307
Iteration :  25   Loss :  0.192706737416
Iteration :  26   Loss :  0.188663955212
Iteration :  27   Loss :  0.184705986275
Iteration :  28   Loss :  0.180831051313
Iteration :  29   Loss :  0.177037408361
Iteration :  30   Loss :  0.173323352
Iteration :  31   Loss :  0.169687212588
Iteration :  32   Loss :  0.166127355509
Iteration :  33   Loss :  0.162642180442
Iteration :  34   Loss :  0.159230120638
Iteration :  35   Loss :  0.155889642217
Iteration :  36   Loss :  0.152619243476
Iteration :  37   Loss :  0.14941745422
Iteration :  38   Loss :  0.146282835094
Iteration :  39   Loss :  0.14321397694
Iteration :  40   Loss :  0.140209500163
Iteration :  41   Loss :  0.13726805411
Iteration :  42   Loss :  0.134388316465
Iteration :  43   Loss :  0.131568992649
Iteration :  44   Loss :  0.128808815246
Iteration :  45   Loss :  0.126106543426
Iteration :  46   Loss :  0.123460962392
Iteration :  47   Loss :  0.120870882833
Iteration :  48   Loss :  0.118335140385
Iteration :  49   Loss :  0.115852595114
Iteration :  50   Loss :  0.113422131
Iteration :  51   Loss :  0.111042655436
Iteration :  52   Loss :  0.108713098736
Iteration :  53   Loss :  0.106432413655
Iteration :  54   Loss :  0.10419957492
Iteration :  55   Loss :  0.102013578765
Iteration :  56   Loss :  0.0998734424813
Iteration :  57   Loss :  0.0977782039789
Iteration :  58   Loss :  0.0957269213498
Iteration :  59   Loss :  0.0937186724466
Iteration :  60   Loss :  0.0917525544674
Iteration :  61   Loss :  0.0898276835504
Iteration :  62   Loss :  0.0879431943761
Iteration :  63   Loss :  0.0860982397786
Iteration :  64   Loss :  0.0842919903644
Iteration :  65   Loss :  0.0825236341401
Iteration :  66   Loss :  0.0807923761469
Iteration :  67   Loss :  0.0790974381033
Iteration :  68   Loss :  0.0774380580556
Iteration :  69   Loss :  0.0758134900347
Iteration :  70   Loss :  0.0742230037215
Iteration :  71   Loss :  0.072665884118
Iteration :  72   Loss :  0.0711414312261
Iteration :  73   Loss :  0.069648959733
Iteration :  74   Loss :  0.068187798703
Iteration :  75   Loss :  0.0667572912759
Iteration :  76   Loss :  0.0653567943718
Iteration :  77   Loss :  0.0639856784019
Iteration :  78   Loss :  0.0626433269854
Iteration :  79   Loss :  0.0613291366725
Iteration :  80   Loss :  0.0600425166734
Iteration :  81   Loss :  0.0587828885923
Iteration :  82   Loss :  0.0575496861673
Iteration :  83   Loss :  0.0563423550163
Iteration :  84   Loss :  0.0551603523877
Iteration :  85   Loss :  0.0540031469159
Iteration :  86   Loss :  0.052870218383
Iteration :  87   Loss :  0.0517610574846
Iteration :  88   Loss :  0.0506751656011
Iteration :  89   Loss :  0.0496120545733
Iteration :  90   Loss :  0.0485712464832
Iteration :  91   Loss :  0.0475522734388
Iteration :  92   Loss :  0.0465546773641
Iteration :  93   Loss :  0.0455780097931
Iteration :  94   Loss :  0.044621831668
Iteration :  95   Loss :  0.043685713142
Iteration :  96   Loss :  0.0427692333862
Iteration :  97   Loss :  0.0418719804
Iteration :  98   Loss :  0.0409935508262
Iteration :  99   Loss :  0.0401335497698
[ -1.22597913e-03  -2.18459223e-04  -4.11066629e-04 ...,   8.16507797e-04
   6.17310888e-04   6.95543217e-05]
CROSS VALIDATION 36
Iteration :  0   Loss :  21.0482793545
Iteration :  1   Loss :  1.63722339364
Iteration :  2   Loss :  1.09886104839
Iteration :  3   Loss :  0.308625681603
Iteration :  4   Loss :  0.302151043352
Iteration :  5   Loss :  0.29581223612
Iteration :  6   Loss :  0.289606410314
Iteration :  7   Loss :  0.283530776128
Iteration :  8   Loss :  0.27758260228
Iteration :  9   Loss :  0.271759214786
Iteration :  10   Loss :  0.266057995763
Iteration :  11   Loss :  0.260476382245
Iteration :  12   Loss :  0.255011865037
Iteration :  13   Loss :  0.249661987583
Iteration :  14   Loss :  0.244424344863
Iteration :  15   Loss :  0.239296582311
Iteration :  16   Loss :  0.234276394759
Iteration :  17   Loss :  0.229361525397
Iteration :  18   Loss :  0.224549764762
Iteration :  19   Loss :  0.219838949744
Iteration :  20   Loss :  0.215226962609
Iteration :  21   Loss :  0.210711730054
Iteration :  22   Loss :  0.206291222272
Iteration :  23   Loss :  0.201963452038
Iteration :  24   Loss :  0.197726473815
Iteration :  25   Loss :  0.193578382885
Iteration :  26   Loss :  0.189517314488
Iteration :  27   Loss :  0.185541442981
Iteration :  28   Loss :  0.181648981027
Iteration :  29   Loss :  0.17783817878
Iteration :  30   Loss :  0.174107323108
Iteration :  31   Loss :  0.170454736817
Iteration :  32   Loss :  0.166878777897
Iteration :  33   Loss :  0.163377838788
Iteration :  34   Loss :  0.159950345655
Iteration :  35   Loss :  0.15659475768
Iteration :  36   Loss :  0.153309566367
Iteration :  37   Loss :  0.150093294872
Iteration :  38   Loss :  0.146944497328
Iteration :  39   Loss :  0.143861758205
Iteration :  40   Loss :  0.140843691666
Iteration :  41   Loss :  0.137888940951
Iteration :  42   Loss :  0.134996177761
Iteration :  43   Loss :  0.132164101662
Iteration :  44   Loss :  0.129391439505
Iteration :  45   Loss :  0.126676944849
Iteration :  46   Loss :  0.124019397401
Iteration :  47   Loss :  0.121417602469
Iteration :  48   Loss :  0.118870390425
Iteration :  49   Loss :  0.116376616178
Iteration :  50   Loss :  0.11393515866
Iteration :  51   Loss :  0.111544920322
Iteration :  52   Loss :  0.109204826639
Iteration :  53   Loss :  0.106913825631
Iteration :  54   Loss :  0.104670887385
Iteration :  55   Loss :  0.102475003596
Iteration :  56   Loss :  0.100325187111
Iteration :  57   Loss :  0.0982204714867
Iteration :  58   Loss :  0.0961599105561
Iteration :  59   Loss :  0.0941425780002
Iteration :  60   Loss :  0.0921675669338
Iteration :  61   Loss :  0.0902339894971
Iteration :  62   Loss :  0.0883409764566
Iteration :  63   Loss :  0.0864876768144
Iteration :  64   Loss :  0.0846732574259
Iteration :  65   Loss :  0.0828969026245
Iteration :  66   Loss :  0.0811578138558
Iteration :  67   Loss :  0.0794552093182
Iteration :  68   Loss :  0.0777883236112
Iteration :  69   Loss :  0.0761564073918
Iteration :  70   Loss :  0.0745587270375
Iteration :  71   Loss :  0.0729945643162
Iteration :  72   Loss :  0.0714632160637
Iteration :  73   Loss :  0.0699639938672
Iteration :  74   Loss :  0.0684962237565
Iteration :  75   Loss :  0.0670592459001
Iteration :  76   Loss :  0.0656524143095
Iteration :  77   Loss :  0.0642750965479
Iteration :  78   Loss :  0.0629266734468
Iteration :  79   Loss :  0.0616065388269
Iteration :  80   Loss :  0.0603140992259
Iteration :  81   Loss :  0.0590487736319
Iteration :  82   Loss :  0.0578099932218
Iteration :  83   Loss :  0.056597201106
Iteration :  84   Loss :  0.0554098520777
Iteration :  85   Loss :  0.054247412368
Iteration :  86   Loss :  0.0531093594059
Iteration :  87   Loss :  0.0519951815834
Iteration :  88   Loss :  0.0509043780256
Iteration :  89   Loss :  0.0498364583652
Iteration :  90   Loss :  0.0487909425224
Iteration :  91   Loss :  0.0477673604889
Iteration :  92   Loss :  0.0467652521169
Iteration :  93   Loss :  0.0457841669117
Iteration :  94   Loss :  0.0448236638297
Iteration :  95   Loss :  0.0438833110799
Iteration :  96   Loss :  0.0429626859297
Iteration :  97   Loss :  0.042061374515
Iteration :  98   Loss :  0.0411789716544
Iteration :  99   Loss :  0.0403150806664
[ -1.02922151e-03  -1.03735633e-04  -1.84272758e-04 ...,   7.82766835e-04
   4.72424339e-04   7.07219720e-05]
CROSS VALIDATION 37
Iteration :  0   Loss :  21.0482793545
Iteration :  1   Loss :  1.63722339364
Iteration :  2   Loss :  1.09886104839
Iteration :  3   Loss :  0.308625681603
Iteration :  4   Loss :  0.302151043352
Iteration :  5   Loss :  0.29581223612
Iteration :  6   Loss :  0.289606410314
Iteration :  7   Loss :  0.283530776128
Iteration :  8   Loss :  0.27758260228
Iteration :  9   Loss :  0.271759214786
Iteration :  10   Loss :  0.266057995763
Iteration :  11   Loss :  0.260476382245
Iteration :  12   Loss :  0.255011865037
Iteration :  13   Loss :  0.249661987583
Iteration :  14   Loss :  0.244424344863
Iteration :  15   Loss :  0.239296582311
Iteration :  16   Loss :  0.234276394759
Iteration :  17   Loss :  0.229361525397
Iteration :  18   Loss :  0.224549764762
Iteration :  19   Loss :  0.219838949744
Iteration :  20   Loss :  0.215226962609
Iteration :  21   Loss :  0.210711730054
Iteration :  22   Loss :  0.206291222272
Iteration :  23   Loss :  0.201963452038
Iteration :  24   Loss :  0.197726473815
Iteration :  25   Loss :  0.193578382885
Iteration :  26   Loss :  0.189517314488
Iteration :  27   Loss :  0.185541442981
Iteration :  28   Loss :  0.181648981027
Iteration :  29   Loss :  0.17783817878
Iteration :  30   Loss :  0.174107323108
Iteration :  31   Loss :  0.170454736817
Iteration :  32   Loss :  0.166878777897
Iteration :  33   Loss :  0.163377838788
Iteration :  34   Loss :  0.159950345655
Iteration :  35   Loss :  0.15659475768
Iteration :  36   Loss :  0.153309566367
Iteration :  37   Loss :  0.150093294872
Iteration :  38   Loss :  0.146944497328
Iteration :  39   Loss :  0.143861758205
Iteration :  40   Loss :  0.140843691666
Iteration :  41   Loss :  0.137888940951
Iteration :  42   Loss :  0.134996177761
Iteration :  43   Loss :  0.132164101662
Iteration :  44   Loss :  0.129391439505
Iteration :  45   Loss :  0.126676944849
Iteration :  46   Loss :  0.124019397401
Iteration :  47   Loss :  0.121417602469
Iteration :  48   Loss :  0.118870390425
Iteration :  49   Loss :  0.116376616178
Iteration :  50   Loss :  0.11393515866
Iteration :  51   Loss :  0.111544920322
Iteration :  52   Loss :  0.109204826639
Iteration :  53   Loss :  0.106913825631
Iteration :  54   Loss :  0.104670887385
Iteration :  55   Loss :  0.102475003596
Iteration :  56   Loss :  0.100325187111
Iteration :  57   Loss :  0.0982204714867
Iteration :  58   Loss :  0.0961599105561
Iteration :  59   Loss :  0.0941425780002
Iteration :  60   Loss :  0.0921675669338
Iteration :  61   Loss :  0.0902339894971
Iteration :  62   Loss :  0.0883409764566
Iteration :  63   Loss :  0.0864876768144
Iteration :  64   Loss :  0.0846732574259
Iteration :  65   Loss :  0.0828969026245
Iteration :  66   Loss :  0.0811578138558
Iteration :  67   Loss :  0.0794552093182
Iteration :  68   Loss :  0.0777883236112
Iteration :  69   Loss :  0.0761564073918
Iteration :  70   Loss :  0.0745587270375
Iteration :  71   Loss :  0.0729945643162
Iteration :  72   Loss :  0.0714632160637
Iteration :  73   Loss :  0.0699639938672
Iteration :  74   Loss :  0.0684962237565
Iteration :  75   Loss :  0.0670592459001
Iteration :  76   Loss :  0.0656524143095
Iteration :  77   Loss :  0.0642750965479
Iteration :  78   Loss :  0.0629266734468
Iteration :  79   Loss :  0.0616065388269
Iteration :  80   Loss :  0.0603140992259
Iteration :  81   Loss :  0.0590487736319
Iteration :  82   Loss :  0.0578099932218
Iteration :  83   Loss :  0.056597201106
Iteration :  84   Loss :  0.0554098520777
Iteration :  85   Loss :  0.054247412368
Iteration :  86   Loss :  0.0531093594059
Iteration :  87   Loss :  0.0519951815834
Iteration :  88   Loss :  0.0509043780256
Iteration :  89   Loss :  0.0498364583652
Iteration :  90   Loss :  0.0487909425224
Iteration :  91   Loss :  0.0477673604889
Iteration :  92   Loss :  0.0467652521169
Iteration :  93   Loss :  0.0457841669117
Iteration :  94   Loss :  0.0448236638297
Iteration :  95   Loss :  0.0438833110799
Iteration :  96   Loss :  0.0429626859297
Iteration :  97   Loss :  0.042061374515
Iteration :  98   Loss :  0.0411789716544
Iteration :  99   Loss :  0.0403150806664
[ -1.02922151e-03  -1.03735633e-04  -1.84272758e-04 ...,   7.82766835e-04
   4.72424339e-04   7.07219720e-05]
CROSS VALIDATION 38
Iteration :  0   Loss :  21.0482793545
Iteration :  1   Loss :  1.63722339364
Iteration :  2   Loss :  1.09886104839
Iteration :  3   Loss :  0.308625681603
Iteration :  4   Loss :  0.302151043352
Iteration :  5   Loss :  0.29581223612
Iteration :  6   Loss :  0.289606410314
Iteration :  7   Loss :  0.283530776128
Iteration :  8   Loss :  0.27758260228
Iteration :  9   Loss :  0.271759214786
Iteration :  10   Loss :  0.266057995763
Iteration :  11   Loss :  0.260476382245
Iteration :  12   Loss :  0.255011865037
Iteration :  13   Loss :  0.249661987583
Iteration :  14   Loss :  0.244424344863
Iteration :  15   Loss :  0.239296582311
Iteration :  16   Loss :  0.234276394759
Iteration :  17   Loss :  0.229361525397
Iteration :  18   Loss :  0.224549764762
Iteration :  19   Loss :  0.219838949744
Iteration :  20   Loss :  0.215226962609
Iteration :  21   Loss :  0.210711730054
Iteration :  22   Loss :  0.206291222272
Iteration :  23   Loss :  0.201963452038
Iteration :  24   Loss :  0.197726473815
Iteration :  25   Loss :  0.193578382885
Iteration :  26   Loss :  0.189517314488
Iteration :  27   Loss :  0.185541442981
Iteration :  28   Loss :  0.181648981027
Iteration :  29   Loss :  0.17783817878
Iteration :  30   Loss :  0.174107323108
Iteration :  31   Loss :  0.170454736817
Iteration :  32   Loss :  0.166878777897
Iteration :  33   Loss :  0.163377838788
Iteration :  34   Loss :  0.159950345655
Iteration :  35   Loss :  0.15659475768
Iteration :  36   Loss :  0.153309566367
Iteration :  37   Loss :  0.150093294872
Iteration :  38   Loss :  0.146944497328
Iteration :  39   Loss :  0.143861758205
Iteration :  40   Loss :  0.140843691666
Iteration :  41   Loss :  0.137888940951
Iteration :  42   Loss :  0.134996177761
Iteration :  43   Loss :  0.132164101662
Iteration :  44   Loss :  0.129391439505
Iteration :  45   Loss :  0.126676944849
Iteration :  46   Loss :  0.124019397401
Iteration :  47   Loss :  0.121417602469
Iteration :  48   Loss :  0.118870390425
Iteration :  49   Loss :  0.116376616178
Iteration :  50   Loss :  0.11393515866
Iteration :  51   Loss :  0.111544920322
Iteration :  52   Loss :  0.109204826639
Iteration :  53   Loss :  0.106913825631
Iteration :  54   Loss :  0.104670887385
Iteration :  55   Loss :  0.102475003596
Iteration :  56   Loss :  0.100325187111
Iteration :  57   Loss :  0.0982204714867
Iteration :  58   Loss :  0.0961599105561
Iteration :  59   Loss :  0.0941425780002
Iteration :  60   Loss :  0.0921675669338
Iteration :  61   Loss :  0.0902339894971
Iteration :  62   Loss :  0.0883409764566
Iteration :  63   Loss :  0.0864876768144
Iteration :  64   Loss :  0.0846732574259
Iteration :  65   Loss :  0.0828969026245
Iteration :  66   Loss :  0.0811578138558
Iteration :  67   Loss :  0.0794552093182
Iteration :  68   Loss :  0.0777883236112
Iteration :  69   Loss :  0.0761564073918
Iteration :  70   Loss :  0.0745587270375
Iteration :  71   Loss :  0.0729945643162
Iteration :  72   Loss :  0.0714632160637
Iteration :  73   Loss :  0.0699639938672
Iteration :  74   Loss :  0.0684962237565
Iteration :  75   Loss :  0.0670592459001
Iteration :  76   Loss :  0.0656524143095
Iteration :  77   Loss :  0.0642750965479
Iteration :  78   Loss :  0.0629266734468
Iteration :  79   Loss :  0.0616065388269
Iteration :  80   Loss :  0.0603140992259
Iteration :  81   Loss :  0.0590487736319
Iteration :  82   Loss :  0.0578099932218
Iteration :  83   Loss :  0.056597201106
Iteration :  84   Loss :  0.0554098520777
Iteration :  85   Loss :  0.054247412368
Iteration :  86   Loss :  0.0531093594059
Iteration :  87   Loss :  0.0519951815834
Iteration :  88   Loss :  0.0509043780256
Iteration :  89   Loss :  0.0498364583652
Iteration :  90   Loss :  0.0487909425224
Iteration :  91   Loss :  0.0477673604889
Iteration :  92   Loss :  0.0467652521169
Iteration :  93   Loss :  0.0457841669117
Iteration :  94   Loss :  0.0448236638297
Iteration :  95   Loss :  0.0438833110799
Iteration :  96   Loss :  0.0429626859297
Iteration :  97   Loss :  0.042061374515
Iteration :  98   Loss :  0.0411789716544
Iteration :  99   Loss :  0.0403150806664
[ -1.02922151e-03  -1.03735633e-04  -1.84272758e-04 ...,   7.82766835e-04
   4.72424339e-04   7.07219720e-05]
CROSS VALIDATION 39
Iteration :  0   Loss :  21.0482793545
Iteration :  1   Loss :  1.63722339364
Iteration :  2   Loss :  1.09886104839
Iteration :  3   Loss :  0.308625681603
Iteration :  4   Loss :  0.302151043352
Iteration :  5   Loss :  0.29581223612
Iteration :  6   Loss :  0.289606410314
Iteration :  7   Loss :  0.283530776128
Iteration :  8   Loss :  0.27758260228
Iteration :  9   Loss :  0.271759214786
Iteration :  10   Loss :  0.266057995763
Iteration :  11   Loss :  0.260476382245
Iteration :  12   Loss :  0.255011865037
Iteration :  13   Loss :  0.249661987583
Iteration :  14   Loss :  0.244424344863
Iteration :  15   Loss :  0.239296582311
Iteration :  16   Loss :  0.234276394759
Iteration :  17   Loss :  0.229361525397
Iteration :  18   Loss :  0.224549764762
Iteration :  19   Loss :  0.219838949744
Iteration :  20   Loss :  0.215226962609
Iteration :  21   Loss :  0.210711730054
Iteration :  22   Loss :  0.206291222272
Iteration :  23   Loss :  0.201963452038
Iteration :  24   Loss :  0.197726473815
Iteration :  25   Loss :  0.193578382885
Iteration :  26   Loss :  0.189517314488
Iteration :  27   Loss :  0.185541442981
Iteration :  28   Loss :  0.181648981027
Iteration :  29   Loss :  0.17783817878
Iteration :  30   Loss :  0.174107323108
Iteration :  31   Loss :  0.170454736817
Iteration :  32   Loss :  0.166878777897
Iteration :  33   Loss :  0.163377838788
Iteration :  34   Loss :  0.159950345655
Iteration :  35   Loss :  0.15659475768
Iteration :  36   Loss :  0.153309566367
Iteration :  37   Loss :  0.150093294872
Iteration :  38   Loss :  0.146944497328
Iteration :  39   Loss :  0.143861758205
Iteration :  40   Loss :  0.140843691666
Iteration :  41   Loss :  0.137888940951
Iteration :  42   Loss :  0.134996177761
Iteration :  43   Loss :  0.132164101662
Iteration :  44   Loss :  0.129391439505
Iteration :  45   Loss :  0.126676944849
Iteration :  46   Loss :  0.124019397401
Iteration :  47   Loss :  0.121417602469
Iteration :  48   Loss :  0.118870390425
Iteration :  49   Loss :  0.116376616178
Iteration :  50   Loss :  0.11393515866
Iteration :  51   Loss :  0.111544920322
Iteration :  52   Loss :  0.109204826639
Iteration :  53   Loss :  0.106913825631
Iteration :  54   Loss :  0.104670887385
Iteration :  55   Loss :  0.102475003596
Iteration :  56   Loss :  0.100325187111
Iteration :  57   Loss :  0.0982204714867
Iteration :  58   Loss :  0.0961599105561
Iteration :  59   Loss :  0.0941425780002
Iteration :  60   Loss :  0.0921675669338
Iteration :  61   Loss :  0.0902339894971
Iteration :  62   Loss :  0.0883409764566
Iteration :  63   Loss :  0.0864876768144
Iteration :  64   Loss :  0.0846732574259
Iteration :  65   Loss :  0.0828969026245
Iteration :  66   Loss :  0.0811578138558
Iteration :  67   Loss :  0.0794552093182
Iteration :  68   Loss :  0.0777883236112
Iteration :  69   Loss :  0.0761564073918
Iteration :  70   Loss :  0.0745587270375
Iteration :  71   Loss :  0.0729945643162
Iteration :  72   Loss :  0.0714632160637
Iteration :  73   Loss :  0.0699639938672
Iteration :  74   Loss :  0.0684962237565
Iteration :  75   Loss :  0.0670592459001
Iteration :  76   Loss :  0.0656524143095
Iteration :  77   Loss :  0.0642750965479
Iteration :  78   Loss :  0.0629266734468
Iteration :  79   Loss :  0.0616065388269
Iteration :  80   Loss :  0.0603140992259
Iteration :  81   Loss :  0.0590487736319
Iteration :  82   Loss :  0.0578099932218
Iteration :  83   Loss :  0.056597201106
Iteration :  84   Loss :  0.0554098520777
Iteration :  85   Loss :  0.054247412368
Iteration :  86   Loss :  0.0531093594059
Iteration :  87   Loss :  0.0519951815834
Iteration :  88   Loss :  0.0509043780256
Iteration :  89   Loss :  0.0498364583652
Iteration :  90   Loss :  0.0487909425224
Iteration :  91   Loss :  0.0477673604889
Iteration :  92   Loss :  0.0467652521169
Iteration :  93   Loss :  0.0457841669117
Iteration :  94   Loss :  0.0448236638297
Iteration :  95   Loss :  0.0438833110799
Iteration :  96   Loss :  0.0429626859297
Iteration :  97   Loss :  0.042061374515
Iteration :  98   Loss :  0.0411789716544
Iteration :  99   Loss :  0.0403150806664
[ -1.02922151e-03  -1.03735633e-04  -1.84272758e-04 ...,   7.82766835e-04
   4.72424339e-04   7.07219720e-05]
CROSS VALIDATION 40
Iteration :  0   Loss :  21.0482793545
Iteration :  1   Loss :  1.63722339364
Iteration :  2   Loss :  1.09886104839
Iteration :  3   Loss :  0.308625681603
Iteration :  4   Loss :  0.302151043352
Iteration :  5   Loss :  0.29581223612
Iteration :  6   Loss :  0.289606410314
Iteration :  7   Loss :  0.283530776128
Iteration :  8   Loss :  0.27758260228
Iteration :  9   Loss :  0.271759214786
Iteration :  10   Loss :  0.266057995763
Iteration :  11   Loss :  0.260476382245
Iteration :  12   Loss :  0.255011865037
Iteration :  13   Loss :  0.249661987583
Iteration :  14   Loss :  0.244424344863
Iteration :  15   Loss :  0.239296582311
Iteration :  16   Loss :  0.234276394759
Iteration :  17   Loss :  0.229361525397
Iteration :  18   Loss :  0.224549764762
Iteration :  19   Loss :  0.219838949744
Iteration :  20   Loss :  0.215226962609
Iteration :  21   Loss :  0.210711730054
Iteration :  22   Loss :  0.206291222272
Iteration :  23   Loss :  0.201963452038
Iteration :  24   Loss :  0.197726473815
Iteration :  25   Loss :  0.193578382885
Iteration :  26   Loss :  0.189517314488
Iteration :  27   Loss :  0.185541442981
Iteration :  28   Loss :  0.181648981027
Iteration :  29   Loss :  0.17783817878
Iteration :  30   Loss :  0.174107323108
Iteration :  31   Loss :  0.170454736817
Iteration :  32   Loss :  0.166878777897
Iteration :  33   Loss :  0.163377838788
Iteration :  34   Loss :  0.159950345655
Iteration :  35   Loss :  0.15659475768
Iteration :  36   Loss :  0.153309566367
Iteration :  37   Loss :  0.150093294872
Iteration :  38   Loss :  0.146944497328
Iteration :  39   Loss :  0.143861758205
Iteration :  40   Loss :  0.140843691666
Iteration :  41   Loss :  0.137888940951
Iteration :  42   Loss :  0.134996177761
Iteration :  43   Loss :  0.132164101662
Iteration :  44   Loss :  0.129391439505
Iteration :  45   Loss :  0.126676944849
Iteration :  46   Loss :  0.124019397401
Iteration :  47   Loss :  0.121417602469
Iteration :  48   Loss :  0.118870390425
Iteration :  49   Loss :  0.116376616178
Iteration :  50   Loss :  0.11393515866
Iteration :  51   Loss :  0.111544920322
Iteration :  52   Loss :  0.109204826639
Iteration :  53   Loss :  0.106913825631
Iteration :  54   Loss :  0.104670887385
Iteration :  55   Loss :  0.102475003596
Iteration :  56   Loss :  0.100325187111
Iteration :  57   Loss :  0.0982204714867
Iteration :  58   Loss :  0.0961599105561
Iteration :  59   Loss :  0.0941425780002
Iteration :  60   Loss :  0.0921675669338
Iteration :  61   Loss :  0.0902339894971
Iteration :  62   Loss :  0.0883409764566
Iteration :  63   Loss :  0.0864876768144
Iteration :  64   Loss :  0.0846732574259
Iteration :  65   Loss :  0.0828969026245
Iteration :  66   Loss :  0.0811578138558
Iteration :  67   Loss :  0.0794552093182
Iteration :  68   Loss :  0.0777883236112
Iteration :  69   Loss :  0.0761564073918
Iteration :  70   Loss :  0.0745587270375
Iteration :  71   Loss :  0.0729945643162
Iteration :  72   Loss :  0.0714632160637
Iteration :  73   Loss :  0.0699639938672
Iteration :  74   Loss :  0.0684962237565
Iteration :  75   Loss :  0.0670592459001
Iteration :  76   Loss :  0.0656524143095
Iteration :  77   Loss :  0.0642750965479
Iteration :  78   Loss :  0.0629266734468
Iteration :  79   Loss :  0.0616065388269
Iteration :  80   Loss :  0.0603140992259
Iteration :  81   Loss :  0.0590487736319
Iteration :  82   Loss :  0.0578099932218
Iteration :  83   Loss :  0.056597201106
Iteration :  84   Loss :  0.0554098520777
Iteration :  85   Loss :  0.054247412368
Iteration :  86   Loss :  0.0531093594059
Iteration :  87   Loss :  0.0519951815834
Iteration :  88   Loss :  0.0509043780256
Iteration :  89   Loss :  0.0498364583652
Iteration :  90   Loss :  0.0487909425224
Iteration :  91   Loss :  0.0477673604889
Iteration :  92   Loss :  0.0467652521169
Iteration :  93   Loss :  0.0457841669117
Iteration :  94   Loss :  0.0448236638297
Iteration :  95   Loss :  0.0438833110799
Iteration :  96   Loss :  0.0429626859297
Iteration :  97   Loss :  0.042061374515
Iteration :  98   Loss :  0.0411789716544
Iteration :  99   Loss :  0.0403150806664
[ -1.02922151e-03  -1.03735633e-04  -1.84272758e-04 ...,   7.82766835e-04
   4.72424339e-04   7.07219720e-05]
CROSS VALIDATION 41
Iteration :  0   Loss :  21.0482793545
Iteration :  1   Loss :  1.63722339364
Iteration :  2   Loss :  1.09886104839
Iteration :  3   Loss :  0.308625681603
Iteration :  4   Loss :  0.302151043352
Iteration :  5   Loss :  0.29581223612
Iteration :  6   Loss :  0.289606410314
Iteration :  7   Loss :  0.283530776128
Iteration :  8   Loss :  0.27758260228
Iteration :  9   Loss :  0.271759214786
Iteration :  10   Loss :  0.266057995763
Iteration :  11   Loss :  0.260476382245
Iteration :  12   Loss :  0.255011865037
Iteration :  13   Loss :  0.249661987583
Iteration :  14   Loss :  0.244424344863
Iteration :  15   Loss :  0.239296582311
Iteration :  16   Loss :  0.234276394759
Iteration :  17   Loss :  0.229361525397
Iteration :  18   Loss :  0.224549764762
Iteration :  19   Loss :  0.219838949744
Iteration :  20   Loss :  0.215226962609
Iteration :  21   Loss :  0.210711730054
Iteration :  22   Loss :  0.206291222272
Iteration :  23   Loss :  0.201963452038
Iteration :  24   Loss :  0.197726473815
Iteration :  25   Loss :  0.193578382885
Iteration :  26   Loss :  0.189517314488
Iteration :  27   Loss :  0.185541442981
Iteration :  28   Loss :  0.181648981027
Iteration :  29   Loss :  0.17783817878
Iteration :  30   Loss :  0.174107323108
Iteration :  31   Loss :  0.170454736817
Iteration :  32   Loss :  0.166878777897
Iteration :  33   Loss :  0.163377838788
Iteration :  34   Loss :  0.159950345655
Iteration :  35   Loss :  0.15659475768
Iteration :  36   Loss :  0.153309566367
Iteration :  37   Loss :  0.150093294872
Iteration :  38   Loss :  0.146944497328
Iteration :  39   Loss :  0.143861758205
Iteration :  40   Loss :  0.140843691666
Iteration :  41   Loss :  0.137888940951
Iteration :  42   Loss :  0.134996177761
Iteration :  43   Loss :  0.132164101662
Iteration :  44   Loss :  0.129391439505
Iteration :  45   Loss :  0.126676944849
Iteration :  46   Loss :  0.124019397401
Iteration :  47   Loss :  0.121417602469
Iteration :  48   Loss :  0.118870390425
Iteration :  49   Loss :  0.116376616178
Iteration :  50   Loss :  0.11393515866
Iteration :  51   Loss :  0.111544920322
Iteration :  52   Loss :  0.109204826639
Iteration :  53   Loss :  0.106913825631
Iteration :  54   Loss :  0.104670887385
Iteration :  55   Loss :  0.102475003596
Iteration :  56   Loss :  0.100325187111
Iteration :  57   Loss :  0.0982204714867
Iteration :  58   Loss :  0.0961599105561
Iteration :  59   Loss :  0.0941425780002
Iteration :  60   Loss :  0.0921675669338
Iteration :  61   Loss :  0.0902339894971
Iteration :  62   Loss :  0.0883409764566
Iteration :  63   Loss :  0.0864876768144
Iteration :  64   Loss :  0.0846732574259
Iteration :  65   Loss :  0.0828969026245
Iteration :  66   Loss :  0.0811578138558
Iteration :  67   Loss :  0.0794552093182
Iteration :  68   Loss :  0.0777883236112
Iteration :  69   Loss :  0.0761564073918
Iteration :  70   Loss :  0.0745587270375
Iteration :  71   Loss :  0.0729945643162
Iteration :  72   Loss :  0.0714632160637
Iteration :  73   Loss :  0.0699639938672
Iteration :  74   Loss :  0.0684962237565
Iteration :  75   Loss :  0.0670592459001
Iteration :  76   Loss :  0.0656524143095
Iteration :  77   Loss :  0.0642750965479
Iteration :  78   Loss :  0.0629266734468
Iteration :  79   Loss :  0.0616065388269
Iteration :  80   Loss :  0.0603140992259
Iteration :  81   Loss :  0.0590487736319
Iteration :  82   Loss :  0.0578099932218
Iteration :  83   Loss :  0.056597201106
Iteration :  84   Loss :  0.0554098520777
Iteration :  85   Loss :  0.054247412368
Iteration :  86   Loss :  0.0531093594059
Iteration :  87   Loss :  0.0519951815834
Iteration :  88   Loss :  0.0509043780256
Iteration :  89   Loss :  0.0498364583652
Iteration :  90   Loss :  0.0487909425224
Iteration :  91   Loss :  0.0477673604889
Iteration :  92   Loss :  0.0467652521169
Iteration :  93   Loss :  0.0457841669117
Iteration :  94   Loss :  0.0448236638297
Iteration :  95   Loss :  0.0438833110799
Iteration :  96   Loss :  0.0429626859297
Iteration :  97   Loss :  0.042061374515
Iteration :  98   Loss :  0.0411789716544
Iteration :  99   Loss :  0.0403150806664
[ -1.02922151e-03  -1.03735633e-04  -1.84272758e-04 ...,   7.82766835e-04
   4.72424339e-04   7.07219720e-05]
CROSS VALIDATION 42
Iteration :  0   Loss :  17.3921260308
Iteration :  1   Loss :  0.244069477418
Iteration :  2   Loss :  0.238949159607
Iteration :  3   Loss :  0.233936260613
Iteration :  4   Loss :  0.229028526904
Iteration :  5   Loss :  0.224223752223
Iteration :  6   Loss :  0.2195197766
Iteration :  7   Loss :  0.214914485378
Iteration :  8   Loss :  0.210405808263
Iteration :  9   Loss :  0.205991718395
Iteration :  10   Loss :  0.201670231433
Iteration :  11   Loss :  0.197439404666
Iteration :  12   Loss :  0.193297336142
Iteration :  13   Loss :  0.189242163805
Iteration :  14   Loss :  0.185272064668
Iteration :  15   Loss :  0.181385253983
Iteration :  16   Loss :  0.17757998445
Iteration :  17   Loss :  0.17385454542
Iteration :  18   Loss :  0.170207262135
Iteration :  19   Loss :  0.16663649497
Iteration :  20   Loss :  0.1631406387
Iteration :  21   Loss :  0.159718121772
Iteration :  22   Loss :  0.156367405606
Iteration :  23   Loss :  0.153086983898
Iteration :  24   Loss :  0.149875381946
Iteration :  25   Loss :  0.146731155983
Iteration :  26   Loss :  0.143652892534
Iteration :  27   Loss :  0.140639207776
Iteration :  28   Loss :  0.137688746915
Iteration :  29   Loss :  0.134800183582
Iteration :  30   Loss :  0.131972219233
Iteration :  31   Loss :  0.129203582565
Iteration :  32   Loss :  0.126493028947
Iteration :  33   Loss :  0.123839339859
Iteration :  34   Loss :  0.121241322342
Iteration :  35   Loss :  0.118697808468
Iteration :  36   Loss :  0.116207654807
Iteration :  37   Loss :  0.113769741918
Iteration :  38   Loss :  0.111382973847
Iteration :  39   Loss :  0.109046277629
Iteration :  40   Loss :  0.106758602811
Iteration :  41   Loss :  0.104518920974
Iteration :  42   Loss :  0.102326225278
Iteration :  43   Loss :  0.100179530004
Iteration :  44   Loss :  0.0980778701112
Iteration :  45   Loss :  0.0960203008056
Iteration :  46   Loss :  0.0940058971137
Iteration :  47   Loss :  2.61515333618
Iteration :  48   Loss :  10.2712936165
Iteration :  49   Loss :  0.151888208618
Iteration :  50   Loss :  0.148701755695
Iteration :  51   Loss :  0.145582151162
Iteration :  52   Loss :  0.142527992611
Iteration :  53   Loss :  0.139537907055
Iteration :  54   Loss :  0.136610550311
Iteration :  55   Loss :  0.133744606395
Iteration :  56   Loss :  0.130938786931
Iteration :  57   Loss :  0.128191830573
Iteration :  58   Loss :  0.125502502435
Iteration :  59   Loss :  0.122869593539
Iteration :  60   Loss :  0.120291920268
Iteration :  61   Loss :  0.117768323838
Iteration :  62   Loss :  0.115297669775
Iteration :  63   Loss :  0.112878847404
Iteration :  64   Loss :  0.110510769351
Iteration :  65   Loss :  0.108192371055
Iteration :  66   Loss :  0.105922610287
Iteration :  67   Loss :  0.103700466684
Iteration :  68   Loss :  0.101524941288
Iteration :  69   Loss :  0.0993950560986
Iteration :  70   Loss :  0.0973098536332
Iteration :  71   Loss :  0.0952683964958
Iteration :  72   Loss :  0.0932697669558
Iteration :  73   Loss :  0.091313066536
Iteration :  74   Loss :  0.0893974156079
Iteration :  75   Loss :  0.087521952997
Iteration :  76   Loss :  0.0856858355952
Iteration :  77   Loss :  0.0838882379818
Iteration :  78   Loss :  0.0821283520526
Iteration :  79   Loss :  0.0804053866568
Iteration :  80   Loss :  0.0787185672408
Iteration :  81   Loss :  0.0770671355004
Iteration :  82   Loss :  0.0754503490399
Iteration :  83   Loss :  0.0738674810381
Iteration :  84   Loss :  0.072317819922
Iteration :  85   Loss :  0.0708006690464
Iteration :  86   Loss :  0.0693153463811
Iteration :  87   Loss :  0.0678611842041
Iteration :  88   Loss :  0.0664375288015
Iteration :  89   Loss :  0.0650437401737
Iteration :  90   Loss :  0.0636791917476
Iteration :  91   Loss :  0.0623432700948
Iteration :  92   Loss :  0.0610353746561
Iteration :  93   Loss :  0.0597549174714
Iteration :  94   Loss :  0.0585013229153
Iteration :  95   Loss :  0.0572740274385
Iteration :  96   Loss :  0.0560724793142
Iteration :  97   Loss :  0.0548961383905
Iteration :  98   Loss :  0.0537444758471
Iteration :  99   Loss :  0.0526169739578
[ -1.18368821e-03  -1.21673319e-04  -3.73643623e-04 ...,   7.95906385e-04
   3.96139969e-04   3.43842271e-05]
CROSS VALIDATION 43
Iteration :  0   Loss :  21.0499395035
Iteration :  1   Loss :  1.63923746402
Iteration :  2   Loss :  1.1022223143
Iteration :  3   Loss :  0.308629853812
Iteration :  4   Loss :  0.302155128033
Iteration :  5   Loss :  0.295816235108
Iteration :  6   Loss :  0.289610325408
Iteration :  7   Loss :  0.283534609087
Iteration :  8   Loss :  0.277586354827
Iteration :  9   Loss :  0.271762888609
Iteration :  10   Loss :  0.266061592513
Iteration :  11   Loss :  0.26047990354
Iteration :  12   Loss :  0.255015312459
Iteration :  13   Loss :  0.249665362681
Iteration :  14   Loss :  0.244427649155
Iteration :  15   Loss :  0.239299817283
Iteration :  16   Loss :  0.234279561864
Iteration :  17   Loss :  0.22936462606
Iteration :  18   Loss :  0.224552800377
Iteration :  19   Loss :  0.219841921674
Iteration :  20   Loss :  0.215229872191
Iteration :  21   Loss :  0.210714578597
Iteration :  22   Loss :  0.206294011055
Iteration :  23   Loss :  0.201966182315
Iteration :  24   Loss :  0.197729146814
Iteration :  25   Loss :  0.193580999808
Iteration :  26   Loss :  0.18951987651
Iteration :  27   Loss :  0.185543951255
Iteration :  28   Loss :  0.18165143668
Iteration :  29   Loss :  0.177840582916
Iteration :  30   Loss :  0.174109676808
Iteration :  31   Loss :  0.170457041138
Iteration :  32   Loss :  0.166881033876
Iteration :  33   Loss :  0.163380047439
Iteration :  34   Loss :  0.159952507971
Iteration :  35   Loss :  0.156596874633
Iteration :  36   Loss :  0.153311638909
Iteration :  37   Loss :  0.150095323933
Iteration :  38   Loss :  0.146946483822
Iteration :  39   Loss :  0.143863703024
Iteration :  40   Loss :  0.140845595686
Iteration :  41   Loss :  0.137890805026
Iteration :  42   Loss :  0.134998002729
Iteration :  43   Loss :  0.132165888345
Iteration :  44   Loss :  0.129393188706
Iteration :  45   Loss :  0.126678657353
Iteration :  46   Loss :  0.124021073978
Iteration :  47   Loss :  0.121419243873
Iteration :  48   Loss :  0.118871997395
Iteration :  49   Loss :  0.116378189435
Iteration :  50   Loss :  0.113936698912
Iteration :  51   Loss :  0.111546428261
Iteration :  52   Loss :  0.109206302943
Iteration :  53   Loss :  0.106915270964
Iteration :  54   Loss :  0.104672302396
Iteration :  55   Loss :  0.102476388921
Iteration :  56   Loss :  0.100326543374
Iteration :  57   Loss :  0.0982217992969
Iteration :  58   Loss :  0.0961612105103
Iteration :  59   Loss :  0.0941438506827
Iteration :  60   Loss :  0.0921688129168
Iteration :  61   Loss :  0.0902352093407
Iteration :  62   Loss :  0.0883421707092
Iteration :  63   Loss :  0.0864888460129
Iteration :  64   Loss :  0.0846744020957
Iteration :  65   Loss :  0.0828980232804
Iteration :  66   Loss :  0.0811589110016
Iteration :  67   Loss :  0.079456283447
Iteration :  68   Loss :  0.0777893752059
Iteration :  69   Loss :  0.0761574369252
Iteration :  70   Loss :  0.0745597349724
Iteration :  71   Loss :  0.0729955511057
Iteration :  72   Loss :  0.0714641821513
Iteration :  73   Loss :  0.0699649396874
Iteration :  74   Loss :  0.0684971497344
Iteration :  75   Loss :  0.067060152452
Iteration :  76   Loss :  0.0656533018428
Iteration :  77   Loss :  0.0642759654618
Iteration :  78   Loss :  0.0629275241318
Iteration :  79   Loss :  0.0616073716654
Iteration :  80   Loss :  0.0603149145923
Iteration :  81   Loss :  0.0590495718928
Iteration :  82   Loss :  0.057810774736
Iteration :  83   Loss :  0.0565979662249
Iteration :  84   Loss :  0.0554106011452
Iteration :  85   Loss :  0.0542481457208
Iteration :  86   Loss :  0.0531100773738
Iteration :  87   Loss :  0.0519958844892
Iteration :  88   Loss :  0.0509050661851
Iteration :  89   Loss :  0.0498371320878
Iteration :  90   Loss :  0.0487916021111
Iteration :  91   Loss :  0.0477680062402
Iteration :  92   Loss :  0.046765884321
Iteration :  93   Loss :  0.0457847858528
Iteration :  94   Loss :  0.0448242697861
Iteration :  95   Loss :  0.0438839043239
Iteration :  96   Loss :  0.0429632667281
Iteration :  97   Loss :  0.0420619431289
Iteration :  98   Loss :  0.0411795283394
Iteration :  99   Loss :  0.0403156256727
[ -1.02920888e-03  -1.03727596e-04  -1.84283548e-04 ...,   7.82784708e-04
   4.72386577e-04   7.07289602e-05]
CROSS VALIDATION 44
Iteration :  0   Loss :  6.48821909181
Iteration :  1   Loss :  2.4857586918
Iteration :  2   Loss :  0.288199098858
Iteration :  3   Loss :  0.282152988568
Iteration :  4   Loss :  0.276233719235
Iteration :  5   Loss :  0.270438629872
Iteration :  6   Loss :  0.264765115314
Iteration :  7   Loss :  0.259210625052
Iteration :  8   Loss :  0.253772662083
Iteration :  9   Loss :  0.248448781788
Iteration :  10   Loss :  0.243236590833
Iteration :  11   Loss :  0.238133746097
Iteration :  12   Loss :  0.23313795361
Iteration :  13   Loss :  0.228246967532
Iteration :  14   Loss :  0.223458589135
Iteration :  15   Loss :  0.218770665819
Iteration :  16   Loss :  0.214181090144
Iteration :  17   Loss :  0.20968779888
Iteration :  18   Loss :  0.205288772084
Iteration :  19   Loss :  0.200982032187
Iteration :  20   Loss :  0.196765643109
Iteration :  21   Loss :  0.192637709384
Iteration :  22   Loss :  0.188596375315
Iteration :  23   Loss :  0.184639824132
Iteration :  24   Loss :  0.180766277181
Iteration :  25   Loss :  0.176973993122
Iteration :  26   Loss :  0.173261267145
Iteration :  27   Loss :  0.169626430207
Iteration :  28   Loss :  0.166067848278
Iteration :  29   Loss :  0.162583921609
Iteration :  30   Loss :  0.159173084014
Iteration :  31   Loss :  0.15583380216
Iteration :  32   Loss :  0.152564574884
Iteration :  33   Loss :  0.149363932517
Iteration :  34   Loss :  0.146230436219
Iteration :  35   Loss :  0.143162677337
Iteration :  36   Loss :  0.140159276772
Iteration :  37   Loss :  0.137218884352
Iteration :  38   Loss :  0.134340178236
Iteration :  39   Loss :  0.131521864309
Iteration :  40   Loss :  0.128762675608
Iteration :  41   Loss :  0.126061371749
Iteration :  42   Loss :  0.123416738369
Iteration :  43   Loss :  0.120827586582
Iteration :  44   Loss :  0.118292752443
Iteration :  45   Loss :  0.115811096426
Iteration :  46   Loss :  0.113381502911
Iteration :  47   Loss :  0.111002879681
Iteration :  48   Loss :  0.108674157434
Iteration :  49   Loss :  0.1063942893
Iteration :  50   Loss :  0.104162250374
Iteration :  51   Loss :  0.101977037247
Iteration :  52   Loss :  0.0998376675661
Iteration :  53   Loss :  0.0977431795834
Iteration :  54   Loss :  0.0956926317288
Iteration :  55   Loss :  0.0936851021853
Iteration :  56   Loss :  0.0917196884745
Iteration :  57   Loss :  0.089795507051
Iteration :  58   Loss :  0.0879116929054
Iteration :  59   Loss :  0.0934917625306
Iteration :  60   Loss :  0.102683387007
Iteration :  61   Loss :  0.100529198859
Iteration :  62   Loss :  0.0984202032862
Iteration :  63   Loss :  0.0963554521951
Iteration :  64   Loss :  0.0943340173838
Iteration :  65   Loss :  0.092354990123
Iteration :  66   Loss :  0.0936552703239
Iteration :  67   Loss :  0.120605291599
Iteration :  68   Loss :  0.118075120973
Iteration :  69   Loss :  0.115598030632
Iteration :  70   Loss :  0.11317290701
Iteration :  71   Loss :  0.1107986599
Iteration :  72   Loss :  0.108474221967
Iteration :  73   Loss :  0.106198548267
Iteration :  74   Loss :  0.103970615778
Iteration :  75   Loss :  0.101789422942
Iteration :  76   Loss :  0.0996539892089
Iteration :  77   Loss :  0.0975633546026
Iteration :  78   Loss :  0.0955165792847
Iteration :  79   Loss :  0.093512743134
Iteration :  80   Loss :  0.0915509453326
Iteration :  81   Loss :  0.0896303039607
Iteration :  82   Loss :  0.0877499556
Iteration :  83   Loss :  0.0859090549463
Iteration :  84   Loss :  0.0841067744285
Iteration :  85   Loss :  0.0823423038374
Iteration :  86   Loss :  0.0806148499609
Iteration :  87   Loss :  0.0789236362277
Iteration :  88   Loss :  0.0772679023583
Iteration :  89   Loss :  0.0756469040228
Iteration :  90   Loss :  0.0740599125068
Iteration :  91   Loss :  0.0725062143833
Iteration :  92   Loss :  0.0709851111925
Iteration :  93   Loss :  0.0694959191273
Iteration :  94   Loss :  0.0680379687263
Iteration :  95   Loss :  0.0666106045726
Iteration :  96   Loss :  0.0652131849994
Iteration :  97   Loss :  0.0638450818012
Iteration :  98   Loss :  0.0625056799517
Iteration :  99   Loss :  0.0611943773271
[ -1.09373679e-03  -3.02254483e-05  -1.01792911e-04 ...,   7.56342190e-04
   2.82035291e-04   1.00745786e-04]
CROSS VALIDATION 45
Iteration :  0   Loss :  21.0539409623
Iteration :  1   Loss :  1.63945203701
Iteration :  2   Loss :  1.10285369691
Iteration :  3   Loss :  0.308631089591
Iteration :  4   Loss :  0.302156337886
Iteration :  5   Loss :  0.29581741958
Iteration :  6   Loss :  0.289611485031
Iteration :  7   Loss :  0.283535744383
Iteration :  8   Loss :  0.277587466306
Iteration :  9   Loss :  0.27176397677
Iteration :  10   Loss :  0.266062657845
Iteration :  11   Loss :  0.260480946522
Iteration :  12   Loss :  0.255016333561
Iteration :  13   Loss :  0.249666362362
Iteration :  14   Loss :  0.244428627863
Iteration :  15   Loss :  0.239300775459
Iteration :  16   Loss :  0.234280499939
Iteration :  17   Loss :  0.229365544455
Iteration :  18   Loss :  0.224553699504
Iteration :  19   Loss :  0.219842801939
Iteration :  20   Loss :  0.215230733989
Iteration :  21   Loss :  0.210715422315
Iteration :  22   Loss :  0.206294837073
Iteration :  23   Loss :  0.201966991004
Iteration :  24   Loss :  0.197729938538
Iteration :  25   Loss :  0.193581774922
Iteration :  26   Loss :  0.189520635363
Iteration :  27   Loss :  0.185544694188
Iteration :  28   Loss :  0.181652164027
Iteration :  29   Loss :  0.177841295004
Iteration :  30   Loss :  0.174110373957
Iteration :  31   Loss :  0.170457723662
Iteration :  32   Loss :  0.166881702081
Iteration :  33   Loss :  0.163380701626
Iteration :  34   Loss :  0.159953148434
Iteration :  35   Loss :  0.156597501659
Iteration :  36   Loss :  0.153312252781
Iteration :  37   Loss :  0.150095924927
Iteration :  38   Loss :  0.146947072208
Iteration :  39   Loss :  0.143864279066
Iteration :  40   Loss :  0.140846159643
Iteration :  41   Loss :  0.137891357152
Iteration :  42   Loss :  0.134998543272
Iteration :  43   Loss :  0.132166417548
Iteration :  44   Loss :  0.129393706806
Iteration :  45   Loss :  0.126679164584
Iteration :  46   Loss :  0.124021570569
Iteration :  47   Loss :  0.121419730046
Iteration :  48   Loss :  0.118872473368
Iteration :  49   Loss :  0.116378655423
Iteration :  50   Loss :  0.113937155124
Iteration :  51   Loss :  0.111546874902
Iteration :  52   Loss :  0.109206740214
Iteration :  53   Loss :  0.106915699061
Iteration :  54   Loss :  0.104672721513
Iteration :  55   Loss :  0.102476799245
Iteration :  56   Loss :  0.100326945089
Iteration :  57   Loss :  0.0982221925849
Iteration :  58   Loss :  0.0961615955475
Iteration :  59   Loss :  0.0941442276424
Iteration :  60   Loss :  0.0921691819682
Iteration :  61   Loss :  0.0902355706498
Iteration :  62   Loss :  0.0883425244384
Iteration :  63   Loss :  0.0864891923212
Iteration :  64   Loss :  0.0846747411389
Iteration :  65   Loss :  0.0828983552108
Iteration :  66   Loss :  0.0811592359684
Iteration :  67   Loss :  0.0794566015964
Iteration :  68   Loss :  0.0777896866809
Iteration :  69   Loss :  0.0761577418658
Iteration :  70   Loss :  0.0745600335156
Iteration :  71   Loss :  0.0729958433858
Iteration :  72   Loss :  0.0714644682997
Iteration :  73   Loss :  0.0699652198327
Iteration :  74   Loss :  0.0684974240025
Iteration :  75   Loss :  0.0670604209663
Iteration :  76   Loss :  0.065653564724
Iteration :  77   Loss :  0.064276222828
Iteration :  78   Loss :  0.0629277760987
Iteration :  79   Loss :  0.0616076183463
Iteration :  80   Loss :  0.0603151560981
Iteration :  81   Loss :  0.059049808332
Iteration :  82   Loss :  0.0578110062151
Iteration :  83   Loss :  0.0565981928477
Iteration :  84   Loss :  0.0554108230137
Iteration :  85   Loss :  0.0542483629348
Iteration :  86   Loss :  0.0531102900309
Iteration :  87   Loss :  0.0519960926849
Iteration :  88   Loss :  0.0509052700131
Iteration :  89   Loss :  0.0498373316398
Iteration :  90   Loss :  0.0487917974766
Iteration :  91   Loss :  0.0477681975071
Iteration :  92   Loss :  0.0467660715753
Iteration :  93   Loss :  0.0457849691788
Iteration :  94   Loss :  0.0448244492661
Iteration :  95   Loss :  0.0438840800386
Iteration :  96   Loss :  0.0429634387565
Iteration :  97   Loss :  0.0420621115483
Iteration :  98   Loss :  0.0411796932255
Iteration :  99   Loss :  0.0403157870997
[ -1.02919955e-03  -1.03727205e-04  -1.84234582e-04 ...,   7.82784708e-04
   4.72386577e-04   7.07289602e-05]
CROSS VALIDATION 46
Iteration :  0   Loss :  16.1087518127
Iteration :  1   Loss :  0.303986542952
Iteration :  2   Loss :  0.297609228892
Iteration :  3   Loss :  0.291365704091
Iteration :  4   Loss :  0.285253161794
Iteration :  5   Loss :  0.279268854128
Iteration :  6   Loss :  0.273410090866
Iteration :  7   Loss :  0.26767423822
Iteration :  8   Loss :  0.262058717656
Iteration :  9   Loss :  0.256561004736
Iteration :  10   Loss :  0.25117862798
Iteration :  11   Loss :  0.245909167759
Iteration :  12   Loss :  0.240750255203
Iteration :  13   Loss :  0.235699571141
Iteration :  14   Loss :  0.230754845054
Iteration :  15   Loss :  0.225913854056
Iteration :  16   Loss :  0.221174421896
Iteration :  17   Loss :  0.216534417977
Iteration :  18   Loss :  0.211991756401
Iteration :  19   Loss :  0.207544395029
Iteration :  20   Loss :  0.203190334564
Iteration :  21   Loss :  0.198927617652
Iteration :  22   Loss :  0.194754328003
Iteration :  23   Loss :  0.190668589529
Iteration :  24   Loss :  0.186668565498
Iteration :  25   Loss :  0.182752457713
Iteration :  26   Loss :  0.1789185057
Iteration :  27   Loss :  0.175164985919
Iteration :  28   Loss :  0.171490210988
Iteration :  29   Loss :  0.167892528922
Iteration :  30   Loss :  0.164370322396
Iteration :  31   Loss :  0.160922008014
Iteration :  32   Loss :  0.157546035596
Iteration :  33   Loss :  0.154240887486
Iteration :  34   Loss :  0.151005077865
Iteration :  35   Loss :  0.147837152084
Iteration :  36   Loss :  0.144735686015
Iteration :  37   Loss :  0.141699285401
Iteration :  38   Loss :  0.13872658524
Iteration :  39   Loss :  0.135816249164
Iteration :  40   Loss :  0.132966968841
Iteration :  41   Loss :  0.130177463385
Iteration :  42   Loss :  0.127446478785
Iteration :  43   Loss :  0.124772787334
Iteration :  44   Loss :  0.122155187083
Iteration :  45   Loss :  0.119592501299
Iteration :  46   Loss :  0.117083577935
Iteration :  47   Loss :  0.114627289112
Iteration :  48   Loss :  0.112222530613
Iteration :  49   Loss :  0.109868221388
Iteration :  50   Loss :  0.107563303064
Iteration :  51   Loss :  0.105306739473
Iteration :  52   Loss :  0.103097516184
Iteration :  53   Loss :  0.100934640047
Iteration :  54   Loss :  0.0988171387498
Iteration :  55   Loss :  0.0967440603752
Iteration :  56   Loss :  0.094714472978
Iteration :  57   Loss :  0.0927274641638
Iteration :  58   Loss :  0.0907821406792
Iteration :  59   Loss :  0.0888776280104
Iteration :  60   Loss :  0.08701306999
Iteration :  61   Loss :  0.0851876284119
Iteration :  62   Loss :  0.0834004826548
Iteration :  63   Loss :  0.0816508293132
Iteration :  64   Loss :  0.0799378818361
Iteration :  65   Loss :  0.0782608701735
Iteration :  66   Loss :  0.0766190404304
Iteration :  67   Loss :  0.0750116545274
Iteration :  68   Loss :  0.0734379898695
Iteration :  69   Loss :  0.0718973390209
Iteration :  70   Loss :  0.070389009387
Iteration :  71   Loss :  0.0689123229031
Iteration :  72   Loss :  0.0674666157296
Iteration :  73   Loss :  0.0660512379536
Iteration :  74   Loss :  0.0646655532966
Iteration :  75   Loss :  0.0633089388285
Iteration :  76   Loss :  0.0619807846878
Iteration :  77   Loss :  0.060680493807
Iteration :  78   Loss :  0.0594074816448
Iteration :  79   Loss :  0.0581611759224
Iteration :  80   Loss :  0.0569410163674
Iteration :  81   Loss :  0.0557464544609
Iteration :  82   Loss :  0.0545769531916
Iteration :  83   Loss :  0.0534319868138
Iteration :  84   Loss :  0.0523110406118
Iteration :  85   Loss :  0.0512136106678
Iteration :  86   Loss :  0.0501392036357
Iteration :  87   Loss :  0.0490873365195
Iteration :  88   Loss :  0.0480575364555
Iteration :  89   Loss :  0.0470493405006
Iteration :  90   Loss :  0.0460622954236
Iteration :  91   Loss :  0.0450959575015
Iteration :  92   Loss :  0.0441498923203
Iteration :  93   Loss :  0.0432236745794
Iteration :  94   Loss :  0.0423168879008
Iteration :  95   Loss :  0.0414291246413
Iteration :  96   Loss :  0.0405599857099
Iteration :  97   Loss :  0.0397090803881
Iteration :  98   Loss :  0.0388760261541
Iteration :  99   Loss :  0.0380604485111
[ -1.29396413e-03  -1.14529142e-04  -3.61847002e-04 ...,   7.60558483e-04
   3.70385027e-04   3.45642522e-05]
CROSS VALIDATION 47
Iteration :  0   Loss :  11.981523152
Iteration :  1   Loss :  0.845816357824
Iteration :  2   Loss :  0.300135939443
Iteration :  3   Loss :  0.293839406945
Iteration :  4   Loss :  0.287674968996
Iteration :  5   Loss :  0.281639854392
Iteration :  6   Loss :  0.275731350068
Iteration :  7   Loss :  0.269946799875
Iteration :  8   Loss :  0.264283603388
Iteration :  9   Loss :  0.258739214733
Iteration :  10   Loss :  0.25331114145
Iteration :  11   Loss :  0.247996943367
Iteration :  12   Loss :  0.242794231501
Iteration :  13   Loss :  0.237700666993
Iteration :  14   Loss :  0.232713960045
Iteration :  15   Loss :  0.2278318689
Iteration :  16   Loss :  0.22305219883
Iteration :  17   Loss :  0.21837280115
Iteration :  18   Loss :  0.213791572252
Iteration :  19   Loss :  0.20930645266
Iteration :  20   Loss :  0.204915426101
Iteration :  21   Loss :  0.200616518606
Iteration :  22   Loss :  0.196407797613
Iteration :  23   Loss :  0.192287371106
Iteration :  24   Loss :  0.188253386761
Iteration :  25   Loss :  0.184304031113
Iteration :  26   Loss :  0.180437528742
Iteration :  27   Loss :  0.176652141475
Iteration :  28   Loss :  0.172946167603
Iteration :  29   Loss :  0.169317941117
Iteration :  30   Loss :  0.165765830961
Iteration :  31   Loss :  0.162288240295
Iteration :  32   Loss :  0.158883605778
Iteration :  33   Loss :  0.155550396869
Iteration :  34   Loss :  0.152287115135
Iteration :  35   Loss :  0.149092293578
Iteration :  36   Loss :  0.145964495976
Iteration :  37   Loss :  0.142902316237
Iteration :  38   Loss :  0.13990437777
Iteration :  39   Loss :  0.136969332861
Iteration :  40   Loss :  0.134095862069
Iteration :  41   Loss :  0.131282673635
Iteration :  42   Loss :  0.1285285029
Iteration :  43   Loss :  0.125832111735
Iteration :  44   Loss :  0.123192287986
Iteration :  45   Loss :  0.120607844929
Iteration :  46   Loss :  0.118077620736
Iteration :  47   Loss :  0.115600477954
Iteration :  48   Loss :  0.113175302989
Iteration :  49   Loss :  0.110801005614
Iteration :  50   Loss :  0.10847651847
Iteration :  51   Loss :  0.106200796592
Iteration :  52   Loss :  0.103972816936
Iteration :  53   Loss :  0.101791577922
Iteration :  54   Loss :  0.0996560989798
Iteration :  55   Loss :  0.0975654201127
Iteration :  56   Loss :  0.0955186014626
Iteration :  57   Loss :  0.0935147228888
Iteration :  58   Loss :  0.0915528835543
Iteration :  59   Loss :  0.0896322015205
Iteration :  60   Loss :  0.0877518133511
Iteration :  61   Loss :  0.0859108737237
Iteration :  62   Loss :  0.0841085550499
Iteration :  63   Loss :  0.0823440471032
Iteration :  64   Loss :  0.0806165566548
Iteration :  65   Loss :  0.0789253071171
Iteration :  66   Loss :  0.0772695381941
Iteration :  67   Loss :  0.0756485055406
Iteration :  68   Loss :  0.0740614804264
Iteration :  69   Loss :  0.0725077494097
Iteration :  70   Loss :  0.0709866140156
Iteration :  71   Loss :  0.0694973904228
Iteration :  72   Loss :  0.0680394091556
Iteration :  73   Loss :  0.0666120147832
Iteration :  74   Loss :  0.0652145656253
Iteration :  75   Loss :  0.063846433463
Iteration :  76   Loss :  0.0625070032571
Iteration :  77   Loss :  0.061195672871
Iteration :  78   Loss :  0.0599118528004
Iteration :  79   Loss :  0.0586549659081
Iteration :  80   Loss :  0.0574244471649
Iteration :  81   Loss :  0.0562197433949
Iteration :  82   Loss :  0.0550403130275
Iteration :  83   Loss :  0.0538856258537
Iteration :  84   Loss :  0.0527551627876
Iteration :  85   Loss :  0.0516484156331
Iteration :  86   Loss :  0.0505648868557
Iteration :  87   Loss :  0.0495040893587
Iteration :  88   Loss :  0.0484655462638
Iteration :  89   Loss :  0.0474487906975
Iteration :  90   Loss :  0.0464533655805
Iteration :  91   Loss :  0.0454788234229
Iteration :  92   Loss :  0.0445247261222
Iteration :  93   Loss :  0.0435906447672
Iteration :  94   Loss :  0.0426761594447
Iteration :  95   Loss :  0.0417808590507
Iteration :  96   Loss :  0.0409043411059
Iteration :  97   Loss :  0.0400462115744
Iteration :  98   Loss :  0.039206084687
Iteration :  99   Loss :  0.0383835827674
[ -7.03170585e-04  -8.31937769e-05  -2.11697239e-04 ...,   1.58022044e-04
   4.52212289e-04   3.38393781e-05]
CROSS VALIDATION 48
Iteration :  0   Loss :  21.0572951296
Iteration :  1   Loss :  1.63883756554
Iteration :  2   Loss :  1.10135823835
Iteration :  3   Loss :  0.308643509288
Iteration :  4   Loss :  0.302168497031
Iteration :  5   Loss :  0.295829323639
Iteration :  6   Loss :  0.289623139356
Iteration :  7   Loss :  0.283547154212
Iteration :  8   Loss :  0.277598636768
Iteration :  9   Loss :  0.271774912888
Iteration :  10   Loss :  0.266073364535
Iteration :  11   Loss :  0.260491428598
Iteration :  12   Loss :  0.255026595733
Iteration :  13   Loss :  0.249676409245
Iteration :  14   Loss :  0.244438463973
Iteration :  15   Loss :  0.239310405218
Iteration :  16   Loss :  0.234289927676
Iteration :  17   Loss :  0.229374774408
Iteration :  18   Loss :  0.224562735823
Iteration :  19   Loss :  0.219851648685
Iteration :  20   Loss :  0.21523939514
Iteration :  21   Loss :  0.210723901764
Iteration :  22   Loss :  0.206303138633
Iteration :  23   Loss :  0.201975118405
Iteration :  24   Loss :  0.197737895435
Iteration :  25   Loss :  0.193589564892
Iteration :  26   Loss :  0.189528261907
Iteration :  27   Loss :  0.185552160736
Iteration :  28   Loss :  0.181659473934
Iteration :  29   Loss :  0.177848451558
Iteration :  30   Loss :  0.174117380374
Iteration :  31   Loss :  0.170464583091
Iteration :  32   Loss :  0.166888417607
Iteration :  33   Loss :  0.163387276268
Iteration :  34   Loss :  0.159959585147
Iteration :  35   Loss :  0.156603803336
Iteration :  36   Loss :  0.153318422256
Iteration :  37   Loss :  0.150101964973
Iteration :  38   Loss :  0.14695298554
Iteration :  39   Loss :  0.143870068343
Iteration :  40   Loss :  0.140851827467
Iteration :  41   Loss :  0.137896906071
Iteration :  42   Loss :  0.135003975781
Iteration :  43   Loss :  0.132171736088
Iteration :  44   Loss :  0.129398913769
Iteration :  45   Loss :  0.126684262311
Iteration :  46   Loss :  0.12402656135
Iteration :  47   Loss :  0.121424616126
Iteration :  48   Loss :  0.118877256943
Iteration :  49   Loss :  0.116383338644
Iteration :  50   Loss :  0.113941740096
Iteration :  51   Loss :  0.111551363686
Iteration :  52   Loss :  0.109211134828
Iteration :  53   Loss :  0.106920001481
Iteration :  54   Loss :  0.104676933672
Iteration :  55   Loss :  0.102480923038
Iteration :  56   Loss :  0.10033098237
Iteration :  57   Loss :  0.0982261451674
Iteration :  58   Loss :  0.096165465209
Iteration :  59   Loss :  0.0941480161225
Iteration :  60   Loss :  0.09217289097
Iteration :  61   Loss :  0.0902392018407
Iteration :  62   Loss :  0.0883460794508
Iteration :  63   Loss :  0.0864926727532
Iteration :  64   Loss :  0.0846781485552
Iteration :  65   Loss :  0.0829016911431
Iteration :  66   Loss :  0.0811625019164
Iteration :  67   Loss :  0.0794597990282
Iteration :  68   Loss :  0.077792817034
Iteration :  69   Loss :  0.0761608065475
Iteration :  70   Loss :  0.0745630339035
Iteration :  71   Loss :  0.0729987808288
Iteration :  72   Loss :  0.0714673441183
Iteration :  73   Loss :  0.0699680353197
Iteration :  74   Loss :  0.0685001804235
Iteration :  75   Loss :  0.0670631195605
Iteration :  76   Loss :  0.0656562067046
Iteration :  77   Loss :  0.0642788093826
Iteration :  78   Loss :  0.0629303083902
Iteration :  79   Loss :  0.061610097513
Iteration :  80   Loss :  0.0603175832546
Iteration :  81   Loss :  0.0590521845693
Iteration :  82   Loss :  0.0578133326014
Iteration :  83   Loss :  0.056600470429
Iteration :  84   Loss :  0.0554130528137
Iteration :  85   Loss :  0.054250545956
Iteration :  86   Loss :  0.0531124272546
Iteration :  87   Loss :  0.0519981850719
Iteration :  88   Loss :  0.0509073185041
Iteration :  89   Loss :  0.0498393371556
Iteration :  90   Loss :  0.0487937609188
Iteration :  91   Loss :  0.0477701197584
Iteration :  92   Loss :  0.0467679534999
Iteration :  93   Loss :  0.0457868116226
Iteration :  94   Loss :  0.0448262530573
Iteration :  95   Loss :  0.0438858459883
Iteration :  96   Loss :  0.0429651676584
Iteration :  97   Loss :  0.0420638041797
Iteration :  98   Loss :  0.0411813503473
Iteration :  99   Loss :  0.0403174094569
[ -1.02922529e-03  -1.03762022e-04  -1.84259157e-04 ...,   7.82808681e-04
   4.72389983e-04   7.07289588e-05]
CROSS VALIDATION 49
Iteration :  0   Loss :  21.0572951296
Iteration :  1   Loss :  1.63883756554
Iteration :  2   Loss :  1.10135823835
Iteration :  3   Loss :  0.308643509288
Iteration :  4   Loss :  0.302168497031
Iteration :  5   Loss :  0.295829323639
Iteration :  6   Loss :  0.289623139356
Iteration :  7   Loss :  0.283547154212
Iteration :  8   Loss :  0.277598636768
Iteration :  9   Loss :  0.271774912888
Iteration :  10   Loss :  0.266073364535
Iteration :  11   Loss :  0.260491428598
Iteration :  12   Loss :  0.255026595733
Iteration :  13   Loss :  0.249676409245
Iteration :  14   Loss :  0.244438463973
Iteration :  15   Loss :  0.239310405218
Iteration :  16   Loss :  0.234289927676
Iteration :  17   Loss :  0.229374774408
Iteration :  18   Loss :  0.224562735823
Iteration :  19   Loss :  0.219851648685
Iteration :  20   Loss :  0.21523939514
Iteration :  21   Loss :  0.210723901764
Iteration :  22   Loss :  0.206303138633
Iteration :  23   Loss :  0.201975118405
Iteration :  24   Loss :  0.197737895435
Iteration :  25   Loss :  0.193589564892
Iteration :  26   Loss :  0.189528261907
Iteration :  27   Loss :  0.185552160736
Iteration :  28   Loss :  0.181659473934
Iteration :  29   Loss :  0.177848451558
Iteration :  30   Loss :  0.174117380374
Iteration :  31   Loss :  0.170464583091
Iteration :  32   Loss :  0.166888417607
Iteration :  33   Loss :  0.163387276268
Iteration :  34   Loss :  0.159959585147
Iteration :  35   Loss :  0.156603803336
Iteration :  36   Loss :  0.153318422256
Iteration :  37   Loss :  0.150101964973
Iteration :  38   Loss :  0.14695298554
Iteration :  39   Loss :  0.143870068343
Iteration :  40   Loss :  0.140851827467
Iteration :  41   Loss :  0.137896906071
Iteration :  42   Loss :  0.135003975781
Iteration :  43   Loss :  0.132171736088
Iteration :  44   Loss :  0.129398913769
Iteration :  45   Loss :  0.126684262311
Iteration :  46   Loss :  0.12402656135
Iteration :  47   Loss :  0.121424616126
Iteration :  48   Loss :  0.118877256943
Iteration :  49   Loss :  0.116383338644
Iteration :  50   Loss :  0.113941740096
Iteration :  51   Loss :  0.111551363686
Iteration :  52   Loss :  0.109211134828
Iteration :  53   Loss :  0.106920001481
Iteration :  54   Loss :  0.104676933672
Iteration :  55   Loss :  0.102480923038
Iteration :  56   Loss :  0.10033098237
Iteration :  57   Loss :  0.0982261451674
Iteration :  58   Loss :  0.096165465209
Iteration :  59   Loss :  0.0941480161225
Iteration :  60   Loss :  0.09217289097
Iteration :  61   Loss :  0.0902392018407
Iteration :  62   Loss :  0.0883460794508
Iteration :  63   Loss :  0.0864926727532
Iteration :  64   Loss :  0.0846781485552
Iteration :  65   Loss :  0.0829016911431
Iteration :  66   Loss :  0.0811625019164
Iteration :  67   Loss :  0.0794597990282
Iteration :  68   Loss :  0.077792817034
Iteration :  69   Loss :  0.0761608065475
Iteration :  70   Loss :  0.0745630339035
Iteration :  71   Loss :  0.0729987808288
Iteration :  72   Loss :  0.0714673441183
Iteration :  73   Loss :  0.0699680353197
Iteration :  74   Loss :  0.0685001804235
Iteration :  75   Loss :  0.0670631195605
Iteration :  76   Loss :  0.0656562067046
Iteration :  77   Loss :  0.0642788093826
Iteration :  78   Loss :  0.0629303083902
Iteration :  79   Loss :  0.061610097513
Iteration :  80   Loss :  0.0603175832546
Iteration :  81   Loss :  0.0590521845693
Iteration :  82   Loss :  0.0578133326014
Iteration :  83   Loss :  0.056600470429
Iteration :  84   Loss :  0.0554130528137
Iteration :  85   Loss :  0.054250545956
Iteration :  86   Loss :  0.0531124272546
Iteration :  87   Loss :  0.0519981850719
Iteration :  88   Loss :  0.0509073185041
Iteration :  89   Loss :  0.0498393371556
Iteration :  90   Loss :  0.0487937609188
Iteration :  91   Loss :  0.0477701197584
Iteration :  92   Loss :  0.0467679534999
Iteration :  93   Loss :  0.0457868116226
Iteration :  94   Loss :  0.0448262530573
Iteration :  95   Loss :  0.0438858459883
Iteration :  96   Loss :  0.0429651676584
Iteration :  97   Loss :  0.0420638041797
Iteration :  98   Loss :  0.0411813503473
Iteration :  99   Loss :  0.0403174094569
[ -1.02922529e-03  -1.03762022e-04  -1.84259157e-04 ...,   7.82808681e-04
   4.72389983e-04   7.07289588e-05]
CROSS VALIDATION 50
Iteration :  0   Loss :  19.4005217868
Iteration :  1   Loss :  0.284317914285
Iteration :  2   Loss :  0.278353227115
Iteration :  3   Loss :  0.272513672733
Iteration :  4   Loss :  0.266796625985
Iteration :  5   Loss :  0.261199516792
Iteration :  6   Loss :  0.255719828991
Iteration :  7   Loss :  0.250355099207
Iteration :  8   Loss :  0.245102915743
Iteration :  9   Loss :  0.239960917496
Iteration :  10   Loss :  0.234926792899
Iteration :  11   Loss :  0.229998278877
Iteration :  12   Loss :  0.225173159832
Iteration :  13   Loss :  0.220449266648
Iteration :  14   Loss :  0.215824475714
Iteration :  15   Loss :  0.211296707971
Iteration :  16   Loss :  0.206863927975
Iteration :  17   Loss :  0.202524142984
Iteration :  18   Loss :  0.198275402063
Iteration :  19   Loss :  0.194115795203
Iteration :  20   Loss :  0.190043452467
Iteration :  21   Loss :  0.186056543146
Iteration :  22   Loss :  0.182153274938
Iteration :  23   Loss :  0.178331893142
Iteration :  24   Loss :  0.174590679869
Iteration :  25   Loss :  0.170927953266
Iteration :  26   Loss :  0.167342066769
Iteration :  27   Loss :  0.163831408353
Iteration :  28   Loss :  0.160394399814
Iteration :  29   Loss :  0.157029496055
Iteration :  30   Loss :  0.153735184394
Iteration :  31   Loss :  0.150509983885
Iteration :  32   Loss :  0.14735244465
Iteration :  33   Loss :  0.144261147226
Iteration :  34   Loss :  0.141234701931
Iteration :  35   Loss :  0.138271748237
Iteration :  36   Loss :  0.135370954157
Iteration :  37   Loss :  0.132531015649
Iteration :  38   Loss :  0.129750656027
Iteration :  39   Loss :  0.12702862539
Iteration :  40   Loss :  0.124363700059
Iteration :  41   Loss :  0.121754682024
Iteration :  42   Loss :  0.119200398409
Iteration :  43   Loss :  0.116699700946
Iteration :  44   Loss :  0.114251465454
Iteration :  45   Loss :  0.111854591336
Iteration :  46   Loss :  0.109508001085
Iteration :  47   Loss :  0.1072106398
Iteration :  48   Loss :  0.104961474708
Iteration :  49   Loss :  0.102759494706
Iteration :  50   Loss :  0.100603709901
Iteration :  51   Loss :  0.0984931511651
Iteration :  52   Loss :  0.0964268697052
Iteration :  53   Loss :  0.0944039366305
Iteration :  54   Loss :  0.0924234425383
Iteration :  55   Loss :  0.0904844971038
Iteration :  56   Loss :  0.0885862286804
Iteration :  57   Loss :  0.0867277839076
Iteration :  58   Loss :  0.0849083273278
Iteration :  59   Loss :  0.0831270410102
Iteration :  60   Loss :  0.0813831241832
Iteration :  61   Loss :  0.0796757928747
Iteration :  62   Loss :  0.0780042795595
Iteration :  63   Loss :  0.0763678328143
Iteration :  64   Loss :  0.0747657169797
Iteration :  65   Loss :  0.0731972118297
Iteration :  66   Loss :  0.0716616122481
Iteration :  67   Loss :  0.0701582279109
Iteration :  68   Loss :  0.0686863829767
Iteration :  69   Loss :  0.0672454157824
Iteration :  70   Loss :  0.0658346785458
Iteration :  71   Loss :  0.0716276462853
Iteration :  72   Loss :  0.11458329683
Iteration :  73   Loss :  0.112179461243
Iteration :  74   Loss :  0.109826055567
Iteration :  75   Loss :  0.107522021837
Iteration :  76   Loss :  0.105266324282
Iteration :  77   Loss :  0.103057948861
Iteration :  78   Loss :  0.100895902805
Iteration :  79   Loss :  0.0987792141731
Iteration :  80   Loss :  0.0967069314158
Iteration :  81   Loss :  0.0946781229446
Iteration :  82   Loss :  0.0926918767154
Iteration :  83   Loss :  0.0907472998176
Iteration :  84   Loss :  0.088843518073
Iteration :  85   Loss :  0.0869796756428
Iteration :  86   Loss :  0.0851549346425
Iteration :  87   Loss :  0.0833684747659
Iteration :  88   Loss :  0.0816194929157
Iteration :  89   Loss :  0.0799072028429
Iteration :  90   Loss :  0.0782308347929
Iteration :  91   Loss :  0.0765896351601
Iteration :  92   Loss :  0.0749828661484
Iteration :  93   Loss :  0.07340980544
Iteration :  94   Loss :  0.0718697458707
Iteration :  95   Loss :  0.0703619951117
Iteration :  96   Loss :  0.0688858753586
Iteration :  97   Loss :  0.0674407230264
Iteration :  98   Loss :  0.0660258884518
Iteration :  99   Loss :  0.0646407356003
[ -1.92843371e-03  -6.70393499e-04  -7.82129755e-04 ...,   9.24104899e-04
   9.42538433e-04   7.39973553e-05]
CROSS VALIDATION 51
Iteration :  0   Loss :  21.0572951296
Iteration :  1   Loss :  1.63932647815
Iteration :  2   Loss :  1.10190992663
Iteration :  3   Loss :  0.308644605629
Iteration :  4   Loss :  0.302169570372
Iteration :  5   Loss :  0.295830374462
Iteration :  6   Loss :  0.289624168134
Iteration :  7   Loss :  0.283548161408
Iteration :  8   Loss :  0.277599622834
Iteration :  9   Loss :  0.271775878267
Iteration :  10   Loss :  0.266074309662
Iteration :  11   Loss :  0.260492353896
Iteration :  12   Loss :  0.25502750162
Iteration :  13   Loss :  0.249677296127
Iteration :  14   Loss :  0.24443933225
Iteration :  15   Loss :  0.239311255279
Iteration :  16   Loss :  0.234290759903
Iteration :  17   Loss :  0.229375589176
Iteration :  18   Loss :  0.224563533498
Iteration :  19   Loss :  0.219852429626
Iteration :  20   Loss :  0.215240159698
Iteration :  21   Loss :  0.210724650282
Iteration :  22   Loss :  0.206303871448
Iteration :  23   Loss :  0.201975835847
Iteration :  24   Loss :  0.197738597825
Iteration :  25   Loss :  0.193590252547
Iteration :  26   Loss :  0.189528935136
Iteration :  27   Loss :  0.185552819841
Iteration :  28   Loss :  0.181660119212
Iteration :  29   Loss :  0.177849083298
Iteration :  30   Loss :  0.174117998861
Iteration :  31   Loss :  0.170465188603
Iteration :  32   Loss :  0.166889010416
Iteration :  33   Loss :  0.16338785664
Iteration :  34   Loss :  0.159960153343
Iteration :  35   Loss :  0.156604359613
Iteration :  36   Loss :  0.153318966862
Iteration :  37   Loss :  0.150102498154
Iteration :  38   Loss :  0.146953507535
Iteration :  39   Loss :  0.143870579388
Iteration :  40   Loss :  0.14085232779
Iteration :  41   Loss :  0.137897395898
Iteration :  42   Loss :  0.135004455332
Iteration :  43   Loss :  0.132172205579
Iteration :  44   Loss :  0.129399373411
Iteration :  45   Loss :  0.126684712309
Iteration :  46   Loss :  0.124027001908
Iteration :  47   Loss :  0.121425047442
Iteration :  48   Loss :  0.11887767921
Iteration :  49   Loss :  0.116383752052
Iteration :  50   Loss :  0.113942144831
Iteration :  51   Loss :  0.11155175993
Iteration :  52   Loss :  0.10921152276
Iteration :  53   Loss :  0.106920381274
Iteration :  54   Loss :  0.104677305498
Iteration :  55   Loss :  0.102481287064
Iteration :  56   Loss :  0.100331338758
Iteration :  57   Loss :  0.0982264940792
Iteration :  58   Loss :  0.096165806801
Iteration :  59   Loss :  0.0941483505482
Iteration :  60   Loss :  0.0921732183799
Iteration :  61   Loss :  0.0902395223818
Iteration :  62   Loss :  0.0883463932673
Iteration :  63   Loss :  0.0864929799862
Iteration :  64   Loss :  0.0846784493427
Iteration :  65   Loss :  0.0829019856205
Iteration :  66   Loss :  0.081162790216
Iteration :  67   Loss :  0.0794600812796
Iteration :  68   Loss :  0.077793093364
Iteration :  69   Loss :  0.0761610770804
Iteration :  70   Loss :  0.0745632987609
Iteration :  71   Loss :  0.0729990401297
Iteration :  72   Loss :  0.0714675979794
Iteration :  73   Loss :  0.069968283855
Iteration :  74   Loss :  0.0685004237449
Iteration :  75   Loss :  0.0670633577773
Iteration :  76   Loss :  0.0656564399238
Iteration :  77   Loss :  0.0642790377092
Iteration :  78   Loss :  0.0629305319267
Iteration :  79   Loss :  0.0616103163599
Iteration :  80   Loss :  0.0603177975103
Iteration :  81   Loss :  0.0590523943302
Iteration :  82   Loss :  0.0578135379617
Iteration :  83   Loss :  0.0566006714811
Iteration :  84   Loss :  0.055413249648
Iteration :  85   Loss :  0.0542507386609
Iteration :  86   Loss :  0.0531126159167
Iteration :  87   Loss :  0.0519983697761
Iteration :  88   Loss :  0.0509074993334
Iteration :  89   Loss :  0.0498395141913
Iteration :  90   Loss :  0.0487939342405
Iteration :  91   Loss :  0.047770289444
Iteration :  92   Loss :  0.0467681196256
Iteration :  93   Loss :  0.0457869742631
Iteration :  94   Loss :  0.0448264122859
Iteration :  95   Loss :  0.0438860018764
Iteration :  96   Loss :  0.0429653202761
Iteration :  97   Loss :  0.0420639535957
Iteration :  98   Loss :  0.0411814966287
Iteration :  99   Loss :  0.0403175526694
[ -1.02920551e-03  -1.03771989e-04  -1.84224671e-04 ...,   7.82808681e-04
   4.72389983e-04   7.07289588e-05]
CROSS VALIDATION 52
Iteration :  0   Loss :  21.0572951296
Iteration :  1   Loss :  1.63932647815
Iteration :  2   Loss :  1.10190992663
Iteration :  3   Loss :  0.308644605629
Iteration :  4   Loss :  0.302169570372
Iteration :  5   Loss :  0.295830374462
Iteration :  6   Loss :  0.289624168134
Iteration :  7   Loss :  0.283548161408
Iteration :  8   Loss :  0.277599622834
Iteration :  9   Loss :  0.271775878267
Iteration :  10   Loss :  0.266074309662
Iteration :  11   Loss :  0.260492353896
Iteration :  12   Loss :  0.25502750162
Iteration :  13   Loss :  0.249677296127
Iteration :  14   Loss :  0.24443933225
Iteration :  15   Loss :  0.239311255279
Iteration :  16   Loss :  0.234290759903
Iteration :  17   Loss :  0.229375589176
Iteration :  18   Loss :  0.224563533498
Iteration :  19   Loss :  0.219852429626
Iteration :  20   Loss :  0.215240159698
Iteration :  21   Loss :  0.210724650282
Iteration :  22   Loss :  0.206303871448
Iteration :  23   Loss :  0.201975835847
Iteration :  24   Loss :  0.197738597825
Iteration :  25   Loss :  0.193590252547
Iteration :  26   Loss :  0.189528935136
Iteration :  27   Loss :  0.185552819841
Iteration :  28   Loss :  0.181660119212
Iteration :  29   Loss :  0.177849083298
Iteration :  30   Loss :  0.174117998861
Iteration :  31   Loss :  0.170465188603
Iteration :  32   Loss :  0.166889010416
Iteration :  33   Loss :  0.16338785664
Iteration :  34   Loss :  0.159960153343
Iteration :  35   Loss :  0.156604359613
Iteration :  36   Loss :  0.153318966862
Iteration :  37   Loss :  0.150102498154
Iteration :  38   Loss :  0.146953507535
Iteration :  39   Loss :  0.143870579388
Iteration :  40   Loss :  0.14085232779
Iteration :  41   Loss :  0.137897395898
Iteration :  42   Loss :  0.135004455332
Iteration :  43   Loss :  0.132172205579
Iteration :  44   Loss :  0.129399373411
Iteration :  45   Loss :  0.126684712309
Iteration :  46   Loss :  0.124027001908
Iteration :  47   Loss :  0.121425047442
Iteration :  48   Loss :  0.11887767921
Iteration :  49   Loss :  0.116383752052
Iteration :  50   Loss :  0.113942144831
Iteration :  51   Loss :  0.11155175993
Iteration :  52   Loss :  0.10921152276
Iteration :  53   Loss :  0.106920381274
Iteration :  54   Loss :  0.104677305498
Iteration :  55   Loss :  0.102481287064
Iteration :  56   Loss :  0.100331338758
Iteration :  57   Loss :  0.0982264940792
Iteration :  58   Loss :  0.096165806801
Iteration :  59   Loss :  0.0941483505482
Iteration :  60   Loss :  0.0921732183799
Iteration :  61   Loss :  0.0902395223818
Iteration :  62   Loss :  0.0883463932673
Iteration :  63   Loss :  0.0864929799862
Iteration :  64   Loss :  0.0846784493427
Iteration :  65   Loss :  0.0829019856205
Iteration :  66   Loss :  0.081162790216
Iteration :  67   Loss :  0.0794600812796
Iteration :  68   Loss :  0.077793093364
Iteration :  69   Loss :  0.0761610770804
Iteration :  70   Loss :  0.0745632987609
Iteration :  71   Loss :  0.0729990401297
Iteration :  72   Loss :  0.0714675979794
Iteration :  73   Loss :  0.069968283855
Iteration :  74   Loss :  0.0685004237449
Iteration :  75   Loss :  0.0670633577773
Iteration :  76   Loss :  0.0656564399238
Iteration :  77   Loss :  0.0642790377092
Iteration :  78   Loss :  0.0629305319267
Iteration :  79   Loss :  0.0616103163599
Iteration :  80   Loss :  0.0603177975103
Iteration :  81   Loss :  0.0590523943302
Iteration :  82   Loss :  0.0578135379617
Iteration :  83   Loss :  0.0566006714811
Iteration :  84   Loss :  0.055413249648
Iteration :  85   Loss :  0.0542507386609
Iteration :  86   Loss :  0.0531126159167
Iteration :  87   Loss :  0.0519983697761
Iteration :  88   Loss :  0.0509074993334
Iteration :  89   Loss :  0.0498395141913
Iteration :  90   Loss :  0.0487939342405
Iteration :  91   Loss :  0.047770289444
Iteration :  92   Loss :  0.0467681196256
Iteration :  93   Loss :  0.0457869742631
Iteration :  94   Loss :  0.0448264122859
Iteration :  95   Loss :  0.0438860018764
Iteration :  96   Loss :  0.0429653202761
Iteration :  97   Loss :  0.0420639535957
Iteration :  98   Loss :  0.0411814966287
Iteration :  99   Loss :  0.0403175526694
[ -1.02920551e-03  -1.03771989e-04  -1.84224671e-04 ...,   7.82808681e-04
   4.72389983e-04   7.07289588e-05]
CROSS VALIDATION 53
Iteration :  0   Loss :  40.5901003917
Iteration :  1   Loss :  0.302071142587
Iteration :  2   Loss :  0.295734011587
Iteration :  3   Loss :  0.289529826849
Iteration :  4   Loss :  0.283455799303
Iteration :  5   Loss :  0.277509198388
Iteration :  6   Loss :  0.27168735083
Iteration :  7   Loss :  0.265987639436
Iteration :  8   Loss :  0.260407501919
Iteration :  9   Loss :  0.254944429747
Iteration :  10   Loss :  0.249595967014
Iteration :  11   Loss :  0.244359709335
Iteration :  12   Loss :  0.239233302768
Iteration :  13   Loss :  0.234214442753
Iteration :  14   Loss :  0.229300873078
Iteration :  15   Loss :  0.224490384865
Iteration :  16   Loss :  0.219780815573
Iteration :  17   Loss :  0.215170048031
Iteration :  18   Loss :  0.210656009484
Iteration :  19   Loss :  0.20623667066
Iteration :  20   Loss :  0.20191004486
Iteration :  21   Loss :  0.197674187063
Iteration :  22   Loss :  0.193527193054
Iteration :  23   Loss :  0.189467198564
Iteration :  24   Loss :  0.185492378437
Iteration :  25   Loss :  0.181600945804
Iteration :  26   Loss :  0.177791151286
Iteration :  27   Loss :  0.1740612822
Iteration :  28   Loss :  0.170409661798
Iteration :  29   Loss :  0.166834648504
Iteration :  30   Loss :  0.163334635183
Iteration :  31   Loss :  0.159908048416
Iteration :  32   Loss :  0.156553347791
Iteration :  33   Loss :  0.153269025214
Iteration :  34   Loss :  0.150053604229
Iteration :  35   Loss :  0.146905639352
Iteration :  36   Loss :  0.143823715428
Iteration :  37   Loss :  0.140806446987
Iteration :  38   Loss :  0.137852477625
Iteration :  39   Loss :  0.134960479397
Iteration :  40   Loss :  0.132129152212
Iteration :  41   Loss :  0.129357223257
Iteration :  42   Loss :  0.126643446421
Iteration :  43   Loss :  0.123986601734
Iteration :  44   Loss :  0.121385494821
Iteration :  45   Loss :  0.118838956361
Iteration :  46   Loss :  0.116345841567
Iteration :  47   Loss :  0.113905029668
Iteration :  48   Loss :  0.111515423404
Iteration :  49   Loss :  0.109175948535
Iteration :  50   Loss :  0.106885553359
Iteration :  51   Loss :  0.104643208235
Iteration :  52   Loss :  0.102447905125
Iteration :  53   Loss :  0.100298657137
Iteration :  54   Loss :  0.0981944980836
Iteration :  55   Loss :  0.0961344820473
Iteration :  56   Loss :  0.0941176829545
Iteration :  57   Loss :  0.0921431941597
Iteration :  58   Loss :  0.0902101280378
Iteration :  59   Loss :  0.0883176155853
Iteration :  60   Loss :  0.0864648060293
Iteration :  61   Loss :  0.0846508664455
Iteration :  62   Loss :  0.082874981383
Iteration :  63   Loss :  0.0811363524987
Iteration :  64   Loss :  0.0794341981974
Iteration :  65   Loss :  0.0777677532814
Iteration :  66   Loss :  0.0761362686057
Iteration :  67   Loss :  0.0745390107417
Iteration :  68   Loss :  0.0729752616473
Iteration :  69   Loss :  0.0714443183442
Iteration :  70   Loss :  0.0699454926018
Iteration :  71   Loss :  0.0684781106279
Iteration :  72   Loss :  0.0670415127657
Iteration :  73   Loss :  0.0656350531973
Iteration :  74   Loss :  0.0642580996534
Iteration :  75   Loss :  0.062910033129
Iteration :  76   Loss :  0.0615902476052
Iteration :  77   Loss :  0.0602981497767
Iteration :  78   Loss :  0.0590331587852
Iteration :  79   Loss :  0.057794705958
Iteration :  80   Loss :  0.0565822345527
Iteration :  81   Loss :  0.0553951995067
Iteration :  82   Loss :  0.0542330671924
Iteration :  83   Loss :  0.0530953151768
Iteration :  84   Loss :  0.0519814319873
Iteration :  85   Loss :  0.0508909168814
Iteration :  86   Loss :  0.0498232796214
Iteration :  87   Loss :  0.0487780402546
Iteration :  88   Loss :  0.0477547288971
Iteration :  89   Loss :  0.0467528855224
Iteration :  90   Loss :  0.0457720597552
Iteration :  91   Loss :  0.0448118106684
Iteration :  92   Loss :  0.0438717065853
Iteration :  93   Loss :  0.042951324885
Iteration :  94   Loss :  0.042050251813
Iteration :  95   Loss :  0.0411680822948
Iteration :  96   Loss :  0.040304419754
Iteration :  97   Loss :  0.0394588759339
Iteration :  98   Loss :  0.038631070723
Iteration :  99   Loss :  0.0378206319842
[ -9.69306925e-04   2.62619117e-05  -2.55321231e-04 ...,   6.97926175e-04
   4.44724355e-04   1.04769145e-04]
1   RFEF   0.000374256064949
2   LT   0.000301537782308
3   LSGA   0.000290694766528
4   LOPER   -0.000415233273154
5   LIFG   -0.000415465483358
6   LTRIA   -0.000415812771186
7   LIT   -0.000424368139435
8   LIPS   -0.000440640837821
9   RIT   -0.000461767329439
10   RT   -0.000522239793698
11   LIPL   -0.000581742339666
12   SMA   -0.000662903893736
13   LPPREC   -0.000727876589074
14   LFEF   -0.000836141655439
15   LDLPFC   -0.000894161806227
16   RSPL   -0.00108875296899
17   LSPL   -0.00113658475151
18   RPPREC   -0.00125335791658
19   CALC   -0.00130764835647
20   RTRIA   -0.00131913252098
21   ROPER   -0.00132911681198
22   RIPS   -0.00146225618483
23   RDLPFC   -0.00189576488604
24   RIPL   -0.00254474378921
25   RSGA   -0.0031144389526
Accuracy (Hinge Loss):	0.852941176471
